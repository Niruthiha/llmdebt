rank,category,name,full_name,description,stars,confidence,signal_agreement,metadata_conf,dependency_conf,readme_conf,html_url,selected,notes
1,1A_2A,adapters,adapter-hub/adapters,A Unified Library for Parameter-Efficient and Modular Transfer Learning ,2758,1.0,0.833,1.0,1.0,1.0,https://github.com/adapter-hub/adapters,Yes,
2,1A_2A,OpenRLHF,OpenRLHF/OpenRLHF,"An Easy-to-use, Scalable and High-performance RLHF Framework based on Ray (PPO & GRPO & REINFORCE++ & vLLM & Ray & Dynamic Sampling & Async Agentic RL)",7730,0.869,1.0,0.7,0.857,1.0,https://github.com/OpenRLHF/OpenRLHF,Yes,
3,1A_2A,safe-rlhf,PKU-Alignment/safe-rlhf,Safe RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback,1519,0.857,1.0,1.0,0.714,1.0,https://github.com/PKU-Alignment/safe-rlhf,Yes,
4,1A_2A,oumi,oumi-ai/oumi,"Easily fine-tune, evaluate and deploy gpt-oss, Qwen3, DeepSeek-R1, or any open source LLM / VLM!",8427,0.849,1.0,0.6,0.857,1.0,https://github.com/oumi-ai/oumi,Yes,
5,1A_2A,unsloth,unslothai/unsloth,"Fine-tuning & Reinforcement Learning for LLMs. ğŸ¦¥ Train OpenAI gpt-oss, Qwen3, Llama 4, DeepSeek-R1, Gemma 3, TTS 2x faster with 70% less VRAM.",44568,0.837,1.0,0.9,0.714,1.0,https://github.com/unslothai/unsloth,Yes,
6,1A_2A,LLaMA-Factory,hiyouga/LLaMA-Factory,Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024),56631,0.786,1.0,1.0,0.571,1.0,https://github.com/hiyouga/LLaMA-Factory,Yes,
7,1A_2A,refiners,finegrain-ai/refiners,A microframework on top of PyTorch with first-class citizen APIs for foundation model adaptation,835,0.714,1.0,1.0,0.429,1.0,https://github.com/finegrain-ai/refiners,Yes,
8,1A_2A,SLAM-LLM,X-LANCE/SLAM-LLM,"Speech, Language, Audio, Music Processing with Large Language Model",875,0.706,1.0,0.3,0.714,0.963,https://github.com/X-LANCE/SLAM-LLM,Yes,
9,1A_2A,EasyDeL,erfanzar/EasyDeL,"Accelerate, Optimize performance with streamlined training and serving options with JAX.",301,0.646,1.0,0.3,0.571,1.0,https://github.com/erfanzar/EasyDeL,Yes,
10,1A_2A,OSWorld,xlang-ai/OSWorld,[NeurIPS 2024] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments,2099,0.624,0.5,0.6,0.571,0.726,https://github.com/xlang-ai/OSWorld,Yes,
11,1A_2A,mlx-vlm,Blaizzy/mlx-vlm,MLX-VLM is a package for inference and fine-tuning of Vision Language Models (VLMs) on your Mac using MLX.,1596,0.61,0.833,0.3,0.5,1.0,https://github.com/Blaizzy/mlx-vlm,Yes,
12,1A_2A,terratorch,IBM/terratorch,A Python toolkit for fine-tuning Geospatial Foundation Models (GFMs).,551,0.594,1.0,0.4,0.429,1.0,https://github.com/IBM/terratorch,Yes,
13,1A_2A,Speech-AI-Forge,lenML/Speech-AI-Forge,"ğŸ¦ Speech-AI-Forge is a project developed around TTS generation model, implementing an API Server and a Gradio-based WebUI.",1334,0.585,0.667,0.3,0.714,0.561,https://github.com/lenML/Speech-AI-Forge,Yes,
14,1A_2A,LLMBox,RUCAIBox/LLMBox,"A comprehensive library for implementing LLMs, including a unified training pipeline and comprehensive model evaluation.",835,0.579,0.833,0.2,0.5,0.963,https://github.com/RUCAIBox/LLMBox,Yes,
15,1A_2A,Ovis,AIDC-AI/Ovis,"A novel Multimodal Large Language Model (MLLM) architecture, designed to structurally align visual and textual embeddings.",1238,0.578,0.833,0.2,0.571,0.841,https://github.com/AIDC-AI/Ovis,Yes,
16,1A_2A,nncf,openvinotoolkit/nncf,Neural Network Compression Framework for enhanced OpenVINOâ„¢ inference,1073,0.563,1.0,0.6,0.286,1.0,https://github.com/openvinotoolkit/nncf,Yes,
17,1A_2A,DeepSpeed,deepspeedai/DeepSpeed,"DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.",39842,0.543,1.0,0.5,0.286,1.0,https://github.com/deepspeedai/DeepSpeed,Yes,
18,1A_2A,instructlab,instructlab/instructlab,InstructLab Core package.  Use this to chat with a model and execute the InstructLab workflow to train a model using custom taxonomy data.,1344,0.537,0.667,0.2,0.714,0.466,https://github.com/instructlab/instructlab,Yes,
19,1A_2A,training_extensions,open-edge-platform/training_extensions,"Train, Evaluate, Optimize, Deploy Computer Vision Models via OpenVINOâ„¢",1199,0.527,0.833,0.3,0.333,1.0,https://github.com/open-edge-platform/training_extensions,Yes,
20,1A_2A,Liger-Kernel,linkedin/Liger-Kernel,Efficient Triton Kernels for LLM Training,5557,0.523,1.0,0.4,0.286,1.0,https://github.com/linkedin/Liger-Kernel,Yes,
1,1A_2B,gpustack,gpustack/gpustack,"Simple, scalable AI model deployment on GPU clusters",3397,0.813,1.0,0.9,0.667,1.0,https://github.com/gpustack/gpustack,Yes,
2,1A_2B,TensorRT-Model-Optimizer,NVIDIA/TensorRT-Model-Optimizer,"A unified library of state-of-the-art model optimization techniques like quantization, pruning, distillation, speculative decoding, etc. It compresses deep learning models for downstream deployment frameworks like TensorRT-LLM or TensorRT to optimize inference speed.",1139,0.757,0.833,0.5,0.714,1.0,https://github.com/NVIDIA/TensorRT-Model-Optimizer,Yes,
3,1A_2B,LightLLM,ModelTC/LightLLM,"LightLLM is a Python-based LLM (Large Language Model) inference and serving framework, notable for its lightweight design, easy scalability, and high-speed performance.",3538,0.753,1.0,0.6,0.667,1.0,https://github.com/ModelTC/LightLLM,Yes,
4,1A_2B,camel,camel-ai/camel,ğŸ« CAMEL: The first and the best multi-agent framework. Finding the Scaling Law of Agents. https://www.camel-ai.org,13931,0.753,0.667,0.6,0.667,1.0,https://github.com/camel-ai/camel,Yes,
5,1A_2B,GPTQModel,ModelCloud/GPTQModel,"Production ready LLM model compression/quantization toolkit with hw accelerated inference support for both cpu/gpu via HF, vLLM, and SGLang.",741,0.714,0.833,1.0,0.429,1.0,https://github.com/ModelCloud/GPTQModel,Yes,
6,1A_2B,UHGEval,IAAR-Shanghai/UHGEval,"[ACL 2024] User-friendly evaluation framework: Eval Suite & Benchmarks: UHGEval, HaluEval, HalluQA, etc.",172,0.714,0.5,1.0,0.429,1.0,https://github.com/IAAR-Shanghai/UHGEval,Yes,
7,1A_2B,MLServer,SeldonIO/MLServer,"An inference server for your machine learning models, including support for multiple frameworks, multi-model serving and more",837,0.713,1.0,0.4,0.667,1.0,https://github.com/SeldonIO/MLServer,Yes,
8,1A_2B,pipelines,open-webui/pipelines,"Pipelines: Versatile, UI-Agnostic OpenAI-Compatible Plugin Framework ",2011,0.713,0.833,0.4,0.667,1.0,https://github.com/open-webui/pipelines,Yes,
9,1A_2B,potpie,potpie-ai/potpie,Prompt-To-Agent : Create custom engineering agents for your codebase,4869,0.708,0.667,0.5,0.667,0.915,https://github.com/potpie-ai/potpie,Yes,
10,1A_2B,OpenLLM,bentoml/OpenLLM,"Run any open-source LLMs, such as DeepSeek and Llama, as OpenAI compatible API endpoint in the cloud.",11709,0.696,0.667,0.6,0.667,0.81,https://github.com/bentoml/OpenLLM,Yes,
11,1A_2B,sarathi-serve,microsoft/sarathi-serve,A low-latency & high-throughput serving engine for LLMs,407,0.673,1.0,0.2,0.667,1.0,https://github.com/microsoft/sarathi-serve,Yes,
12,1A_2B,NeMo-Guardrails,NVIDIA/NeMo-Guardrails,NeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems.,5009,0.673,0.833,0.2,0.667,1.0,https://github.com/NVIDIA/NeMo-Guardrails,Yes,
13,1A_2B,auto-round,intel/auto-round,"Advanced Quantization Algorithm for LLMs and VLMs, with support for CPU, Intel GPU, CUDA and HPU. Seamlessly integrated with Torchao, Transformers, and vLLM. Export your models effortlessly to autogptq, autoawq, gguf and autoround formats with high accuracy even at extremely low bit precision.",597,0.673,0.833,0.8,0.429,0.995,https://github.com/intel/auto-round,Yes,
14,1A_2B,vllm,vllm-project/vllm,A high-throughput and memory-efficient inference and serving engine for LLMs,56098,0.667,1.0,1.0,0.333,1.0,https://github.com/vllm-project/vllm,Yes,
15,1A_2B,zenml,zenml-io/zenml,ZenML ğŸ™: MLOps for Reliable AI: from Classical AI to Agents. https://zenml.io.,4829,0.649,0.667,0.2,0.833,0.64,https://github.com/zenml-io/zenml,Yes,
16,1A_2B,FastDeploy,PaddlePaddle/FastDeploy,High-performance Inference and Deployment Toolkit for LLMs and VLMs based on PaddlePaddle,3462,0.647,1.0,0.9,0.333,1.0,https://github.com/PaddlePaddle/FastDeploy,Yes,
17,1A_2B,CosyVoice,FunAudioLLM/CosyVoice,"Multi-lingual large voice generation model, providing inference, training and deployment full-stack ability.",15936,0.621,0.833,0.5,0.667,0.625,https://github.com/FunAudioLLM/CosyVoice,Yes,
18,1A_2B,ENOVA,Emerging-AI/ENOVA,"A deployment, monitoring and autoscaling service towards serverless LLM serving.",153,0.619,1.0,0.4,0.5,0.963,https://github.com/Emerging-AI/ENOVA,Yes,
19,1A_2B,evalplus,evalplus/evalplus,Rigourous evaluation of LLM-synthesized code - NeurIPS 2023 & COLM 2024,1563,0.607,0.833,0.7,0.333,1.0,https://github.com/evalplus/evalplus,Yes,
20,1A_2B,neural-compressor,intel/neural-compressor,"SOTA low-bit LLM quantization (INT8/FP8/INT4/FP4/NF4) & sparsity; leading model compression techniques on TensorFlow, PyTorch, and ONNX Runtime",2476,0.543,0.667,0.8,0.167,1.0,https://github.com/intel/neural-compressor,Yes,
1,1A_2C,RAG-FiT,IntelLabs/RAG-FiT,Framework for enhancing LLMs for RAG tasks using fine-tuning.,747,0.857,0.833,1.0,0.714,1.0,https://github.com/IntelLabs/RAG-FiT,Yes,
2,1A_2C,pyserini,castorini/pyserini,Pyserini is a Python toolkit for reproducible information retrieval research with sparse and dense representations.,1917,0.773,0.833,0.7,0.667,1.0,https://github.com/castorini/pyserini,Yes,
3,1A_2C,stark,snap-stanford/stark,(NeurIPS D&B 2024) STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases ,318,0.76,0.833,0.8,0.6,1.0,https://github.com/snap-stanford/stark,Yes,
4,1A_2C,cognee,topoteretes/cognee,Memory for AI Agents in 5 lines of code,6791,0.756,0.667,1.0,0.667,0.743,https://github.com/topoteretes/cognee,Yes,
5,1A_2C,neo4j-graphrag-python,neo4j/neo4j-graphrag-python,Neo4j GraphRAG for Python,725,0.75,1.0,1.0,0.5,1.0,https://github.com/neo4j/neo4j-graphrag-python,Yes,
6,1A_2C,HippoRAG,OSU-NLP-Group/HippoRAG,[NeurIPS'24] HippoRAG is a novel RAG framework inspired by human long-term memory that enables LLMs to continuously integrate knowledge across external documents. RAG + Knowledge Graphs + Personalized PageRank.,2715,0.75,0.833,1.0,0.5,1.0,https://github.com/OSU-NLP-Group/HippoRAG,Yes,
7,1A_2C,rag_api,danny-avila/rag_api,ID-based RAG FastAPI: Integration with Langchain and PostgreSQL/pgvector,619,0.75,0.833,1.0,0.5,1.0,https://github.com/danny-avila/rag_api,Yes,
8,1A_2C,gpt-researcher,assafelovic/gpt-researcher,LLM based autonomous agent that conducts deep local and web research on any topic and generates a long report with citations.,23150,0.733,0.667,0.5,0.667,1.0,https://github.com/assafelovic/gpt-researcher,Yes,
9,1A_2C,pylate,lightonai/pylate,Late Interaction Models Training & Retrieval,530,0.73,0.833,0.9,0.5,1.0,https://github.com/lightonai/pylate,Yes,
10,1A_2C,txtai,neuml/txtai,"ğŸ’¡ All-in-one open-source AI framework for semantic search, LLM orchestration and language model workflows",11457,0.714,0.833,1.0,0.429,1.0,https://github.com/neuml/txtai,Yes,
11,1A_2C,FlashRAG,RUC-NLPIR/FlashRAG,âš¡FlashRAG: A Python Toolkit for Efficient RAG Research (WWW2025 Resource),2636,0.714,0.833,1.0,0.429,1.0,https://github.com/RUC-NLPIR/FlashRAG,Yes,
12,1A_2C,beir,beir-cellar/beir,"A Heterogeneous Benchmark for Information Retrieval. Easy to use, evaluate your models across 15+ diverse IR datasets.",1924,0.714,0.833,1.0,0.429,1.0,https://github.com/beir-cellar/beir,Yes,
13,1A_2C,TrustRAG,gomate-community/TrustRAG,"TrustRAGï¼šThe RAG Framework within Reliable input,Trusted output",1113,0.714,0.833,1.0,0.429,1.0,https://github.com/gomate-community/TrustRAG,Yes,
14,1A_2C,RAG-Retrieval,NovaSearch-Team/RAG-Retrieval,"Unify Efficient Fine-tuning of  RAG Retrieval, including Embedding, ColBERT, ReRanker.",1020,0.714,0.833,1.0,0.429,1.0,https://github.com/NovaSearch-Team/RAG-Retrieval,Yes,
15,1A_2C,giskard-oss,Giskard-AI/giskard-oss,ğŸ¢ Open-Source Evaluation & Testing library for LLM Agents,4824,0.714,0.667,1.0,0.429,1.0,https://github.com/Giskard-AI/giskard-oss,Yes,
16,1A_2C,colpali,illuin-tech/colpali,"The code used to train and run inference with the ColVision models, e.g. ColPali, ColQwen2, and ColSmol.",2153,0.706,0.833,0.6,0.571,1.0,https://github.com/illuin-tech/colpali,Yes,
17,1A_2C,langroid,langroid/langroid,Harness LLMs with Multi-Agent Programming,3622,0.696,0.667,0.9,0.5,0.887,https://github.com/langroid/langroid,Yes,
18,1A_2C,mem0,mem0ai/mem0,Universal memory layer for AI Agents; Announcing OpenMemory MCP - local and secure memory management.,38646,0.67,0.667,0.3,0.667,0.923,https://github.com/mem0ai/mem0,Yes,
19,1A_2C,dsRAG,D-Star-AI/dsRAG,High-performance retrieval engine for unstructured data,1479,0.67,0.667,0.6,0.5,1.0,https://github.com/D-Star-AI/dsRAG,Yes,
20,1A_2C,VARAG,adithya-s-k/VARAG, Vision-Augmented Retrieval and Generation (VARAG) - Vision first RAG Engine,477,0.667,0.833,1.0,0.333,1.0,https://github.com/adithya-s-k/VARAG,Yes,
1,1A_2D,agentops,AgentOps-AI/agentops,"Python SDK for AI agent monitoring, LLM cost tracking, benchmarking, and more. Integrates with most LLMs and agent frameworks including CrewAI, Agno, OpenAI Agents SDK, Langchain, Autogen, AG2, and CamelAI",4810,0.833,0.833,1.0,0.667,1.0,https://github.com/AgentOps-AI/agentops,Yes,
2,1A_2D,AgentLab,ServiceNow/AgentLab,"AgentLab: An open-source framework for developing, testing, and benchmarking web agents on diverse tasks, designed for scalability and reproducibility.",388,0.833,0.667,1.0,0.667,1.0,https://github.com/ServiceNow/AgentLab,Yes,
3,1A_2D,open-assistant-api,MLT-OSS/open-assistant-api,"The Open Assistant API is a ready-to-use, open-source, self-hosted agent/gpts orchestration creation framework, supporting customized extensions for LLM, RAG, function call, and tools capabilities. It also supports seamless integration with the openai/langchain sdk.",349,0.75,0.667,1.0,0.5,1.0,https://github.com/MLT-OSS/open-assistant-api,Yes,
4,1A_2D,ControlFlow,PrefectHQ/ControlFlow,ğŸ¦¾ Take control of your AI agents,1360,0.72,0.833,0.6,0.6,1.0,https://github.com/PrefectHQ/ControlFlow,Yes,
5,1A_2D,RD-Agent,microsoft/RD-Agent,"Research and development (R&D) is crucial for the enhancement of industrial productivity, especially in the AI era, where the core aspects of R&D are mainly focused on data and models. We are committed to automating these high-value generic R&D processes through R&D-Agent, which lets AI drive data-driven AI. ğŸ”—https://aka.ms/RD-Agent-Tech-Report",7145,0.67,0.833,0.6,0.5,1.0,https://github.com/microsoft/RD-Agent,Yes,
6,1A_2D,astra-assistants-api,datastax/astra-assistants-api,Drop in replacement for the OpenAI Assistants API ,204,0.667,0.667,1.0,0.333,1.0,https://github.com/datastax/astra-assistants-api,Yes,
7,1A_2D,logfire,pydantic/logfire,Uncomplicated Observability for Python and beyond! ğŸªµğŸ”¥,3487,0.662,0.5,0.2,0.833,0.684,https://github.com/pydantic/logfire,Yes,
8,1A_2D,crewAI,crewAIInc/crewAI,"Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.",36029,0.66,1.0,0.8,0.4,1.0,https://github.com/crewAIInc/crewAI,Yes,
9,1A_2D,agents,livekit/agents,A powerful framework for building realtime voice AI agents ğŸ¤–ğŸ™ï¸ğŸ“¹ ,7215,0.66,0.833,0.3,0.6,1.0,https://github.com/livekit/agents,Yes,
10,1A_2D,Devon,entropy-research/Devon,Devon: An open-source pair programmer,3448,0.65,0.833,0.5,0.5,1.0,https://github.com/entropy-research/Devon,Yes,
11,1A_2D,agent-zero,agent0ai/agent-zero,Agent Zero AI framework,11582,0.644,0.667,0.5,0.5,0.981,https://github.com/agent0ai/agent-zero,Yes,
12,1A_2D,dbos-transact-py,dbos-inc/dbos-transact-py,Lightweight Durable Python Workflows,869,0.643,0.667,1.0,0.286,1.0,https://github.com/dbos-inc/dbos-transact-py,Yes,
13,1A_2D,prefect,PrefectHQ/prefect,Prefect is a workflow orchestration framework for building resilient data pipelines in Python.,20149,0.624,0.833,1.0,0.333,0.859,https://github.com/PrefectHQ/prefect,Yes,
14,1A_2D,MetaGPT,FoundationAgents/MetaGPT,"ğŸŒŸ The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming",58041,0.62,0.667,0.6,0.4,1.0,https://github.com/FoundationAgents/MetaGPT,Yes,
15,1A_2D,AGiXT,Josh-XT/AGiXT,"AGiXT is a dynamic AI Agent Automation Platform that seamlessly orchestrates instruction management and complex task execution across diverse AI providers. Combining adaptive memory, smart features, and a versatile plugin system, AGiXT delivers efficient and comprehensive AI solutions.",3067,0.618,0.833,0.4,0.667,0.684,https://github.com/Josh-XT/AGiXT,Yes,
16,1A_2D,griptape,griptape-ai/griptape,"Modular Python framework for AI agents and workflows with chain-of-thought reasoning, tools, and memory. ",2365,0.61,0.667,0.3,0.5,1.0,https://github.com/griptape-ai/griptape,Yes,
17,1A_2D,letta,letta-ai/letta,"Letta (formerly MemGPT) is the stateful agents framework with memory, reasoning, and context management.",18020,0.608,0.833,0.3,0.833,0.439,https://github.com/letta-ai/letta,Yes,
18,1A_2D,TravelPlanner,OSU-NLP-Group/TravelPlanner,"[ICML'24 Spotlight] ""TravelPlanner: A Benchmark for Real-World Planning with Language Agents""",403,0.6,0.833,0.5,0.4,1.0,https://github.com/OSU-NLP-Group/TravelPlanner,Yes,
19,1A_2D,llm-workflow-engine,llm-workflow-engine/llm-workflow-engine,Power CLI and Workflow manager for LLMs (core package),3710,0.58,1.0,0.4,0.4,1.0,https://github.com/llm-workflow-engine/llm-workflow-engine,Yes,
20,1A_2D,byzer-llm,allwefantasy/byzer-llm,"Easy, fast, and cheap pretrain,finetune, serving for everyone",314,0.569,0.667,0.2,0.667,0.651,https://github.com/allwefantasy/byzer-llm,Yes,
1,1A_2E,transformers,huggingface/transformers,"ğŸ¤— Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",148714,0.94,0.833,0.7,1.0,1.0,https://github.com/huggingface/transformers,Yes,
2,1A_2E,optimum-benchmark,huggingface/optimum-benchmark,"ğŸ‹ï¸ A unified multi-backend utility for benchmarking Transformers, Timm, PEFT, Diffusers and Sentence-Transformers with full support of Optimum's hardware optimizations & quantization schemes.",310,0.837,0.833,0.9,0.714,1.0,https://github.com/huggingface/optimum-benchmark,Yes,
3,1A_2E,deepeval,confident-ai/deepeval,The LLM Evaluation Framework,10328,0.833,0.667,1.0,0.667,1.0,https://github.com/confident-ai/deepeval,Yes,
4,1A_2E,helm,stanford-crfm/helm,"Holistic Evaluation of Language Models (HELM) is an open source Python framework created by the Center for Research on Foundation Models (CRFM) at Stanford for holistic, reproducible and transparent evaluation of foundation models, including large language models (LLMs) and multimodal models.",2428,0.797,1.0,0.4,0.833,1.0,https://github.com/stanford-crfm/helm,Yes,
5,1A_2E,evaluate,huggingface/evaluate,ğŸ¤— Evaluate: A library for easily evaluating machine learning models and datasets.,2299,0.757,1.0,0.2,0.833,1.0,https://github.com/huggingface/evaluate,Yes,
6,1A_2E,mteb,embeddings-benchmark/mteb,MTEB: Massive Text Embedding Benchmark,2783,0.714,0.667,1.0,0.429,1.0,https://github.com/embeddings-benchmark/mteb,Yes,
7,1A_2E,VLMEvalKit,open-compass/VLMEvalKit,"Open-source evaluation toolkit of large multi-modality models (LMMs), support 220+ LMMs, 80+ benchmarks",2944,0.654,0.833,0.7,0.429,1.0,https://github.com/open-compass/VLMEvalKit,Yes,
8,1A_2E,promptbench,microsoft/promptbench,A unified evaluation framework for large language models,2693,0.654,0.833,0.7,0.429,1.0,https://github.com/microsoft/promptbench,Yes,
9,1A_2E,benchmark,pytorch/benchmark,TorchBench is a collection of open source benchmarks used to evaluate PyTorch performance.,978,0.643,0.833,1.0,0.286,1.0,https://github.com/pytorch/benchmark,Yes,
10,1A_2E,langtest,Pacific-AI-Corp/langtest,Deliver safe & effective language models,533,0.643,0.833,1.0,0.286,1.0,https://github.com/Pacific-AI-Corp/langtest,Yes,
11,1A_2E,PerfKitBenchmarker,GoogleCloudPlatform/PerfKitBenchmarker,"PerfKit Benchmarker (PKB) contains a set of benchmarks to measure and compare cloud offerings. The benchmarks use default settings to reflect what most users will see. PerfKit Benchmarker is licensed under the Apache 2 license terms. Please make sure to read, understand and agree to the terms of the LICENSE and CONTRIBUTING files before proceeding.",1958,0.583,0.667,1.0,0.167,1.0,https://github.com/GoogleCloudPlatform/PerfKitBenchmarker,Yes,
12,1A_2E,SWE-bench,SWE-bench/SWE-bench,SWE-bench [Multimodal]: Can Language Models Resolve Real-world Github Issues?,3372,0.574,0.833,0.3,0.429,1.0,https://github.com/SWE-bench/SWE-bench,Yes,
13,1A_2E,vidore-benchmark,illuin-tech/vidore-benchmark,Vision Document Retrieval (ViDoRe): Benchmark. Evaluation code for the ColPali paper.,230,0.571,0.667,1.0,0.143,1.0,https://github.com/illuin-tech/vidore-benchmark,Yes,
14,1A_2E,VBench,Vchitect/VBench,[CVPR2024 Highlight] VBench - We Evaluate Video Generation,1167,0.567,0.667,0.5,0.333,1.0,https://github.com/Vchitect/VBench,Yes,
15,1A_2E,vector-db-benchmark,qdrant/vector-db-benchmark,Framework for benchmarking vector search engines,330,0.563,1.0,0.9,0.167,1.0,https://github.com/qdrant/vector-db-benchmark,Yes,
16,1A_2E,automlbenchmark,openml/automlbenchmark,OpenML AutoML Benchmarking Framework,433,0.563,0.667,0.9,0.167,1.0,https://github.com/openml/automlbenchmark,Yes,
17,1A_2E,ranx,AmenRa/ranx,"âš¡ï¸A Blazing-Fast Python Library for Ranking Evaluation, Comparison, and Fusion ğŸ",583,0.544,0.833,1.0,0.167,0.868,https://github.com/AmenRa/ranx,Yes,
18,1A_2E,bigcode-evaluation-harness,bigcode-project/bigcode-evaluation-harness,A framework for the evaluation of autoregressive code generation language models.,976,0.523,0.833,0.4,0.286,1.0,https://github.com/bigcode-project/bigcode-evaluation-harness,Yes,
19,1A_2E,algorithmic-efficiency,mlcommons/algorithmic-efficiency,MLCommons Algorithmic Efficiency is a benchmark and competition measuring neural network training speedups due to algorithmic improvements in both training algorithms and models.,390,0.523,0.833,0.4,0.286,1.0,https://github.com/mlcommons/algorithmic-efficiency,Yes,
20,1A_2E,LiveCodeBench,LiveCodeBench/LiveCodeBench,"Official repository for the paper ""LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code""",634,0.507,0.833,0.2,0.333,1.0,https://github.com/LiveCodeBench/LiveCodeBench,Yes,
1,1B_2B,comfyui_LLM_party,heshengtao/comfyui_LLM_party,"LLM Agent Framework in ComfyUI includes MCP sever, Omost,GPT-sovits, ChatTTS,GOT-OCR2.0, and FLUX prompt nodes,access to Feishu,discord,and adapts to all llms with similar openai / aisuite interfaces, such as o1,ollama, gemini, grok, qwen, GLM, deepseek, kimi,doubao. Adapted to local llms, vlm, gguf such as llama-3.3 Janus-Pro, Linkage graphRAG",1866,0.897,0.833,0.9,0.833,1.0,https://github.com/heshengtao/comfyui_LLM_party,Yes,
2,1B_2B,burr,apache/burr,"Build applications that make decisions (chatbots, agents, simulations, etc...). Monitor, trace, persist, and execute on your own infrastructure.",1768,0.837,0.833,0.6,0.833,1.0,https://github.com/apache/burr,Yes,
3,1B_2B,HuixiangDou,InternLM/HuixiangDou,HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance,2427,0.753,0.667,0.6,0.667,1.0,https://github.com/InternLM/HuixiangDou,Yes,
4,1B_2B,llm-compressor,vllm-project/llm-compressor,Transformers-compatible library for applying various compression algorithms to LLMs for optimized deployment with vLLM,1830,0.726,0.833,0.7,0.571,1.0,https://github.com/vllm-project/llm-compressor,Yes,
5,1B_2B,airunner,Capsize-Games/airunner,"Offline inference engine for art, real-time voice conversations, LLM powered chatbots and automated workflows",1221,0.706,0.667,0.6,0.571,1.0,https://github.com/Capsize-Games/airunner,Yes,
6,1B_2B,FedML,FedML-AI/FedML,"FEDML - The unified and scalable ML library for large-scale distributed training, model serving, and federated learning. FEDML Launch, a cross-cloud scheduler, further enables running any AI jobs on any GPU cloud or on-premise cluster. Built on this library, TensorOpera AI (https://TensorOpera.ai) is your generative AI platform at scale.",3919,0.693,1.0,0.9,0.5,0.875,https://github.com/FedML-AI/FedML,Yes,
7,1B_2B,biniou,Woolverine94/biniou,a self-hosted webui for 30+ generative ai,607,0.677,0.667,0.5,0.571,0.972,https://github.com/Woolverine94/biniou,Yes,
8,1B_2B,parlant,emcie-co/parlant,LLM agents built for control. Designed for real-world use. Deployed in minutes.,7408,0.673,0.667,0.2,0.667,1.0,https://github.com/emcie-co/parlant,Yes,
9,1B_2B,ServerlessLLM,ServerlessLLM/ServerlessLLM,Serverless LLM Serving for Everyone.,520,0.67,0.667,0.6,0.5,1.0,https://github.com/ServerlessLLM/ServerlessLLM,Yes,
10,1B_2B,trulens,truera/trulens,Evaluation and Tracking for LLM Experiments and AI Agents,2727,0.667,0.5,1.0,0.333,1.0,https://github.com/truera/trulens,Yes,
11,1B_2B,swirl-search,swirlai/swirl-search,"AI Search & RAG Without Moving Your Data. Get instant answers from your company's knowledge across 100+ apps while keeping data secure. Deploy in minutes, not months.",2878,0.643,0.5,1.0,0.286,1.0,https://github.com/swirlai/swirl-search,Yes,
12,1B_2B,BentoML,bentoml/BentoML,"The easiest way to serve AI apps and models - Build Model Inference APIs, Job queues, LLM apps, Multi-model pipelines, and more!",8004,0.643,0.833,0.6,0.5,0.909,https://github.com/bentoml/BentoML,Yes,
13,1B_2B,LitServe,Lightning-AI/LitServe,"The easiest way to deploy agents, MCP servers, models, RAG, pipelines and more. No MLOps. No YAML.",3513,0.634,1.0,0.3,0.667,0.803,https://github.com/Lightning-AI/LitServe,Yes,
14,1B_2B,nix-fast-build,Mic92/nix-fast-build,Combine the power of nix-eval-jobs with nix-output-monitor to speed-up your evaluation and building process.,379,0.627,0.667,0.8,0.333,1.0,https://github.com/Mic92/nix-fast-build,Yes,
15,1B_2B,OmniQuant,OpenGVLab/OmniQuant,[ICLR2024 spotlight] OmniQuant is a simple and powerful quantization technique for LLMs. ,842,0.594,0.833,0.4,0.429,1.0,https://github.com/OpenGVLab/OmniQuant,Yes,
16,1B_2B,luigi,spotify/luigi,"Luigi is a Python module that helps you build complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization etc. It also comes with Hadoop support built in. ",18444,0.583,0.667,1.0,0.167,1.0,https://github.com/spotify/luigi,Yes,
17,1B_2B,Kiln,Kiln-AI/Kiln,"The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.",4063,0.563,0.5,0.9,0.167,1.0,https://github.com/Kiln-AI/Kiln,Yes,
18,1B_2B,ChatterBot,gunthercox/ChatterBot,"ChatterBot is a machine learning, conversational dialog engine for creating chat bots",14397,0.563,0.667,0.6,0.286,1.0,https://github.com/gunthercox/ChatterBot,Yes,
19,1B_2B,ComfyUI-Florence2,kijai/ComfyUI-Florence2,Inference Microsoft Florence2 VLM,1390,0.554,0.667,0.2,0.429,1.0,https://github.com/kijai/ComfyUI-Florence2,Yes,
20,1B_2B,ComfyUI-IF_AI_tools,if-ai/ComfyUI-IF_AI_tools,ComfyUI-IF_AI_tools is a set of custom nodes for ComfyUI that allows you to generate prompts using a local Large Language Model (LLM) via Ollama. This tool enables you to enhance your image generation workflow by leveraging the power of language models.,669,0.551,0.5,0.9,0.143,1.0,https://github.com/if-ai/ComfyUI-IF_AI_tools,Yes,
1,1B_2C,ragbuilder,KruxAI/ragbuilder,A toolkit to create optimal Production-readyRetrieval Augmented Generation(RAG) setup for your data,1465,0.917,1.0,1.0,0.833,1.0,https://github.com/KruxAI/ragbuilder,Yes,
2,1B_2C,restai,apocas/restai,"RESTai is an AIaaS (AI as a Service) open-source platform. Built on top of LlamaIndex & Langchain. Supports any public LLM supported by LlamaIndex and any local LLM suported by Ollama/vLLM/etc. Precise embeddings usage and tuning. Built-in image generation (Dall-E, SD, Flux) and dynamic loading generators.",430,0.917,0.833,1.0,0.833,1.0,https://github.com/apocas/restai,Yes,
3,1B_2C,RAGatouille,AnswerDotAI/RAGatouille,"Easily use and train state of the art late-interaction retrieval methods (ColBERT) in any RAG pipeline. Designed for modularity and ease-of-use, backed by research.",3643,0.833,1.0,1.0,0.667,1.0,https://github.com/AnswerDotAI/RAGatouille,Yes,
4,1B_2C,chat-with-your-data-solution-accelerator,Azure-Samples/chat-with-your-data-solution-accelerator,"A Solution Accelerator for the RAG pattern running in Azure, using Azure AI Search for retrieval and Azure OpenAI large language models to power ChatGPT-style and Q&A experiences. This includes most common requirements and best practices.",1095,0.793,0.667,0.8,0.667,1.0,https://github.com/Azure-Samples/chat-with-your-data-solution-accelerator,Yes,
5,1B_2C,FlagEmbedding,FlagOpen/FlagEmbedding,Retrieval and Retrieval-augmented LLMs,10395,0.786,0.833,1.0,0.571,1.0,https://github.com/FlagOpen/FlagEmbedding,Yes,
6,1B_2C,raggenie,sirocco-ventures/raggenie,"RAGGENIE: An open-source, low-code platform to build custom Retrieval-Augmented Generation (RAG) Copilets with your own data. Simplify AI development with ease!",174,0.75,0.667,1.0,0.5,1.0,https://github.com/sirocco-ventures/raggenie,Yes,
7,1B_2C,DemoGPT,melih-unsal/DemoGPT,"ğŸ¤– Everything you need to create an LLM Agentâ€”tools, prompts, frameworks, and modelsâ€”all in one place.",1861,0.73,0.833,0.9,0.5,1.0,https://github.com/melih-unsal/DemoGPT,Yes,
8,1B_2C,MaxKB,1Panel-dev/MaxKB,ğŸ”¥ MaxKB is an open-source platform for building enterprise-grade agents.  MaxKB æ˜¯å¼ºå¤§æ˜“ç”¨çš„å¼€æºä¼ä¸šçº§æ™ºèƒ½ä½“å¹³å°ã€‚,17815,0.72,0.833,0.7,0.6,0.932,https://github.com/1Panel-dev/MaxKB,Yes,
9,1B_2C,langflow,langflow-ai/langflow,Langflow is a powerful tool for building and deploying AI-powered agents and workflows.,104868,0.713,0.5,0.4,0.667,1.0,https://github.com/langflow-ai/langflow,Yes,
10,1B_2C,vec2text,vec2text/vec2text,utilities for decoding deep representations (like sentence embeddings) back to text,930,0.673,0.833,0.2,0.667,1.0,https://github.com/vec2text/vec2text,Yes,
11,1B_2C,Verba,weaviate/Verba,Retrieval Augmented Generation (RAG) chatbot powered by Weaviate,7267,0.67,0.833,0.6,0.5,1.0,https://github.com/weaviate/Verba,Yes,
12,1B_2C,ragstack-ai,datastax/ragstack-ai,RAGStack is an out of the box solution simplifying Retrieval Augmented Generation (RAG) in AI apps.,183,0.667,1.0,1.0,0.333,1.0,https://github.com/datastax/ragstack-ai,Yes,
13,1B_2C,raglite,superlinear-ai/raglite,ğŸ¥¤ RAGLite is a Python toolkit for Retrieval-Augmented Generation (RAG) with DuckDB or PostgreSQL,1056,0.667,0.833,1.0,0.333,1.0,https://github.com/superlinear-ai/raglite,Yes,
14,1B_2C,haystack,deepset-ai/haystack,"AI orchestration framework to build customizable, production-ready LLM applications. Connect components (models, vector DBs, file converters) to pipelines or agents that can interact with your data. With advanced retrieval methods, it's best suited for building RAG, question answering, semantic search or conversational agent chatbots.",21981,0.667,0.667,1.0,0.333,1.0,https://github.com/deepset-ai/haystack,Yes,
15,1B_2C,graphiti,getzep/graphiti,Build Real-Time Knowledge Graphs for AI Agents,17193,0.647,0.833,0.4,0.6,0.89,https://github.com/getzep/graphiti,Yes,
16,1B_2C,pixeltable,pixeltable/pixeltable,"Pixeltable â€” AI Data infrastructure providing a declarative, incremental approach for multimodal workloads.",741,0.61,0.667,0.3,0.5,1.0,https://github.com/pixeltable/pixeltable,Yes,
17,1B_2C,ChuanhuChatGPT,GaiZhenbiao/ChuanhuChatGPT,"GUI for ChatGPT API and many LLMs. Supports agents, file-based QA, GPT finetuning and query with web search. All with a neat UI.",15437,0.589,0.833,0.6,0.667,0.454,https://github.com/GaiZhenbiao/ChuanhuChatGPT,Yes,
18,1B_2C,AdalFlow,SylphAI-Inc/AdalFlow,AdalFlow: The library to build & auto-optimize LLM applications.,3584,0.571,0.833,0.8,0.429,0.656,https://github.com/SylphAI-Inc/AdalFlow,Yes,
19,1B_2C,LazyLLM,LazyAGI/LazyLLM,Easiest and laziest way for  building multi-agent LLMs applications.,2460,0.565,0.833,1.0,0.333,0.66,https://github.com/LazyAGI/LazyLLM,Yes,
20,1B_2C,localGPT,PromtEngineer/localGPT,Chat with your documents on your local device using GPT models. No data leaves your device and 100% private. ,21802,0.534,0.833,0.1,0.429,1.0,https://github.com/PromtEngineer/localGPT,Yes,
1,1B_2D,CrewAI-Studio,strnad/CrewAI-Studio,"A user-friendly, multi-platform GUI for managing and running CrewAI agents and tasks. Supports Conda and virtual environments, no coding needed. ",977,0.9,1.0,1.0,0.8,1.0,https://github.com/strnad/CrewAI-Studio,Yes,
2,1B_2D,gpt-all-star,kyaukyuai/gpt-all-star,ğŸ¤– AI-powered code generation tool for scratch development of web applications with a team collaboration of autonomous AI agents.,199,0.837,0.833,0.6,0.833,1.0,https://github.com/kyaukyuai/gpt-all-star,Yes,
3,1B_2D,gptme,gptme/gptme,"Your agent in your terminal, equipped with local tools: writes code, uses the terminal, browses the web, vision.",3971,0.828,0.833,1.0,0.667,0.984,https://github.com/gptme/gptme,Yes,
4,1B_2D,crewAI-tools,crewAIInc/crewAI-tools,Extend the capabilities of your CrewAI agents with Tools,1214,0.8,1.0,1.0,0.6,1.0,https://github.com/crewAIInc/crewAI-tools,Yes,
5,1B_2D,agent-service-toolkit,JoshuaC215/agent-service-toolkit,"Full toolkit for running an AI agent service built with LangGraph, FastAPI and Streamlit",3477,0.797,0.833,0.4,0.833,1.0,https://github.com/JoshuaC215/agent-service-toolkit,Yes,
6,1B_2D,fastagency,ag2ai/fastagency,The fastest way to bring multi-agent workflows to production.,506,0.793,0.833,0.8,0.667,1.0,https://github.com/ag2ai/fastagency,Yes,
7,1B_2D,AutoAgents,Link-AGI/AutoAgents,[IJCAI 2024] Generate different roles for GPTs to form a collaborative entity for complex tasks.,1400,0.705,0.833,0.1,0.833,0.896,https://github.com/Link-AGI/AutoAgents,Yes,
8,1B_2D,khoj,khoj-ai/khoj,"Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free.",30783,0.694,0.667,0.6,0.833,0.524,https://github.com/khoj-ai/khoj,Yes,
9,1B_2D,gpt_academic,binary-husky/gpt_academic,"ä¸ºGPT/GLMç­‰LLMå¤§è¯­è¨€æ¨¡å‹æä¾›å®ç”¨åŒ–äº¤äº’æ¥å£ï¼Œç‰¹åˆ«ä¼˜åŒ–è®ºæ–‡é˜…è¯»/æ¶¦è‰²/å†™ä½œä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®&å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒPythonå’ŒC++ç­‰é¡¹ç›®å‰–æ&è‡ªè¯‘è§£åŠŸèƒ½ï¼ŒPDF/LaTexè®ºæ–‡ç¿»è¯‘&æ€»ç»“åŠŸèƒ½ï¼Œæ”¯æŒå¹¶è¡Œé—®è¯¢å¤šç§LLMæ¨¡å‹ï¼Œæ”¯æŒchatglm3ç­‰æœ¬åœ°æ¨¡å‹ã€‚æ¥å…¥é€šä¹‰åƒé—®, deepseekcoder, è®¯é£æ˜Ÿç«, æ–‡å¿ƒä¸€è¨€, llama2, rwkv, claude2, mossç­‰ã€‚",69156,0.633,0.5,0.0,0.667,1.0,https://github.com/binary-husky/gpt_academic,Yes,
10,1B_2D,agentscope,agentscope-ai/agentscope,Start building LLM-empowered multi-agent applications in an easier way.,7748,0.62,0.833,0.6,0.4,1.0,https://github.com/agentscope-ai/agentscope,Yes,
11,1B_2D,avatar,zou-group/avatar,(NeurIPS 2024) AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning ,220,0.603,0.667,0.4,0.667,0.632,https://github.com/zou-group/avatar,Yes,
12,1B_2D,parllama,paulrobello/parllama,TUI for Ollama and other LLM providers,361,0.593,0.833,0.6,0.667,0.464,https://github.com/paulrobello/parllama,Yes,
13,1B_2D,vision-agent,landing-ai/vision-agent,Vision agent,5013,0.59,1.0,0.2,0.5,1.0,https://github.com/landing-ai/vision-agent,Yes,
14,1B_2D,hera,argoproj-labs/hera,Hera makes Python code easy to orchestrate on Argo Workflows through native Python integrations. It lets you construct and submit your Workflows entirely in Python. â­ï¸ Remember to star!,762,0.583,0.833,1.0,0.167,1.0,https://github.com/argoproj-labs/hera,Yes,
15,1B_2D,Open-LLM-VTuber,Open-LLM-VTuber/Open-LLM-VTuber,"Talk to any LLM with hands-free voice interaction, voice interruption, and Live2D taking face running locally across platforms",4294,0.562,0.833,0.2,0.667,0.629,https://github.com/Open-LLM-VTuber/Open-LLM-VTuber,Yes,
16,1B_2D,SWE-agent,SWE-agent/SWE-agent,"SWE-agent takes a GitHub issue and tries to automatically fix it, using your LM of choice. It can also be employed for offensive cybersecurity or competitive coding challenges. [NeurIPS 2024] ",17099,0.547,0.667,0.4,0.333,1.0,https://github.com/SWE-agent/SWE-agent,Yes,
17,1B_2D,Agently,AgentEra/Agently,[GenAI Application Development Framework]  ğŸš€ Build GenAI application quick and easy ğŸ’¬ Easy to interact with GenAI agent in code using structure data and chained-calls syntax ğŸ§© Use Agently Workflow to manage complex GenAI working logic ğŸ”€ Switch to any model without rewrite application code,1411,0.543,0.667,0.8,0.167,1.0,https://github.com/AgentEra/Agently,Yes,
18,1B_2D,covalent,AgnostiqHQ/covalent,Pythonic tool for orchestrating machine-learning/high performance/quantum-computing workflows in heterogeneous compute environments.,844,0.537,0.667,1.0,0.333,0.568,https://github.com/AgnostiqHQ/covalent,Yes,
19,1B_2D,Qwen-Agent,QwenLM/Qwen-Agent,"Agent framework and applications built upon Qwen>=3.0, featuring Function Calling, MCP, Code Interpreter, RAG, Chrome extension, etc.",11097,0.531,0.5,0.3,0.429,0.854,https://github.com/QwenLM/Qwen-Agent,Yes,
20,1B_2D,LangBot,langbot-app/LangBot,ğŸ¤© Easy-to-use global IM bot platform designed for the LLM era / ç®€å•æ˜“ç”¨çš„å¤§æ¨¡å‹å³æ—¶é€šä¿¡æœºå™¨äººå¼€å‘å¹³å° âš¡ï¸ Bots for QQ / QQé¢‘é“ / Discord / WeChatï¼ˆå¾®ä¿¡ï¼‰/ Telegram / é£ä¹¦ / é’‰é’‰ / Slack ğŸ§© Integrated with ChatGPTï¼ˆGPT)ã€DeepSeekã€Difyã€n8nã€Claudeã€Google Geminiã€xAIã€PPIOã€Ollamaã€é˜¿é‡Œäº‘ç™¾ç‚¼ã€SiliconFlowã€Qwenã€Moonshot(Kimi K2)ã€SillyTravenã€MCPã€WeClone etc. LLM & Agent & RAG,13114,0.529,0.667,0.6,0.667,0.252,https://github.com/langbot-app/LangBot,Yes,
