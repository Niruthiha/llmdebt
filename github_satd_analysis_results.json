[
  {
    "issue_number": 324,
    "repo_name": "SeldonIO/MLServer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"we could add support for binary data in payloads for http requests\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"could add support\",\n    \"similarly to what Triton server supports\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SeldonIO/MLServer/issues/324",
    "repo_size": 145,
    "size_category": "medium"
  },
  {
    "issue_number": 18122,
    "repo_name": "PrefectHQ/prefect",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Prefect event webhooks do not support Azure Event Grid\u2019s subscription validation handshake.\",\n    \"As a result, Prefect cannot receive events directly from Azure Event Grid.\",\n    \"Currently, users must build and maintain additional cloud functions or webhook relays solely to handle Event Grid\u2019s validation handshake.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"do not support\",\n    \"cannot receive\",\n    \"must build and maintain\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/prefect/issues/18122",
    "repo_size": 289,
    "size_category": "large"
  },
  {
    "issue_number": 933,
    "repo_name": "InternLM/xtuner",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u8bcd\u8868\u957f\u5ea6\u4e0d\u4e00\u81f4\",\n    \"\u663e\u793atensor 'token_embd.weight' has wrong shape; expected 6144, 92550, got 6144, 92544\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u51fa\u73b0\u4e86\",\n    \"\u663e\u793a\",\n    \"\u957f\u5ea6\u4e0d\u4e00\u81f4\",\n    \"\u8bf7\u95ee\u600e\u4e48\u529e\uff1f\"\n  ]\n}\n```",
    "issue_url": "https://github.com/InternLM/xtuner/issues/933",
    "repo_size": 344,
    "size_category": "large"
  },
  {
    "issue_number": 1458,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u6d41\u5f0f\u8f93\u5165\u6709\u6982\u7387\u5728\u751f\u6210\u97f3\u9891\u91cc\u9762\u76f4\u63a5\u590d\u5236\u539f\u59cbprompt\u97f3\u9891\u91cc\u9762\u7684\u90e8\u5206\u6bb5\uff0c\u975e\u6d41\u5f0f\u8f93\u5165\u5219\u4e0d\u4f1a\u51fa\u73b0\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u6709\u6982\u7387\",\n    \"\u76f4\u63a5\u590d\u5236\",\n    \"\u4e0d\u4f1a\u51fa\u73b0\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/1458",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 926,
    "repo_name": "neuml/txtai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"should be updated to limit the number of translation pipelines created\",\n    \"current test is raising HTTP 429 tests with the `list_models` call\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"should be updated\",\n    \"current test is raising\",\n    \"workaround\"\n  ]\n}\n```",
    "issue_url": "https://github.com/neuml/txtai/issues/926",
    "repo_size": 252,
    "size_category": "large"
  },
  {
    "issue_number": 7311,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Dropping the following result as it does not have all the necessary fields\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"does not have all the necessary fields\"\n  ]\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/7311",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 1512,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It primarily describes a compatibility problem without indicating any known debt or plans for future improvement.\"\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/1512",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 3829,
    "repo_name": "huggingface/trl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The current RLOO trainer implementation has significant memory inefficiency when handling multiple generations per prompt.\",\n    \"This implementation physically duplicates prompt tokens in GPU memory, creating exponential memory issues(>rloo_k=4).\",\n    \"The RLOO trainer uses inefficient token-level duplication in its core generation logic.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"significant memory inefficiency\",\n    \"inefficient token-level duplication\",\n    \"exponential memory issues\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/trl/issues/3829",
    "repo_size": 239,
    "size_category": "large"
  },
  {
    "issue_number": 3619,
    "repo_name": "zenml-io/zenml",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It primarily describes a bug related to Docker image manifest digest retrieval without indicating any underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/zenml-io/zenml/issues/3619",
    "repo_size": 83,
    "size_category": "medium"
  },
  {
    "issue_number": 1287,
    "repo_name": "h2oai/h2ogpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Fontconfig error: Cannot load default config file: No such file: (null)\",\n    \"cannot create /Annot for kind: 4\"\n  ],\n  \"WHO_ADMITS\": \"issue author (@pseudotensor)\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"error\",\n    \"cannot load\",\n    \"no such file\",\n    \"cannot create\"\n  ]\n}\n```",
    "issue_url": "https://github.com/h2oai/h2ogpt/issues/1287",
    "repo_size": 299,
    "size_category": "large"
  },
  {
    "issue_number": 1825,
    "repo_name": "mem0ai/mem0",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue discusses the introduction of Pinecone as a vector database for the MEM0 project, focusing on its benefits and motivation without acknowledging any suboptimal solutions, limitations, or technical shortcuts.\"\n}\n```",
    "issue_url": "https://github.com/mem0ai/mem0/issues/1825",
    "repo_size": 283,
    "size_category": "large"
  },
  {
    "issue_number": 104,
    "repo_name": "weaviate/Verba",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I'm poking through the codebase and made sure my .env.example was set and renamed.\",\n    \"not sure if it's helpful as I'm not super familiar with the codebase yet.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I'm poking through the codebase\",\n    \"not sure if it's helpful\",\n    \"not super familiar with the codebase yet\"\n  ]\n}\n```",
    "issue_url": "https://github.com/weaviate/Verba/issues/104",
    "repo_size": 243,
    "size_category": "large"
  },
  {
    "issue_number": 1158,
    "repo_name": "FlagOpen/FlagEmbedding",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"this might be a toy run\",\n    \"there are no in-context examples\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"this might be a toy run\",\n    \"no icl pairs will ever be added to the prompt\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FlagOpen/FlagEmbedding/issues/1158",
    "repo_size": 371,
    "size_category": "large"
  },
  {
    "issue_number": 150,
    "repo_name": "potpie-ai/potpie",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"search indexes are not being copied\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"When someone tries to\",\n    \"are not being copied\"\n  ]\n}\n```",
    "issue_url": "https://github.com/potpie-ai/potpie/issues/150",
    "repo_size": 64,
    "size_category": "medium"
  },
  {
    "issue_number": 120,
    "repo_name": "pydantic/logfire",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the implementation for this may not be that easy\",\n    \"Datadog installs some kind of additional binary and a handler that wraps the default Lambda handler to make this work\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"may not be that easy\",\n    \"some kind of additional binary\",\n    \"wraps the default Lambda handler\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pydantic/logfire/issues/120",
    "repo_size": 202,
    "size_category": "large"
  },
  {
    "issue_number": 1483,
    "repo_name": "ModelCloud/GPTQModel",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It is a request for information on how to prepare a calibration dataset, without indicating any awareness of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/ModelCloud/GPTQModel/issues/1483",
    "repo_size": 123,
    "size_category": "medium"
  },
  {
    "issue_number": 1780,
    "repo_name": "FoundationAgents/MetaGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"to run the example app of hello_world.py with the llm config of ollama encounter the exception when json.loads the response\",\n    \"Exception has occurred: JSONDecodeError\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"encounter the exception\",\n    \"JSONDecodeError\",\n    \"suboptimal solutions or temporary fixes\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FoundationAgents/MetaGPT/issues/1780",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 2674,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"BetterTransformer requires transformers<4.49 but found 4.53.3.\",\n    \"`optimum.bettertransformer` is deprecated and will be removed in optimum v2.0.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"requires\",\n    \"but found\",\n    \"is deprecated\",\n    \"will be removed\"\n  ]\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/2674",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 77,
    "repo_name": "weaviate/Verba",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"what if I forget how I ingested my documents 2 months ago\",\n    \"the results will not be accurate\",\n    \"we should provide that in the UI\",\n    \"we are in need of a Profile setting where the user can save its configuration\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"what if\",\n    \"we should provide\",\n    \"we are in need of\"\n  ]\n}\n```",
    "issue_url": "https://github.com/weaviate/Verba/issues/77",
    "repo_size": 243,
    "size_category": "large"
  },
  {
    "issue_number": 18657,
    "repo_name": "PrefectHQ/prefect",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently, it's not clear on how to contribute examples to Prefect.\",\n    \"On our docs there is not clear guidance on the expected structure, formatting, and review process.\",\n    \"This makes it difficult for contributors to add new examples.\",\n    \"It doesn't directly state the criteria and process to submit examples of Prefect patterns that may be useful for users.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"documentation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"it's not clear\",\n    \"there is not clear guidance\",\n    \"makes it difficult\",\n    \"doesn't directly state\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/prefect/issues/18657",
    "repo_size": 289,
    "size_category": "large"
  },
  {
    "issue_number": 2772,
    "repo_name": "letta-ai/letta",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I had to figure out how to reach the agents endpoints, etc.\",\n    \"I can not define/test my agents with my local defined models.\",\n    \"Letta app should either remember last one or allow removal of the default 'localhost' server, as it always defaults to that even if another (url based) local server is defined, and can not be removed.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration, design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I had to figure out\",\n    \"I can not define/test\",\n    \"should either remember last one or allow removal\",\n    \"defaults to that even if another (url based) local server is defined\"\n  ]\n}\n```",
    "issue_url": "https://github.com/letta-ai/letta/issues/2772",
    "repo_size": 134,
    "size_category": "medium"
  },
  {
    "issue_number": 331,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Make tests run faster - currently it takes 10-15min to run the test suite.\",\n    \"The error messages of the doctests that run for the metrics (measurements/comparisons) are hard to read. It would be great if we could improve that.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": [\n    \"performance\",\n    \"implementation\"\n  ],\n  \"LANGUAGE_PATTERNS\": [\n    \"currently it takes\",\n    \"hard to read\",\n    \"it would be great if we could improve that\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/331",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 3157,
    "repo_name": "huggingface/trl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Everything was working, including with vLLM, before updating to the latest release.\",\n    \"The server gets to the following but then infinitely blocks.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Everything was working, including with vLLM, before updating to the latest release.\",\n    \"infinitely blocks\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/trl/issues/3157",
    "repo_size": 239,
    "size_category": "large"
  },
  {
    "issue_number": 870,
    "repo_name": "AgentOps-AI/agentops",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Going through the docs is really annoying because of integrations extending over multiple pages.\",\n    \"I suggest we enclose integrations in a single table, back-linking to their respective docs, to keep the doc reader-friendly and simple.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"really annoying\",\n    \"suggest we enclose\",\n    \"to keep the doc reader-friendly and simple\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AgentOps-AI/agentops/issues/870",
    "repo_size": 139,
    "size_category": "medium"
  },
  {
    "issue_number": 57,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, or known limitations. The author is seeking additional information rather than admitting to any technical debt.\"\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/57",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 16504,
    "repo_name": "open-webui/open-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Not sure if this is related to the changes to /v1 API handling?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Not sure if this is related to\",\n    \"changes to /v1 API handling\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-webui/open-webui/issues/16504",
    "repo_size": 332,
    "size_category": "large"
  },
  {
    "issue_number": 246,
    "repo_name": "bigcode-project/bigcode-evaluation-harness",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"However, when I use this code base, I get 51.6 for Llama3-8B-Instruct and 45.4 for Llama3-8B base.\",\n    \"Strangely, I was managed to reproduce the greedy decoding pass@1 score for HumanEval.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I found that in the diagram\",\n    \"However, when I use this code base\",\n    \"Strangely, I was managed to reproduce\"\n  ]\n}\n```",
    "issue_url": "https://github.com/bigcode-project/bigcode-evaluation-harness/issues/246",
    "repo_size": 159,
    "size_category": "medium"
  },
  {
    "issue_number": 2706,
    "repo_name": "letta-ai/letta",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"TypeError: compile() arg 1 must be a string, bytes or AST object\",\n    \"Error executing function web_search: TypeError: compile() arg 1 must be a string, bytes or AST object\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"encountering a TypeError\",\n    \"preventing the tool from functioning\",\n    \"specific error message observed\",\n    \"Error executing function\"\n  ]\n}\n```",
    "issue_url": "https://github.com/letta-ai/letta/issues/2706",
    "repo_size": 134,
    "size_category": "medium"
  },
  {
    "issue_number": 938,
    "repo_name": "pydantic/logfire",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I can't find any function that allow me to change the format\",\n    \"I want the console log to be the same as default loguru\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I can't find\",\n    \"I want\",\n    \"I want the console log to be the same\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pydantic/logfire/issues/938",
    "repo_size": 202,
    "size_category": "large"
  },
  {
    "issue_number": 105,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, temporary fixes, or known limitations. It simply reports a bug related to a URL error without indicating any awareness of technical debt or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/105",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 686,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It primarily reports a bug related to encoding without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/686",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 320,
    "repo_name": "weaviate/Verba",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply inquires about the existence of a roadmap and plans for future support, without indicating any known issues or debts.\"\n}\n```",
    "issue_url": "https://github.com/weaviate/Verba/issues/320",
    "repo_size": 243,
    "size_category": "large"
  },
  {
    "issue_number": 880,
    "repo_name": "microsoft/RD-Agent",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue is a straightforward request to update a QR code without any acknowledgment of suboptimal solutions, limitations, or technical debt.\"\n}\n```",
    "issue_url": "https://github.com/microsoft/RD-Agent/issues/880",
    "repo_size": 61,
    "size_category": "medium"
  },
  {
    "issue_number": 1243,
    "repo_name": "confident-ai/deepeval",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"when set the local succeed\",\n    \"But when use the DeepEval test , still the OpenAI Key ?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"when set the local succeed\",\n    \"still the OpenAI Key\"\n  ]\n}\n```",
    "issue_url": "https://github.com/confident-ai/deepeval/issues/1243",
    "repo_size": 223,
    "size_category": "large"
  },
  {
    "issue_number": 16723,
    "repo_name": "open-webui/open-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It should get the current changes from db without refreshing ui manuelly.\",\n    \"When I create or update a chat using the API, the result is not reflected in the currently open OpenWebUI session. I have to manually refresh the interface to see the changes.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"should get the current changes\",\n    \"not reflected in the currently open OpenWebUI session\",\n    \"have to manually refresh\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-webui/open-webui/issues/16723",
    "repo_size": 332,
    "size_category": "large"
  },
  {
    "issue_number": 2310,
    "repo_name": "livekit/agents",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"there can be more simple and more resource thoughtful way of recording audio\",\n    \"diarization still works pretty bad\",\n    \"this is what stopping us from complete switch from Retell to LiveKit agents\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance, implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"there can be more simple and more resource thoughtful way\",\n    \"should be option\",\n    \"still works pretty bad\",\n    \"this is what stopping us\"\n  ]\n}\n```",
    "issue_url": "https://github.com/livekit/agents/issues/2310",
    "repo_size": 297,
    "size_category": "large"
  },
  {
    "issue_number": 8810,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"no matter how I change these two paras(ray_num_workers and GPU) it still shows OOM problem\",\n    \"If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"shows OOM problem\",\n    \"no matter how I change\",\n    \"try setting PYTORCH_CUDA_ALLOC_CONF\"\n  ]\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/8810",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 126,
    "repo_name": "qwersyk/Newelle",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue discusses the potential benefits of using Llama.cpp with Vulkan support but does not acknowledge any suboptimal solutions, limitations, or technical shortcuts. It focuses on the advantages of GPU acceleration and ease of integration without indicating any existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/qwersyk/Newelle/issues/126",
    "repo_size": 133,
    "size_category": "medium"
  },
  {
    "issue_number": 2413,
    "repo_name": "pytorch/torchtune",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"As a starting point, we could implement just a pairwise judge that could be useful with techniques like Online DPO\",\n    \"Please let me know if you have feedback on this approach or if there could be other more useful abstractions to make this something torchtune would want to integrate.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"As a starting point\",\n    \"could be useful\",\n    \"let me know if you have feedback\",\n    \"if there could be other more useful abstractions\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pytorch/torchtune/issues/2413",
    "repo_size": 237,
    "size_category": "large"
  },
  {
    "issue_number": 18601,
    "repo_name": "PrefectHQ/prefect",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the retried second processing subflow is incorrectly given the parameters for A instead of C\",\n    \"this causes the parent flow run to complete successfully on retry eventhough some failed subflows were not actually retried\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"incorrectly given the parameters\",\n    \"causes the parent flow run to complete successfully on retry eventhough some failed subflows were not actually retried\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/prefect/issues/18601",
    "repo_size": 289,
    "size_category": "large"
  },
  {
    "issue_number": 3086,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"But, following error still hasn't been resolved.\",\n    \"# The larger, the higher the accuracy, but might overfit\",\n    \"# Optional now! Can specify a list if needed\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": [\n    \"implementation\",\n    \"performance\"\n  ],\n  \"LANGUAGE_PATTERNS\": [\n    \"still hasn't been resolved\",\n    \"might overfit\",\n    \"Optional now!\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/3086",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 8445,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u5728\u90e8\u7f72\u7684\u65f6\u5019\u6ca1\u6709\u4f7f\u7528\u5b98\u65b9\u7ed9\u7684\u811a\u672c \u800c\u662f\u76f4\u63a5\u4e0b\u8f7d\u7684docker-compose init-data.json searxng.yml\u548c.env\u6587\u4ef6\",\n    \"\u529f\u80fd\u6b63\u5e38 \u4f46\u662f\u5728\u77e5\u8bc6\u5e93\u529f\u80fd\u4e2d \u65b0\u4e0a\u4f20txt\u6587\u4ef6\u540e \u65e0\u6cd5\u5728\u7ebf\u9884\u89c8 \u62a5\u9519500 internal error\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u6ca1\u6709\u4f7f\u7528\u5b98\u65b9\u7ed9\u7684\u811a\u672c\",\n    \"\u529f\u80fd\u6b63\u5e38 \u4f46\u662f\u5728\u77e5\u8bc6\u5e93\u529f\u80fd\u4e2d \u65b0\u4e0a\u4f20txt\u6587\u4ef6\u540e \u65e0\u6cd5\u5728\u7ebf\u9884\u89c8\"\n  ]\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8445",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 3561,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I would like to have an option that allows AnythingLLM to auto-add all documents from a specified folder\",\n    \"This would work very similarly to 'Automatic document sync' (experimental feature)\",\n    \"I see that #1873 was closed 9 months ago, with others asking for the exact same thing.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I would like to have an option\",\n    \"This would work very similarly to\",\n    \"PLEASE reconsider.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/3561",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 1335,
    "repo_name": "stanford-crfm/helm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This does not match what I understand to be the core benchmarking run_specs.conf\",\n    \"Nor does it match the 10 subjects mentioned in the docstring for that section of the run_specs.conf\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"does not match\",\n    \"I understand to be\",\n    \"mentioned in\"\n  ]\n}\n```",
    "issue_url": "https://github.com/stanford-crfm/helm/issues/1335",
    "repo_size": 157,
    "size_category": "medium"
  },
  {
    "issue_number": 8308,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"version 07f7921 seems to save incorrect lora model when training\",\n    \"the 07 version model performs poorly\",\n    \"the training parameters are identical\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"seems to save incorrect\",\n    \"performs poorly\",\n    \"training parameters are identical\"\n  ]\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/8308",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 1891,
    "repo_name": "intel/neural-compressor",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Why is FP4_E2M1 like this?\",\n    \"How is 0.0625 computed?\",\n    \"shouldn't it be 0.5?\",\n    \"Is FP4_BNB the result of left shifting FP4_E2M1 one bit?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Why is ... like this?\",\n    \"How is ... computed?\",\n    \"shouldn't it be ...?\",\n    \"Is ... the result of ...?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/intel/neural-compressor/issues/1891",
    "repo_size": 50,
    "size_category": "medium"
  },
  {
    "issue_number": 218,
    "repo_name": "SWE-bench/SWE-bench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Looks like while installing dependencies, the package Cython conflicts with the installation.\",\n    \"Error building image sweb.eval.x86_64.scikit-learn__scikit-learn-25500:latest: The command '/bin/sh -c /bin/bash /root/setup_repo.sh' returned a non-zero code: 1\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Looks like while installing dependencies\",\n    \"conflicts with the installation\",\n    \"returned a non-zero code\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SWE-bench/SWE-bench/issues/218",
    "repo_size": 199,
    "size_category": "medium"
  },
  {
    "issue_number": 2646,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"WARNING:\",\n    \"can result in broken permissions and conflicting behaviour\",\n    \"recommended to use a virtual environment instead\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/2646",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 1273,
    "repo_name": "topoteretes/cognee",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"LLM Provider NOT provided. Pass in the LLM provider you are trying to call.\",\n    \"You passed model=<custom>/openai/gpt-oss-120b\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"NOT provided\",\n    \"Pass in the LLM provider\",\n    \"You passed model\"\n  ]\n}\n```",
    "issue_url": "https://github.com/topoteretes/cognee/issues/1273",
    "repo_size": 74,
    "size_category": "medium"
  },
  {
    "issue_number": 33,
    "repo_name": "existence-master/Sentient",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue presents a feature request without acknowledging any suboptimal solutions, limitations, or technical shortcuts. It focuses on a proposed solution rather than admitting to existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/existence-master/Sentient/issues/33",
    "repo_size": 37,
    "size_category": "small"
  },
  {
    "issue_number": 1735,
    "repo_name": "oumi-ai/oumi",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"One workaround I am going to try is to enable Tensorboard and examine the logs on the head node.\",\n    \"Still, I think it would be really useful to see the exact remote output so you know your job is doing okay.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"workaround\",\n    \"I am going to try\",\n    \"I think it would be really useful\"\n  ]\n}\n```",
    "issue_url": "https://github.com/oumi-ai/oumi/issues/1735",
    "repo_size": 46,
    "size_category": "small"
  },
  {
    "issue_number": 34,
    "repo_name": "huggingface/optimum-benchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"task specific evaluators\",\n    \"as I did it manually when I did whisper's benchmark\"\n  ],\n  \"WHO_ADMITS\": \"contributor\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"would it make sense to add\",\n    \"as I did it manually\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/optimum-benchmark/issues/34",
    "repo_size": 60,
    "size_category": "medium"
  },
  {
    "issue_number": 2749,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u5728\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\u65f6\u53d1\u73b0\u7684\",\n    \"\u6210\u529f\u7387\u4e0d\u8db3100\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u53d1\u73b0\u7684\",\n    \"\u4e0d\u8db3\"\n  ]\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/2749",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 480,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"datasets dropped python 3.7 support\",\n    \"this line won't work anymore\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"dropped support\",\n    \"won't work anymore\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/480",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 34,
    "repo_name": "llm-workflow-engine/llm-workflow-engine",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report describes a specific error encountered during installation but does not acknowledge any suboptimal solutions, known limitations, or technical shortcuts. It is a straightforward bug report without indications of technical debt.\"\n}\n```",
    "issue_url": "https://github.com/llm-workflow-engine/llm-workflow-engine/issues/34",
    "repo_size": 188,
    "size_category": "medium"
  },
  {
    "issue_number": 1211,
    "repo_name": "FoundationAgents/MetaGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"best approach in integrating the RAG module into Data Interpreter\",\n    \"without hindering the current architecture of the agent\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"best approach\",\n    \"without hindering\",\n    \"current architecture\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FoundationAgents/MetaGPT/issues/1211",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 99,
    "repo_name": "bhaskatripathi/pdfGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I think allowing it to be able to access freeGPT model will be highly beneficial considering that we won't be limited by the gpt api anymore\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I think\",\n    \"will be highly beneficial\",\n    \"we won't be limited\"\n  ]\n}\n```",
    "issue_url": "https://github.com/bhaskatripathi/pdfGPT/issues/99",
    "repo_size": 98,
    "size_category": "medium"
  },
  {
    "issue_number": 2850,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"ValueError: Can not map tensor 'model.layers.0.mlp.down_proj.weight.absmax'\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"ValueError: Can not map tensor\",\n    \"raise ValueError\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/2850",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 1690,
    "repo_name": "h2oai/h2ogpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"TypeError: 'NoneType' object is not iterable\",\n    \"Running without the base model option works fine\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"encountered an error during execution\",\n    \"the error originates from line\",\n    \"known limitations or problems they plan to address\"\n  ]\n}\n```",
    "issue_url": "https://github.com/h2oai/h2ogpt/issues/1690",
    "repo_size": 299,
    "size_category": "large"
  },
  {
    "issue_number": 80,
    "repo_name": "qdrant/vector-db-benchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the process pool starts to increase\",\n    \"the benchmark script becomes unresponsive and eventually times out\",\n    \"this issue might impact the benchmark result\",\n    \"the processes consume a significant amount of CPU time\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"noticed a process leak\",\n    \"might impact the benchmark result\",\n    \"becomes unresponsive\",\n    \"consume a significant amount of CPU time\"\n  ]\n}\n```",
    "issue_url": "https://github.com/qdrant/vector-db-benchmark/issues/80",
    "repo_size": 66,
    "size_category": "medium"
  },
  {
    "issue_number": 8623,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u5ba2\u6237\u7aef\u65e0\u6cd5\u8fde\u63a5\u81ea\u90e8\u7f72\u5b9e\u4f8b\",\n    \"\u5e0c\u671b\u5ba2\u6237\u7aef\u53ef\u6b63\u5e38\u8fde\u63a5\u81ea\u90e8\u7f72\u5b9e\u4f8b\",\n    \"\u5173\u95ed\u53cd\u4ee3\u7684HTTP2\u7684\u62a5\u9519\u5982\u4e0b\",\n    \"\u5f00\u542f\u53cd\u4ee3\u7684HTTP2\u7684\u62a5\u9519\u5982\u4e0b\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u65e0\u6cd5\u8fde\u63a5\",\n    \"\u5e0c\u671b...\u53ef\u6b63\u5e38\u8fde\u63a5\",\n    \"\u62a5\u9519\u5982\u4e0b\"\n  ]\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8623",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 1322,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, or known limitations. It primarily describes a bug without indicating any awareness of technical debt or plans to address it.\"\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/1322",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 226,
    "repo_name": "qwersyk/Newelle",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Missing close buttons in prompts dialog\",\n    \"start window decorations\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Missing\",\n    \"prompts dialog\",\n    \"start window decorations\"\n  ]\n}\n```",
    "issue_url": "https://github.com/qwersyk/Newelle/issues/226",
    "repo_size": 133,
    "size_category": "medium"
  },
  {
    "issue_number": 951,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"failed to import ttsfrd, use WeTextProcessing instead\",\n    \"Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: ''.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"failed to import\",\n    \"use WeTextProcessing instead\",\n    \"Repo id must use alphanumeric chars\",\n    \"forbidden\",\n    \"max length is 96\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/951",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 1660,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Has anyone ever faced similar issue?\",\n    \"Is it okay to ingest such amount of data?\",\n    \"Is it really possible to avoid SQLite restrictions?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Has anyone ever faced similar issue?\",\n    \"Is it okay to ingest such amount of data?\",\n    \"Is it really possible to avoid SQLite restrictions?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/1660",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 719,
    "repo_name": "InternLM/xtuner",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"KeyError: 'messages'\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"KeyError\",\n    \"The above exception was the direct cause of the following exception\"\n  ]\n}\n```",
    "issue_url": "https://github.com/InternLM/xtuner/issues/719",
    "repo_size": 344,
    "size_category": "large"
  },
  {
    "issue_number": 8050,
    "repo_name": "open-webui/open-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, or known limitations. It simply lists features with checkboxes indicating their status without any commentary on technical debt.\"\n}\n```",
    "issue_url": "https://github.com/open-webui/open-webui/issues/8050",
    "repo_size": 332,
    "size_category": "large"
  },
  {
    "issue_number": 117,
    "repo_name": "illuin-tech/vidore-benchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I ran the following script but got error.\",\n    \"I have successfully got the result of vidore/colpali-v1.3 using similar script structure.\",\n    \"size mismatch for bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1280]).\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"but got error\",\n    \"successfully got the result\",\n    \"size mismatch for bias\"\n  ]\n}\n```",
    "issue_url": "https://github.com/illuin-tech/vidore-benchmark/issues/117",
    "repo_size": 21,
    "size_category": "small"
  },
  {
    "issue_number": 1036,
    "repo_name": "Pacific-AI-Corp/langtest",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"underscores the need for ongoing refinement and rigorous testing to ensure medical LLM\u2019s accuracy and reliability\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"underscores the need for\",\n    \"ongoing refinement\",\n    \"rigorous testing\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Pacific-AI-Corp/langtest/issues/1036",
    "repo_size": 188,
    "size_category": "medium"
  },
  {
    "issue_number": 291,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Error when Indexing GraphRAG: 'Columns must be same length as key'\",\n    \"This can take a long time.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Error when Indexing\",\n    \"This can take a long time\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/291",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 290,
    "repo_name": "dbos-inc/dbos-transact-py",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Span creation is currently quite hidden\",\n    \"Expose this publicly so users can create spans\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"currently quite hidden\",\n    \"Expose this publicly\"\n  ]\n}\n```",
    "issue_url": "https://github.com/dbos-inc/dbos-transact-py/issues/290",
    "repo_size": 43,
    "size_category": "small"
  },
  {
    "issue_number": 2254,
    "repo_name": "zenml-io/zenml",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the process of building Docker images (or having them built by a cloud image builder) often lacks clear and informative log messages.\",\n    \"Users may find it challenging to understand when and why certain Docker builds are used or not used in their workflows.\",\n    \"Improve the logging mechanism in ZenML to provide clear and explicit messages about Docker build processes.\",\n    \"Enhanced logging will improve transparency and aid in troubleshooting and optimizing pipeline executions.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"lacks clear and informative log messages\",\n    \"may find it challenging to understand\",\n    \"improve the logging mechanism\",\n    \"enhanced logging will improve transparency\"\n  ]\n}\n```",
    "issue_url": "https://github.com/zenml-io/zenml/issues/2254",
    "repo_size": 83,
    "size_category": "medium"
  },
  {
    "issue_number": 709,
    "repo_name": "neuml/txtai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. The author is seeking clarification on a problem rather than admitting to any technical debt.\"\n}\n```",
    "issue_url": "https://github.com/neuml/txtai/issues/709",
    "repo_size": 252,
    "size_category": "large"
  },
  {
    "issue_number": 23878,
    "repo_name": "vllm-project/vllm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It primarily serves as a feature request without addressing any existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/vllm-project/vllm/issues/23878",
    "repo_size": 165,
    "size_category": "medium"
  },
  {
    "issue_number": 84,
    "repo_name": "microsoft/promptbench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Evaluate the sentiment of the given text and classify it as 'positive' or 'negative'\",\n    \"Given the context of this text, indicate if the emotion conveyed is 'positive' or 'negative'\",\n    \"Analyze the tone of this statement and respond with either 'positive' or 'negative'\",\n    \"In the role of a sentiment analysis tool, respond with 'positive' or 'negative' to classify this statement\",\n    \"Functioning as a sentiment identification tool, assess if the following expression is 'positive' or 'negative'\",\n    \"Serving as a sentiment evaluation model, determine if the given statement is 'positive' or 'negative'\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"original prompt\",\n    \"attacked prompt\",\n    \"score\",\n    \"PDR\"\n  ]\n}\n```",
    "issue_url": "https://github.com/microsoft/promptbench/issues/84",
    "repo_size": 63,
    "size_category": "medium"
  },
  {
    "issue_number": 39,
    "repo_name": "superlinear-ai/raglite",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently, hybrid search executes keyword search and vector search independently, and then combines the results of both with RRF.\",\n    \"This could be optimised by implementing a single SQL query that pushes all of this computation to the database.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Currently\",\n    \"could be optimised\",\n    \"independently\",\n    \"combines the results\",\n    \"pushes all of this computation\"\n  ]\n}\n```",
    "issue_url": "https://github.com/superlinear-ai/raglite/issues/39",
    "repo_size": 39,
    "size_category": "small"
  },
  {
    "issue_number": 72,
    "repo_name": "jekalmin/extended_openai_conversation",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"why not to go shortcut and use llama-cpp-python directly?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"shortcut\",\n    \"suboptimal solutions\",\n    \"temporary fixes\"\n  ]\n}\n```",
    "issue_url": "https://github.com/jekalmin/extended_openai_conversation/issues/72",
    "repo_size": 226,
    "size_category": "large"
  },
  {
    "issue_number": 2029,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, or known limitations. It primarily describes an error encountered during model saving without indicating any awareness of technical debt or plans to address it.\"\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/2029",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 43,
    "repo_name": "horseee/LLM-Pruner",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"401 Client Error: Unauthorized for url: https://huggingface.co/decapoda-research/llama-7b-hf/resolve/main/tokenizer_config.json\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Client Error: Unauthorized\",\n    \"Traceback (most recent call last)\",\n    \"raise HTTPError(http_error_msg, response=self)\"\n  ]\n}\n```",
    "issue_url": "https://github.com/horseee/LLM-Pruner/issues/43",
    "repo_size": 90,
    "size_category": "medium"
  },
  {
    "issue_number": 135,
    "repo_name": "AnswerDotAI/RAGatouille",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The number of returned top-k isn't always as specified\",\n    \"this is more the case for the fine-tuned version of colbert-v2\",\n    \"it's uncommon to have such a high top-k\",\n    \"this is helpful for me when benchmarking and making the function more predictable when used\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"isn't always as specified\",\n    \"this is more the case for\",\n    \"it's uncommon to have\",\n    \"this is helpful for me when benchmarking\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AnswerDotAI/RAGatouille/issues/135",
    "repo_size": 196,
    "size_category": "medium"
  },
  {
    "issue_number": 1807,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Parsing PDF takes forever\",\n    \"For a simple 497KB pdf it's already 186s / 30.9s and counting.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"takes forever\",\n    \"already 186s / 30.9s and counting\"\n  ]\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/1807",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 26,
    "repo_name": "seratch/ChatGPT-in-Slack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"We forked and implemented this ability for our own needs\",\n    \"Ideally we'd contribute back to this repo instead of maintaining a fork.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"forked and implemented\",\n    \"Ideally we'd contribute back\",\n    \"maintaining a fork\"\n  ]\n}\n```",
    "issue_url": "https://github.com/seratch/ChatGPT-in-Slack/issues/26",
    "repo_size": 53,
    "size_category": "medium"
  },
  {
    "issue_number": 2169,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"While deleting a few documents, it began to give errors.\",\n    \"Now when I reboot and restart the application I am getting the following errors:\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"began to give errors\",\n    \"getting the following errors\"\n  ]\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/2169",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 2338,
    "repo_name": "pytorch/torchtune",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"`seed: null` should generate random seed but launching same standard config with `seed: null` twice creates the same loss curve and metrics\",\n    \"May be caused by #2339\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"should generate random seed\",\n    \"creates the same loss curve and metrics\",\n    \"may be caused by\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pytorch/torchtune/issues/2338",
    "repo_size": 237,
    "size_category": "large"
  },
  {
    "issue_number": 2528,
    "repo_name": "livekit/agents",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I want to call either multi-user-transcribe agent or AI interview agent.\",\n    \"I didn't find any multi-agent reference based on condition & I don't want to add a redundant Agent to just orchestrate calling either agents.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I want to call either\",\n    \"I didn't find any\",\n    \"I don't want to add a redundant Agent\"\n  ]\n}\n```",
    "issue_url": "https://github.com/livekit/agents/issues/2528",
    "repo_size": 297,
    "size_category": "large"
  },
  {
    "issue_number": 3440,
    "repo_name": "zenml-io/zenml",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Your ZenML client version (0.75.1) does not match the server version (0.75.0). This version mismatch might lead to errors or unexpected behavior.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"version mismatch\",\n    \"might lead to errors or unexpected behavior\"\n  ]\n}\n```",
    "issue_url": "https://github.com/zenml-io/zenml/issues/3440",
    "repo_size": 83,
    "size_category": "medium"
  },
  {
    "issue_number": 1461,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"there's a monkey-patch to avoid this error and get it working, but seems very ugly.\",\n    \"a cleaner way to save the model (lora adapters) and load it for inference with the modified lm_head.\",\n    \"a native support for finetuning classification models would be great too if it's in the plans.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"monkey-patch\",\n    \"seems very ugly\",\n    \"cleaner way\",\n    \"native support for finetuning classification models would be great\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/1461",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 2689,
    "repo_name": "openaccess-ai-collective/axolotl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"We should transition our gc_steps to use that.\",\n    \"gc_steps also does a gc.collect() which transformers trainer doesn't do, so we should still support that.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"We should transition\",\n    \"we should still support\"\n  ]\n}\n```",
    "issue_url": "https://github.com/axolotl-ai-cloud/axolotl/issues/2689",
    "repo_size": 193,
    "size_category": "medium"
  },
  {
    "issue_number": 2727,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It primarily describes a specific error without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/2727",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 358,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It simply requests a configuration without indicating any awareness of potential problems or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/358",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 1177,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It simply describes a bug related to inputting Chinese characters in a specific environment without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/1177",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 1287,
    "repo_name": "FlagOpen/FlagEmbedding",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u6839\u636edebug\u65f6\uff0c\u67e5\u627e\u5230\u52a0\u8f7d\u6570\u636e\u96c6\u7684\u4ee3\u7801load_data\",\n    \"\u901a\u8fc7\u67e5\u770bload_dataset\u6e90\u7801\uff0c\u7ed3\u5408\u672c\u4eba\u7684\u7406\u89e3\u4fee\u6539\u7684evaluation.run()\u65b9\u6cd5\u4e2d\u7684\u53c2\u6570\",\n    \"\u6bd4\u5982\u672c\u4eba\u81ea\u5df1\u6dfb\u52a0\u4e86\u201cpath\u201d\u53c2\u6570\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u6839\u636edebug\u65f6\",\n    \"\u67e5\u627e\u5230\",\n    \"\u901a\u8fc7\u67e5\u770b\",\n    \"\u7ed3\u5408\u672c\u4eba\u7684\u7406\u89e3\",\n    \"\u4fee\u6539\u7684\",\n    \"\u81ea\u5df1\u6dfb\u52a0\u4e86\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FlagOpen/FlagEmbedding/issues/1287",
    "repo_size": 371,
    "size_category": "large"
  },
  {
    "issue_number": 8906,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The JSON format expected by LobeChat, specifically of the `arguments` key, does not match to the Ollama spec\",\n    \"On top of that, `id` and `type` are not present in Ollama output\",\n    \"Because of that, feature like Web search is not working (the tool is skipped)\"\n  ],\n  \"WHO_ADMITS\": \"Antoine (issue author)\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"does not match\",\n    \"not present\",\n    \"not working\",\n    \"the tool is skipped\"\n  ]\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8906",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 1181,
    "repo_name": "Pacific-AI-Corp/langtest",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"templatic augmentation issues with pydantic v1 basemodel.\",\n    \"UnboundLocalError: cannot access local variable 'additional_info' where it is not associated with a value\",\n    \"Backward Compatibility: Default model_type(chat, completion) for OpenAI and Azure-OpenAI\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"issues found\",\n    \"cannot access local variable\",\n    \"Backward Compatibility\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Pacific-AI-Corp/langtest/issues/1181",
    "repo_size": 188,
    "size_category": "medium"
  },
  {
    "issue_number": 2790,
    "repo_name": "embeddings-benchmark/mteb",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"we have a lot of printing when running tasks\",\n    \"I would like to rework printing such that it is both pleasant and considerate\",\n    \"Consider whether `logging.py` can be removed\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I would like to rework\",\n    \"Consider whether\",\n    \"we have a lot of\"\n  ]\n}\n```",
    "issue_url": "https://github.com/embeddings-benchmark/mteb/issues/2790",
    "repo_size": 301,
    "size_category": "large"
  },
  {
    "issue_number": 1746,
    "repo_name": "mosaicml/llm-foundry",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Using the `ConcatTokensDataset` from `data/data.py` means creating sharded datasets for each tokenizer which uses up a lot of disk space.\",\n    \"Using the `NoConcatTokensDataset` instead seems to solve the disk usage issue but leads to massively decreased throughput because the tokens are not concatenated while also degrading the training stability (perplexity goes all over the place instead of gradually decreasing.)\",\n    \"Is there a way to combine the best of both worlds, i.e. having a text streaming dataset that concatenates tokens within a sample during training?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"means creating sharded datasets for each tokenizer which uses up a lot of disk space\",\n    \"seems to solve the disk usage issue but leads to massively decreased throughput\",\n    \"degrading the training stability\",\n    \"perplexity goes all over the place instead of gradually decreasing\",\n    \"Is there a way to combine the best of both worlds\"\n  ]\n}\n```",
    "issue_url": "https://github.com/mosaicml/llm-foundry/issues/1746",
    "repo_size": 50,
    "size_category": "medium"
  },
  {
    "issue_number": 146,
    "repo_name": "browser-use/web-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"[Errno 111] Connection refused\",\n    \"I made the adjustment to the dockerfile as describe here\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I made the adjustment\",\n    \"Connection refused\",\n    \"How to debug/resolve this issue?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/browser-use/web-ui/issues/146",
    "repo_size": 353,
    "size_category": "large"
  },
  {
    "issue_number": 999,
    "repo_name": "GaiZhenbiao/ChuanhuChatGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u76ee\u524d\u5df2\u77e5\u53ea\u6709\u5728\u767b\u5f55\u72b6\u6001\u4e0b\u5b9e\u73b0\u804a\u5929\u8bb0\u5f55\u9694\u58c1\u3002\",\n    \"\u53ef\u662f\u73b0\u5728\u7684\u4f7f\u7528\u573a\u666f\u60f3\u5728\u4e0d\u767b\u9646\u7684\u72b6\u6001\u4e0b\u4e5f\u53ef\u4ee5\u5b9e\u73b0\u4fdd\u5b58\u5bf9\u8bdd\u7684\u8bb0\u5f55\uff0c\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u8bfb\u53d6\u6d4f\u89c8\u5668\u7f13\u5b58\u7684\u65b9\u5f0f\u5b9e\u73b0\u672a\u767b\u5f55\u72b6\u6001\u4e0b\u7684\u5bf9\u8bdd\u8bb0\u5f55\u9694\u79bb\uff1f\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u76ee\u524d\u5df2\u77e5\u53ea\u6709\",\n    \"\u60f3\u5728\u4e0d\u767b\u9646\u7684\u72b6\u6001\u4e0b\u4e5f\u53ef\u4ee5\u5b9e\u73b0\",\n    \"\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\"\n  ]\n}\n```",
    "issue_url": "https://github.com/GaiZhenbiao/ChuanhuChatGPT/issues/999",
    "repo_size": 305,
    "size_category": "large"
  },
  {
    "issue_number": 207,
    "repo_name": "llm-workflow-engine/llm-workflow-engine",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I'm not entirely sure how it would select the previous conversations\",\n    \"obviously each conversation would need a unique identifier\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I'm not entirely sure\",\n    \"obviously\"\n  ]\n}\n```",
    "issue_url": "https://github.com/llm-workflow-engine/llm-workflow-engine/issues/207",
    "repo_size": 188,
    "size_category": "medium"
  },
  {
    "issue_number": 165,
    "repo_name": "PKU-Alignment/safe-rlhf",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It is a straightforward question regarding disk space requirements for models based on llama-7b.\"\n}\n```",
    "issue_url": "https://github.com/PKU-Alignment/safe-rlhf/issues/165",
    "repo_size": 90,
    "size_category": "medium"
  },
  {
    "issue_number": 398,
    "repo_name": "SWE-bench/SWE-bench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Adding (1) setup scripts to image build repo\",\n    \"git reset --hard 5ec2bd279729ff534719b8bf238dbbca907b93c5\",\n    \"chmod -R 777 /testbed\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Adding (1) setup scripts to image build repo\",\n    \"git reset --hard\",\n    \"chmod -R 777\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SWE-bench/SWE-bench/issues/398",
    "repo_size": 199,
    "size_category": "medium"
  },
  {
    "issue_number": 237,
    "repo_name": "llm-workflow-engine/llm-workflow-engine",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply describes an error encountered while using the application without indicating any known issues or plans for improvement.\"\n}\n```",
    "issue_url": "https://github.com/llm-workflow-engine/llm-workflow-engine/issues/237",
    "repo_size": 188,
    "size_category": "medium"
  },
  {
    "issue_number": 88,
    "repo_name": "OSU-NLP-Group/HippoRAG",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Is it good way compatible with HippoRAG or should I change something?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Is it good way\",\n    \"should I change something\"\n  ]\n}\n```",
    "issue_url": "https://github.com/OSU-NLP-Group/HippoRAG/issues/88",
    "repo_size": 120,
    "size_category": "medium"
  },
  {
    "issue_number": 1834,
    "repo_name": "h2oai/h2ogpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. The user is reporting a problem without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/h2oai/h2ogpt/issues/1834",
    "repo_size": 299,
    "size_category": "large"
  },
  {
    "issue_number": 1397,
    "repo_name": "castorini/pyserini",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Link to `robust04` README is broken.\",\n    \"Might want to go through and make sure they all work...\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"broken\",\n    \"might want to\",\n    \"make sure\"\n  ]\n}\n```",
    "issue_url": "https://github.com/castorini/pyserini/issues/1397",
    "repo_size": 104,
    "size_category": "medium"
  },
  {
    "issue_number": 54,
    "repo_name": "NVIDIA/TensorRT-Model-Optimizer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I'm unsure how to integrate it with quant_nn.QuantConv\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"unsure how to integrate\"\n  ]\n}\n```",
    "issue_url": "https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/54",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 3292,
    "repo_name": "mem0ai/mem0",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"suboptimal solutions or temporary fixes\",\n    \"known limitations or problems they plan to address\",\n    \"technical shortcuts or workarounds\",\n    \"areas needing future improvement\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"just use the same Postgres instance\",\n    \"no need to instantiate/install another database\"\n  ]\n}\n```",
    "issue_url": "https://github.com/mem0ai/mem0/issues/3292",
    "repo_size": 283,
    "size_category": "large"
  },
  {
    "issue_number": 577,
    "repo_name": "browser-use/web-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily reports a validation error related to model output format without acknowledging any suboptimal solutions, limitations, or technical shortcuts. It does not express intent to address any known problems or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/browser-use/web-ui/issues/577",
    "repo_size": 353,
    "size_category": "large"
  },
  {
    "issue_number": 116,
    "repo_name": "ModelTC/LightLLM",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u770b\u8d77\u6765lightllm\u7ed3\u679c\u4e0e\u62a5\u544a\u7684\u6027\u80fd\u76f8\u5dee\u5f88\u5927\uff0c\u53ef\u4ee5\u544a\u8bc9\u6211\u662f\u54ea\u91cc\u8bbe\u7f6e\u9519\u8bef\u4e86\u5417\uff1f\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u7ed3\u679c\u4e0e\u62a5\u544a\u7684\u6027\u80fd\u76f8\u5dee\u5f88\u5927\",\n    \"\u53ef\u4ee5\u544a\u8bc9\u6211\u662f\u54ea\u91cc\u8bbe\u7f6e\u9519\u8bef\u4e86\u5417\"\n  ]\n}\n```",
    "issue_url": "https://github.com/ModelTC/LightLLM/issues/116",
    "repo_size": 84,
    "size_category": "medium"
  },
  {
    "issue_number": 558,
    "repo_name": "adapter-hub/adapters",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It simply asks how to update the library without indicating any existing problems or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/adapter-hub/adapters/issues/558",
    "repo_size": 161,
    "size_category": "medium"
  },
  {
    "issue_number": 1974,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. The user is reporting a bug without indicating any awareness of underlying technical debt or areas needing future improvement.\"\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/1974",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 18006,
    "repo_name": "PrefectHQ/prefect",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"it's weird that setting a result_storage creates a side effects on the logging, seems like a bug to me.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"weird that setting a result_storage creates a side effects\",\n    \"seems like a bug to me\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/prefect/issues/18006",
    "repo_size": 289,
    "size_category": "large"
  },
  {
    "issue_number": 1139,
    "repo_name": "open-compass/VLMEvalKit",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This is fixed by adding `torch_dtype=torch.bfloat16` to the model loading line of `gemma.py`.\",\n    \"I'm considering making a PR about this, but scores were visibly computed at least once using default (bf32) settings.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"This is fixed by adding\",\n    \"scores were visibly computed at least once using default (bf32) settings\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-compass/VLMEvalKit/issues/1139",
    "repo_size": 212,
    "size_category": "large"
  },
  {
    "issue_number": 434,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"you need to install the following dependencies['nltk'] using 'pip install # Here to have a nice missing dependency error message early on'\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"you need to install the following dependencies\",\n    \"nice missing dependency error message early on\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/434",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 413,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It primarily seeks clarification on integration with Azure APIM without indicating any known issues or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/413",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 8727,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Warning: Cannot load \\\"@napi-rs/canvas\\\" package: \\\"Error: Cannot find module '@napi-rs/canvas'\\\"\",\n    \"Warning: Cannot polyfill `DOMMatrix`, rendering may be broken.\",\n    \"Warning: Cannot polyfill `ImageData`, rendering may be broken.\",\n    \"Warning: Cannot polyfill `Path2D`, rendering may be broken.\",\n    \"(node:28) [DEP0060] DeprecationWarning: The `util._extend` API is deprecated. Please use Object.assign() instead.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Warning: Cannot load\",\n    \"Warning: Cannot polyfill\",\n    \"DeprecationWarning\"\n  ]\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8727",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 824,
    "repo_name": "InternLM/xtuner",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It simply describes an error encountered while using the Qwen2 model without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/InternLM/xtuner/issues/824",
    "repo_size": 344,
    "size_category": "large"
  },
  {
    "issue_number": 2336,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I suspect that it's the GPU who use the largest VRAM could not fit any more.\",\n    \"Is that possible to balance the VRAM usage across the GPUs, so that none of any one would be the resource boundary of the whole system.\",\n    \"I tried to set --tensor-split=16,16,16,13,16,16,16,16 combining with --gpu-layers=63 for Gemma3 to adjust VRAM usage manually, however, the model could not even start in case ctx-size is 100k.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I suspect that...\",\n    \"Is that possible to...\",\n    \"I tried to set... however...\"\n  ]\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/2336",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 70,
    "repo_name": "D-Star-AI/dsRAG",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently, the only option is to pickle the metadata dictionary and save to local file system.\",\n    \"This is a problem when trying to deploy with Lambda functions.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Currently, the only option is\",\n    \"This is a problem when\"\n  ]\n}\n```",
    "issue_url": "https://github.com/D-Star-AI/dsRAG/issues/70",
    "repo_size": 39,
    "size_category": "small"
  },
  {
    "issue_number": 1303,
    "repo_name": "Josh-XT/AGiXT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"centralize the logging mechanism\",\n    \"enhance maintainability\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"aims to\",\n    \"needs to\",\n    \"should calculate\",\n    \"before proceeding\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Josh-XT/AGiXT/issues/1303",
    "repo_size": 76,
    "size_category": "medium"
  },
  {
    "issue_number": 116,
    "repo_name": "danny-avila/rag_api",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"My guess is that the `langchain_huggingface` package is missing from the `requirements.lite.txt` file.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"My guess is that\",\n    \"could this be the cause of the issue?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/danny-avila/rag_api/issues/116",
    "repo_size": 88,
    "size_category": "medium"
  },
  {
    "issue_number": 947,
    "repo_name": "neuml/txtai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"this logic needs to be improved\",\n    \"an additional check should be added\",\n    \"the method can always be manually set\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"needs to be improved\",\n    \"should be added\",\n    \"can always be manually set\"\n  ]\n}\n```",
    "issue_url": "https://github.com/neuml/txtai/issues/947",
    "repo_size": 252,
    "size_category": "large"
  },
  {
    "issue_number": 16996,
    "repo_name": "open-webui/open-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It primarily reports a discrepancy in image sizes without indicating any intention to address or improve the underlying issue.\"\n}\n```",
    "issue_url": "https://github.com/open-webui/open-webui/issues/16996",
    "repo_size": 332,
    "size_category": "large"
  },
  {
    "issue_number": 850,
    "repo_name": "bentoml/OpenLLM",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue is a request for a new feature (a Gradio demo) and does not acknowledge any suboptimal solutions, limitations, or technical shortcuts. It does not indicate any existing problems that need to be addressed or areas needing future improvement.\"\n}\n```",
    "issue_url": "https://github.com/bentoml/OpenLLM/issues/850",
    "repo_size": 97,
    "size_category": "medium"
  },
  {
    "issue_number": 3307,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply requests a feature enhancement without indicating any existing problems or temporary fixes.\"\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/3307",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 712,
    "repo_name": "open-compass/VLMEvalKit",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It primarily seeks clarification on the results obtained from specific settings without indicating any known issues or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/open-compass/VLMEvalKit/issues/712",
    "repo_size": 212,
    "size_category": "large"
  },
  {
    "issue_number": 389,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Both metrics seem relatively straightforward (famous last words!).\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"famous last words\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/389",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 378,
    "repo_name": "father-bot/chatgpt_telegram_bot",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Something went wrong during completion.\",\n    \"It shouldn't be my OpenAPI API key, I generated a separate one just for this, and it has only used up a few cents now, so it's most probably not that.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Something went wrong\",\n    \"It shouldn't be\",\n    \"most probably not that\"\n  ]\n}\n```",
    "issue_url": "https://github.com/father-bot/chatgpt_telegram_bot/issues/378",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 14,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not express any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is simply a request for guidance on how to execute the project.\"\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/14",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 2530,
    "repo_name": "embeddings-benchmark/mteb",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I think this can be implemented like:\",\n    \"create test similarly to metadata.is_filled()\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I think this can be implemented like:\",\n    \"create test similarly to\"\n  ]\n}\n```",
    "issue_url": "https://github.com/embeddings-benchmark/mteb/issues/2530",
    "repo_size": 301,
    "size_category": "large"
  },
  {
    "issue_number": 2622,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Enable using other files such as DOC, images etc.\",\n    \"Unstructured allows us to utilize their API via a JS SDK\",\n    \"Their API can be deployed as a docker container locally via the current docker compose and use this locally.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Enable using\",\n    \"allows us to utilize\",\n    \"can be deployed as\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/2622",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 750,
    "repo_name": "langroid/langroid",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"When strict recovery is enabled in Agent's config the following code causes endless loop\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"causes endless loop\",\n    \"strict recovery is enabled\"\n  ]\n}\n```",
    "issue_url": "https://github.com/langroid/langroid/issues/750",
    "repo_size": 121,
    "size_category": "medium"
  },
  {
    "issue_number": 1807,
    "repo_name": "openaccess-ai-collective/axolotl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This method makes it straightforward to communicate with the system and also offers flexible options for saving the trained models, either locally or on cloud storage \u2014 though we can figure out the details of cloud storage later.\",\n    \"By setting up a RESTful server, teams can easily put Axolotl to work in their own systems and start training or tweaking models with just a few clicks. This setup removes the technical hurdles and lets anyone manage machine learning tasks through simple web requests.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"we can figure out the details of cloud storage later\",\n    \"removes the technical hurdles\",\n    \"easily put Axolotl to work\"\n  ]\n}\n```",
    "issue_url": "https://github.com/axolotl-ai-cloud/axolotl/issues/1807",
    "repo_size": 193,
    "size_category": "medium"
  },
  {
    "issue_number": 2831,
    "repo_name": "camel-ai/camel",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is simply a question about the support for a specific feature (streamable-http mode) without any indication of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/camel-ai/camel/issues/2831",
    "repo_size": 200,
    "size_category": "large"
  },
  {
    "issue_number": 3215,
    "repo_name": "mem0ai/mem0",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"there is not memory getting saved with `infer=False`\",\n    \"Am I doing something wrong here?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"not memory getting saved\",\n    \"Am I doing something wrong here?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/mem0ai/mem0/issues/3215",
    "repo_size": 283,
    "size_category": "large"
  },
  {
    "issue_number": 56,
    "repo_name": "danny-avila/rag_api",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It would be a great feature if there the rage can interact with bedrock API also as it's one of the leading model provider\",\n    \"most of the organisations including mine, prefer using aws infra for obvious reasons\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"It would be a great feature\",\n    \"prefer using aws infra for obvious reasons\"\n  ]\n}\n```",
    "issue_url": "https://github.com/danny-avila/rag_api/issues/56",
    "repo_size": 88,
    "size_category": "medium"
  },
  {
    "issue_number": 558,
    "repo_name": "PromtEngineer/localGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"ValueError: Requested tokens (2332) exceed context window of 2048\",\n    \"Is this a threshold under the hood for the token-size of the queries aggregated or the token size of the anticipated response?\",\n    \"It appears only to happen after at least 3 queries have been made.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"ValueError: Requested tokens exceed context window\",\n    \"threshold under the hood\",\n    \"appears only to happen after at least 3 queries\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PromtEngineer/localGPT/issues/558",
    "repo_size": 194,
    "size_category": "medium"
  },
  {
    "issue_number": 278,
    "repo_name": "SWE-bench/SWE-bench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"There are a few code tools that claims to be better than Claude\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"claims to be better than\",\n    \"a few code tools\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SWE-bench/SWE-bench/issues/278",
    "repo_size": 199,
    "size_category": "medium"
  },
  {
    "issue_number": 101,
    "repo_name": "RUC-NLPIR/FlashRAG",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"input_prompts.append([q + ' ' + doc for doc in docs])\u8fd9\u53e5\u8bdd\u62a5\u9519\u8bf4\u4e0d\u80fdappend\u4e00\u4e2a\u5b57\u5178\uff0c\u7136\u540e\u6211\u5c31\u6539\u6210\u4e86 input_prompts.append([q + ' ' + doc['contents'] for doc in docs])\",\n    \"\u6211\u8bd5\u7740\u5c06\u62a5\u9519\u8bed\u53e5\u6539\u4e3a outputs = self.model.generate(**inputs, # do_sample=True, # temperature=0.8, # top_p=0.9, max_length=256, # num_beams=1,)\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u62a5\u9519\u8bf4\u4e0d\u80fdappend\u4e00\u4e2a\u5b57\u5178\",\n    \"\u6211\u5c31\u6539\u6210\u4e86\",\n    \"\u6211\u8bd5\u7740\u5c06\u62a5\u9519\u8bed\u53e5\u6539\u4e3a\"\n  ]\n}\n```",
    "issue_url": "https://github.com/RUC-NLPIR/FlashRAG/issues/101",
    "repo_size": 164,
    "size_category": "medium"
  },
  {
    "issue_number": 1308,
    "repo_name": "FlagOpen/FlagEmbedding",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"One obvious suggestion is to remove the following from the `encode_single_device` function:\",\n    \"The second observation is that `self.model(...` is now invoked at least two times instead of once just to adjust batch size on Error?\"\n  ],\n  \"WHO_ADMITS\": \"Nikola (issue author)\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"obvious suggestion\",\n    \"is now invoked at least two times instead of once\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FlagOpen/FlagEmbedding/issues/1308",
    "repo_size": 371,
    "size_category": "large"
  },
  {
    "issue_number": 6372,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"\u4f7f\u7528zero3\u65f6\uff0c72B\u6a21\u578b\u88ab\u5206\u5230\u4e86\u6240\u6709\u8282\u70b9\u7684\u6240\u6709gpu\u4e0a\uff0c\u5373\u4f7f\u4f7f\u7528\u4e86nvlink\uff0c\u4f46\u901a\u4fe1\u5ef6\u8fdf\u4ecd\u7136\u975e\u5e38\u9ad8\uff0c\u5bfc\u81f4\u8bad\u7ec3\u901f\u5ea6\u5f88\u6162\",\n    \"\u8282\u70b9\u8d8a\u591a\uff0c\u8bad\u7ec3\u901f\u5ea6\u53cd\u800c\u66f4\u6162\uff0c\u4e0d\u5982\u53ea\u4f7f\u7528\u5355\u8282\u70b9\",\n    \"\u82e5\u53ef\u4ee5\u63a7\u5236\u6a21\u578b\u53ea\u5728\u8282\u70b9\u5185\u88ab\u62c6\u5206\uff0c\u7406\u8bba\u4e0a\u53ef\u4ee5\u51cf\u5c11\u901a\u4fe1\uff0c\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u901f\u5ea6\u5f88\u6162\",\n    \"\u901a\u4fe1\u5ef6\u8fdf\u4ecd\u7136\u975e\u5e38\u9ad8\",\n    \"\u5bfc\u81f4\u8bad\u7ec3\u901f\u5ea6\u5f88\u6162\",\n    \"\u7406\u8bba\u4e0a\u53ef\u4ee5\u51cf\u5c11\u901a\u4fe1\uff0c\u52a0\u5feb\u8bad\u7ec3\u901f\u5ea6\"\n  ]\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/6372",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 755,
    "repo_name": "mosaicml/llm-foundry",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"eval.py hangs when config yaml's model hparams don't match model checkpoint hparams\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"hangs\",\n    \"don't match\"\n  ]\n}\n```",
    "issue_url": "https://github.com/mosaicml/llm-foundry/issues/755",
    "repo_size": 50,
    "size_category": "medium"
  },
  {
    "issue_number": 7114,
    "repo_name": "oobabooga/text-generation-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The llama_cpp_binaries module does NOT exist for Linux.\",\n    \"It is only built for Windows 3.11 Wheels and is a workaround for portable/server mode.\",\n    \"The current architecture of oobabooga/text-generation-webui requires server mode for GGUF models \u2013 this is effectively no longer available for Linux.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"does NOT exist\",\n    \"is a workaround\",\n    \"effectively no longer available\"\n  ]\n}\n```",
    "issue_url": "https://github.com/oobabooga/text-generation-webui/issues/7114",
    "repo_size": 339,
    "size_category": "large"
  },
  {
    "issue_number": 304,
    "repo_name": "agent0ai/agent-zero",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. The user is reporting a problem without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/agent0ai/agent-zero/issues/304",
    "repo_size": 245,
    "size_category": "large"
  },
  {
    "issue_number": 15,
    "repo_name": "microsoft/promptbench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"`ValueError`\",\n    \"`temperature` (=0) has to be a strictly positive float, otherwise your next token scores will be invalid.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"ValueError\",\n    \"has to be a strictly positive float\",\n    \"otherwise your next token scores will be invalid\"\n  ]\n}\n```",
    "issue_url": "https://github.com/microsoft/promptbench/issues/15",
    "repo_size": 63,
    "size_category": "medium"
  },
  {
    "issue_number": 2963,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"there is an error of: RuntimeError: Unsloth: vllm_process failed to load!\",\n    \"the script can run in colab with H100 GPU\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"failed to load\",\n    \"can run in colab with H100 GPU\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/2963",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 261,
    "repo_name": "evalplus/evalplus",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It primarily serves as a request to evaluate a model without indicating any existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/evalplus/evalplus/issues/261",
    "repo_size": 206,
    "size_category": "large"
  },
  {
    "issue_number": 1340,
    "repo_name": "assafelovic/gpt-researcher",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the results weren\u2019t particularly stable\",\n    \"I can\u2019t effectively control the quality and length of the generated text\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"wasn't particularly stable\",\n    \"can\u2019t effectively control\",\n    \"wondering if you might consider adding this feature\"\n  ]\n}\n```",
    "issue_url": "https://github.com/assafelovic/gpt-researcher/issues/1340",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 1929,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"None of ... have been found\",\n    \"Models won't be available\",\n    \"only tokenizers, configuration and file/data utilities can be used\"\n  ]\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/1929",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 1113,
    "repo_name": "Pacific-AI-Corp/langtest",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Fix Error in Accuracy Tests for Multi-Label Classification\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Fix Error\",\n    \"Accuracy Tests\",\n    \"Multi-Label Classification\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Pacific-AI-Corp/langtest/issues/1113",
    "repo_size": 188,
    "size_category": "medium"
  },
  {
    "issue_number": 9025,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n    \"SATD_FOUND\": \"Yes\",\n    \"EXACT_QUOTES\": [\n        \"--bf16\"\n    ],\n    \"WHO_ADMITS\": \"issue author\",\n    \"DEBT_TYPE\": \"configuration\",\n    \"LANGUAGE_PATTERNS\": [\n        \"\u4e0d\u652f\u6301bf16\",\n        \"\u5f97\u5230\u4e86\u8fd9\u4e2aerror\"\n    ]\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/9025",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 103,
    "repo_name": "letta-ai/letta",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"we will work on polishing up the paper eval code and preparing it for release\",\n    \"these results are quite expensive and resource-intensive to replicate\",\n    \"we will work on releasing the MemGPT generations from our paper\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"we will work on\",\n    \"polishing up\",\n    \"expensive and resource-intensive\",\n    \"known limitations\",\n    \"temporary fixes\"\n  ]\n}\n```",
    "issue_url": "https://github.com/letta-ai/letta/issues/103",
    "repo_size": 134,
    "size_category": "medium"
  },
  {
    "issue_number": 872,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"UserWarning: 1Torch was not compiled with flash attention.\",\n    \"UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\",\n    \"RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": [\n    \"configuration\",\n    \"implementation\"\n  ],\n  \"LANGUAGE_PATTERNS\": [\n    \"UserWarning\",\n    \"RuntimeWarning\",\n    \"defaulting to\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/872",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 2961,
    "repo_name": "livekit/agents",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Is there any known limitation with allow_interruptions=False and AWS STT?\",\n    \"Does LiveKit drop audio input during the assistant's speaking time or delay it indefinitely?\",\n    \"How can I allow the assistant to finish speaking but still capture what the user said afterward?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Is there any known limitation\",\n    \"Does LiveKit drop audio input\",\n    \"How can I allow the assistant to finish speaking but still capture what the user said afterward\"\n  ]\n}\n```",
    "issue_url": "https://github.com/livekit/agents/issues/2961",
    "repo_size": 297,
    "size_category": "large"
  },
  {
    "issue_number": 16126,
    "repo_name": "PrefectHQ/prefect",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"Multiple flows occasionally become stuck in an infinite loop of events when certain tasks enter a retry state.\",\n    \"We have identified the issue as being related to Workers.\",\n    \"If a ProcessWorker is destroyed and replaced, the flow it was executing cannot properly transition to a new state or restart.\",\n    \"This results in the flow being unable to progress and effectively stuck.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"occasionally become stuck\",\n    \"identified the issue as being related to\",\n    \"cannot properly transition\",\n    \"unable to progress and effectively stuck\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/prefect/issues/16126",
    "repo_size": 289,
    "size_category": "large"
  },
  {
    "issue_number": 1204,
    "repo_name": "assafelovic/gpt-researcher",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"I disabled paralellism because i want to stay on Gemini's free tier and avoid rate limit errors.\",\n    \"GPTR doesn't search properly or doesn't handle search result properly, it refers to hypotetical entities.\",\n    \"Placeholder for a hypothetical commercial platform.\",\n    \"Note: These often evolve into open-source or commercial offerings.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": [\n    \"configuration\",\n    \"implementation\"\n  ],\n  \"LANGUAGE_PATTERNS\": [\n    \"I disabled paralellism because\",\n    \"doesn't search properly\",\n    \"refers to hypotetical entities\",\n    \"Placeholder for a hypothetical commercial platform\",\n    \"Note: These often evolve\"\n  ]\n}\n```",
    "issue_url": "https://github.com/assafelovic/gpt-researcher/issues/1204",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 1468,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u5b58\u5728\u8f93\u5165\u957f\u6587\u672c\u540e\uff0ctokenizer\u5bf9\u6587\u672c\u8fdb\u884c\u5206\u5272\uff0c\u524d\u540e\u5206\u5272\u540e\u7684\u5408\u6210\u7684\u8bed\u97f3\u5728\u97f3\u8272\u3001\u8bed\u6c14\u3001\u8bed\u8c03\u4e0a\u6709\u663e\u8457\u4e0d\u540c\",\n    \"\u5bfc\u81f4\u957f\u6587\u672c\u8bed\u97f3\u7684\u4f53\u9a8c\u5341\u5206\u5272\u88c2\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u5b58\u5728\",\n    \"\u5bfc\u81f4\",\n    \"\u663e\u8457\u4e0d\u540c\",\n    \"\u4f53\u9a8c\u5341\u5206\u5272\u88c2\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/1468",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 23517,
    "repo_name": "vllm-project/vllm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It primarily focuses on a bug report without indicating any underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/vllm-project/vllm/issues/23517",
    "repo_size": 165,
    "size_category": "medium"
  },
  {
    "issue_number": 532,
    "repo_name": "FlagOpen/FlagEmbedding",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently i cannot really use the 'Sparse mode' of BGE-M3.\",\n    \"Why does this mode need so much VRAM? Is this to be expected?\",\n    \"Can this somehow be mitigated? Split over GPUs?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"cannot really use\",\n    \"need so much VRAM\",\n    \"Is this to be expected?\",\n    \"Can this somehow be mitigated?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FlagOpen/FlagEmbedding/issues/532",
    "repo_size": 371,
    "size_category": "large"
  },
  {
    "issue_number": 1579,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"editing settings.yaml and running again isn't enough to change to different models\",\n    \"I'm ok if errors happen or the new models don't work properly\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"isn't enough to change\",\n    \"I'm ok if errors happen\",\n    \"new models don't work properly\"\n  ]\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/1579",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 43,
    "repo_name": "beir-cellar/beir",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It consists solely of questions seeking clarification on the use of the Trec-Covid datasets without indicating any known issues or areas for improvement.\"\n}\n```",
    "issue_url": "https://github.com/beir-cellar/beir/issues/43",
    "repo_size": 149,
    "size_category": "medium"
  },
  {
    "issue_number": 1778,
    "repo_name": "FoundationAgents/MetaGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u8fd9\u901a\u5e38\u662f\u7531\u4e8e pydantic \u7248\u672c\u517c\u5bb9\u6027\u95ee\u9898\u5f15\u8d77\u7684\u3002\",\n    \"\u56e0\u6b64\u8fd9\u4e2a\u95ee\u9898\u603b\u7684\u6765\u8bf4\u662f\uff0cpydantic \u5c0f\u4e8e2.0\u548c\u5927\u4e8e\u7b49\u4e8e2.0 \u4e5f\u5c31\u662f\u6574\u4e2a\u9879\u76ee\u4e2d\u5b58\u5728\u5f15\u7528pydantic\u8fd9\u4e2a\u5e93\u65f6\u5019\u51fa\u73b0\u4f9d\u8d56\u51b2\u7a81\u9519\u8bef\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u8fd9\u901a\u5e38\u662f\u7531\u4e8e ... \u5f15\u8d77\u7684\u3002\",\n    \"\u56e0\u6b64\u8fd9\u4e2a\u95ee\u9898\u603b\u7684\u6765\u8bf4\u662f ...\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FoundationAgents/MetaGPT/issues/1778",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 21,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is simply a request for information regarding open source video data without any indication of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/21",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 10679,
    "repo_name": "open-webui/open-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This can cause many duplicates in the vector database, long term leading to problems in RAG because of duplicates in top-k results.\",\n    \"I would have expected similar file treatment through both routes.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"This can cause many duplicates\",\n    \"I would have expected similar file treatment\",\n    \"known limitations or problems they plan to address\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-webui/open-webui/issues/10679",
    "repo_size": 332,
    "size_category": "large"
  },
  {
    "issue_number": 276,
    "repo_name": "bigcode-project/bigcode-evaluation-harness",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Does not pass the arg trust_remote_code here\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Does not pass the arg\",\n    \"here\"\n  ]\n}\n```",
    "issue_url": "https://github.com/bigcode-project/bigcode-evaluation-harness/issues/276",
    "repo_size": 159,
    "size_category": "medium"
  },
  {
    "issue_number": 2702,
    "repo_name": "openaccess-ai-collective/axolotl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently `axolotl train` does have a single --trl flag, but it is unusable.\",\n    \"The best way to do that is likely by adding additional if-clause into `add_options_from_config`.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"but it is unusable\",\n    \"best way to do that is likely by adding additional if-clause\"\n  ]\n}\n```",
    "issue_url": "https://github.com/axolotl-ai-cloud/axolotl/issues/2702",
    "repo_size": 193,
    "size_category": "medium"
  },
  {
    "issue_number": 1841,
    "repo_name": "h2oai/h2ogpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"we need to be able to skip execution of such code blocks in H2OLocalCommandLineCodeExecutor\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"seems when\",\n    \"we need to be able to\",\n    \"hence the conversation goes on as a loop\"\n  ]\n}\n```",
    "issue_url": "https://github.com/h2oai/h2ogpt/issues/1841",
    "repo_size": 299,
    "size_category": "large"
  },
  {
    "issue_number": 18166,
    "repo_name": "PrefectHQ/prefect",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"filtering by the items per page selector seems not to be useful and is limiting the graphs usefulness for us\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"seems not to be useful\",\n    \"limiting the graphs usefulness\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/prefect/issues/18166",
    "repo_size": 289,
    "size_category": "large"
  },
  {
    "issue_number": 18490,
    "repo_name": "PrefectHQ/prefect",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I need to delete the newly created docker work pool, and create a new one, so I can add the Docker Registry Credentials from the Prefect Blocks.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I need to delete the newly created docker work pool\",\n    \"create a new one\",\n    \"so I can add the Docker Registry Credentials\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/prefect/issues/18490",
    "repo_size": 289,
    "size_category": "large"
  },
  {
    "issue_number": 316,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain explicit acknowledgments of suboptimal solutions, known limitations, or technical shortcuts. It primarily describes a bug without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/316",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 1873,
    "repo_name": "SeldonIO/MLServer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"TypeError: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"doesn't work\",\n    \"always found this errors\",\n    \"how can I make it work correctly\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SeldonIO/MLServer/issues/1873",
    "repo_size": 145,
    "size_category": "medium"
  },
  {
    "issue_number": 831,
    "repo_name": "neuml/txtai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"issues with upserts that delete all existing data\",\n    \"Passing the SQLAlchemy engine to table DDL statements. This wraps the operation with another layered transaction.\",\n    \"Passing the SQLAlchemy engine to the database session. This is causing locking behavior within the same database component.\",\n    \"For ANNs backed by databases, the `close` method must be run before recreating a new ANN.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Currently, there are scenarios where...\",\n    \"The following issues have been identified.\",\n    \"This work will address these issues...\"\n  ]\n}\n```",
    "issue_url": "https://github.com/neuml/txtai/issues/831",
    "repo_size": 252,
    "size_category": "large"
  },
  {
    "issue_number": 16054,
    "repo_name": "PrefectHQ/prefect",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"having a scheduled flow tampering with the Prefect database directly might be a source of issues downhill.\",\n    \"it would be very nice if Prefect server had a way of cleaning its logs automatically.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"might be a source of issues\",\n    \"it would be very nice if\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/prefect/issues/16054",
    "repo_size": 289,
    "size_category": "large"
  },
  {
    "issue_number": 125,
    "repo_name": "evalplus/evalplus",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The outputs of `find_zero` are not an iterable.\",\n    \"You always get this error: TypeError: Value after * must be an iterable, not float\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"not an iterable\",\n    \"always get this error\"\n  ]\n}\n```",
    "issue_url": "https://github.com/evalplus/evalplus/issues/125",
    "repo_size": 206,
    "size_category": "large"
  },
  {
    "issue_number": 1628,
    "repo_name": "FoundationAgents/MetaGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"no output is shown in the terminal\",\n    \"But o1 is indeed being used and charged\",\n    \"logs does have the o1 output as 'DEBUG', it is just not shown in the terminal\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"no output is shown\",\n    \"is indeed being used and charged\",\n    \"just not shown in the terminal\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FoundationAgents/MetaGPT/issues/1628",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 350,
    "repo_name": "SeldonIO/MLServer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently we return the output of explainers as v2 `BYTES` and downstream would need to know details about `alibi.Explanation` in order to decode and consume the response.\",\n    \"Perhaps we need to introduce a v2 protocol extension to describe the output of explain call?\",\n    \"This would require also codec specific to deal with Explanation data.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Currently we return\",\n    \"would need to know details\",\n    \"Perhaps we need to introduce\",\n    \"This would require\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SeldonIO/MLServer/issues/350",
    "repo_size": 145,
    "size_category": "medium"
  },
  {
    "issue_number": 23983,
    "repo_name": "vllm-project/vllm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the problem seems to be that outlines (versions 0.0.43\u20130.0.46) depends on pyairports, but pyairports is not available on PyPI\",\n    \"To fix this you could try to: loosen the range of package versions you've specified or remove package versions to allow pip to attempt to solve the dependency conflict\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"the problem seems to be\",\n    \"To fix this you could try to\"\n  ]\n}\n```",
    "issue_url": "https://github.com/vllm-project/vllm/issues/23983",
    "repo_size": 165,
    "size_category": "medium"
  },
  {
    "issue_number": 3150,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily reports a runtime error without any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. There are no phrases indicating that the author recognizes any technical debt or plans to address known issues.\"\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/3150",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 3763,
    "repo_name": "stanford-crfm/helm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Error compiling Cython file\",\n    \"undeclared name not builtin: PyInt_CheckExact\",\n    \"undeclared name not builtin: PyInt_Check\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Error compiling\",\n    \"undeclared name\",\n    \"did not run successfully\"\n  ]\n}\n```",
    "issue_url": "https://github.com/stanford-crfm/helm/issues/3763",
    "repo_size": 157,
    "size_category": "medium"
  },
  {
    "issue_number": 8823,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"missing display names\",\n    \"duplicate entries\",\n    \"phantom models\",\n    \"disabled states\",\n    \"requiring manual SQL intervention to make models usable\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"creates database records with missing display names\",\n    \"duplicate entries\",\n    \"phantom models\",\n    \"disabled states\",\n    \"requiring manual SQL intervention\"\n  ]\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8823",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 2050,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is simply a question regarding the possibility of supporting Llama on Azure AI Studio without any indication of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/2050",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 2936,
    "repo_name": "camel-ai/camel",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. The body lacks any content that indicates the author is aware of existing technical debt or plans to address it.\"\n}\n```",
    "issue_url": "https://github.com/camel-ai/camel/issues/2936",
    "repo_size": 200,
    "size_category": "large"
  },
  {
    "issue_number": 1357,
    "repo_name": "openaccess-ai-collective/axolotl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the '</s>' is added as a string, THEN the '<|endoftext|>' token is added afterwards\",\n    \"resulting in the tuned model to output BOTH '</s>' and '<|endoftext|>' when conversation turn ends\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"is added as a string\",\n    \"resulting in\",\n    \"when conversation turn ends\"\n  ]\n}\n```",
    "issue_url": "https://github.com/axolotl-ai-cloud/axolotl/issues/1357",
    "repo_size": 193,
    "size_category": "medium"
  },
  {
    "issue_number": 1093,
    "repo_name": "NVIDIA/NeMo-Guardrails",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Looking at the code, in the llmrails.py file, I see the following line changing the res object:\",\n    \"Commenting out this line solves the issue.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Looking at the code\",\n    \"Commenting out this line solves the issue\"\n  ]\n}\n```",
    "issue_url": "https://github.com/NVIDIA/NeMo-Guardrails/issues/1093",
    "repo_size": 148,
    "size_category": "medium"
  },
  {
    "issue_number": 2501,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"`num_procs` seems to be disregarded\",\n    \"unsloth seems to loop and spawn new process and crash\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"seems to be disregarded\",\n    \"seems to loop\",\n    \"crash\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/2501",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 10775,
    "repo_name": "Significant-Gravitas/AutoGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I realised Id personally like the following features\",\n    \"Search functionality within the graph across inputs, outputs and block titles\",\n    \"List of all blocks we have in the graph which moves view to that block when clicked\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I realised Id personally like\",\n    \"features\",\n    \"functionality\",\n    \"which moves view to that block\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Significant-Gravitas/AutoGPT/issues/10775",
    "repo_size": 215,
    "size_category": "large"
  },
  {
    "issue_number": 424,
    "repo_name": "Lightning-AI/LitServe",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I'm encountering an error in my predict function\",\n    \"which is causing a multiprocessing.managers.RemoteError\",\n    \"resulting in the server going down\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"encountering an error\",\n    \"causing a ... RemoteError\",\n    \"resulting in the server going down\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Lightning-AI/LitServe/issues/424",
    "repo_size": 69,
    "size_category": "medium"
  },
  {
    "issue_number": 8701,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It primarily describes a bug without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8701",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 767,
    "repo_name": "SeldonIO/MLServer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"it would be useful to introduce support for Unions in simplified `predict()` interfaces.\",\n    \"This would allow for use cases where data types are variable\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"it would be useful to introduce\",\n    \"allow for use cases where data types are variable\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SeldonIO/MLServer/issues/767",
    "repo_size": 145,
    "size_category": "medium"
  },
  {
    "issue_number": 394,
    "repo_name": "SWE-bench/SWE-bench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I am not sure whether this is a bug or maybe it's just my personal operation.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I am not sure\",\n    \"maybe it's just my personal operation\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SWE-bench/SWE-bench/issues/394",
    "repo_size": 199,
    "size_category": "medium"
  },
  {
    "issue_number": 123,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is simply a request for information regarding the availability of videos for vbench2.\"\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/123",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 335,
    "repo_name": "SWE-bench/SWE-bench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"when creating a sandbox, you should pass it an app for cost tracking in modal.\",\n    \"I previously ran into an issue where image building processes ended up getting orphaned and accumulated > $200 without any way to stop those processes.\",\n    \"Supposedly fixed if you associate each container with an app.\",\n    \"Also not sure it makes sense to have a modal function call its own modal sandbox. That seems like twice the number of instances necessary.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Heads up\",\n    \"I previously ran into an issue\",\n    \"Supposedly fixed\",\n    \"not sure it makes sense\",\n    \"twice the number of instances necessary\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SWE-bench/SWE-bench/issues/335",
    "repo_size": 199,
    "size_category": "medium"
  },
  {
    "issue_number": 168,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently, when `compute` is called all data is loaded into memory and passed as a list.\",\n    \"This can pose a bottleneck especially for data intensive modalities (e.g. images) or measurements of large datasets.\",\n    \"As an alternative we could pass a generator (or something similar) object that iterates over the datasets as many metrics are calculated in for loops or list comprehensions.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Currently, when `compute` is called all data is loaded into memory\",\n    \"This can pose a bottleneck\",\n    \"As an alternative we could pass a generator\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/168",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 2358,
    "repo_name": "embeddings-benchmark/mteb",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"it seems that it hasn't been decided on what to do with ASR tasks since downstream ASR tasks require non-trivial evaluation process/implementation.\",\n    \"though it may lack motivation/significance since they already put it together.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"it seems that\",\n    \"require non-trivial evaluation process/implementation\",\n    \"may lack motivation/significance\"\n  ]\n}\n```",
    "issue_url": "https://github.com/embeddings-benchmark/mteb/issues/2358",
    "repo_size": 301,
    "size_category": "large"
  },
  {
    "issue_number": 88,
    "repo_name": "AgentOps-AI/agentops",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This is the first of several test features we'll use to determine which is the best instrumentation library.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"first of several test features\",\n    \"determine which is the best\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AgentOps-AI/agentops/issues/88",
    "repo_size": 139,
    "size_category": "medium"
  },
  {
    "issue_number": 146,
    "repo_name": "bigcode-project/bigcode-evaluation-harness",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"but another process is utilizing it.\",\n    \"Please specify a different port (such as using the `----main_process_port` flag or specifying a different `main_process_port` in your config file) and rerun your script.\",\n    \"To automatically use the next open port (on a single node), you can set this to `0`.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"but another process is utilizing it.\",\n    \"Please specify a different port\",\n    \"you can set this to `0`.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/bigcode-project/bigcode-evaluation-harness/issues/146",
    "repo_size": 159,
    "size_category": "medium"
  },
  {
    "issue_number": 1905,
    "repo_name": "h2oai/h2ogpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report describes a problem with collections disappearing but does not acknowledge any suboptimal solutions, known limitations, or technical shortcuts. It simply asks for help in diagnosing the issue without indicating any awareness of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/h2oai/h2ogpt/issues/1905",
    "repo_size": 299,
    "size_category": "large"
  },
  {
    "issue_number": 2237,
    "repo_name": "pytorch/torchtune",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I wonder if I can use one of the existing recipes like `llama3_2/1B_full` and derive my own template to fine-tune the Llama Guard models.\",\n    \"I appreciate any suggestions to tell me if I am on the right track before I spend more time on it.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I wonder if\",\n    \"I appreciate any suggestions\",\n    \"before I spend more time on it\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pytorch/torchtune/issues/2237",
    "repo_size": 237,
    "size_category": "large"
  },
  {
    "issue_number": 372,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It primarily describes a bug without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/372",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 608,
    "repo_name": "agent0ai/agent-zero",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. The author is simply seeking guidance on customizing the API interface without indicating any known issues or debt.\"\n}\n```",
    "issue_url": "https://github.com/agent0ai/agent-zero/issues/608",
    "repo_size": 245,
    "size_category": "large"
  },
  {
    "issue_number": 155,
    "repo_name": "father-bot/chatgpt_telegram_bot",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Please help, I can't install bot, What I do wrong?\",\n    \"FileNotFoundError: [Errno 2] No such file or directory\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Please help\",\n    \"What I do wrong?\",\n    \"returns\",\n    \"No such file or directory\"\n  ]\n}\n```",
    "issue_url": "https://github.com/father-bot/chatgpt_telegram_bot/issues/155",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 82,
    "repo_name": "microsoft/promptbench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I modified the GLUE code so that the attack evaluation can be carried out, but the current score of the output is always 0.\",\n    \"I want to know why?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"modified the GLUE code\",\n    \"current score of the output is always 0\",\n    \"want to know why\"\n  ]\n}\n```",
    "issue_url": "https://github.com/microsoft/promptbench/issues/82",
    "repo_size": 63,
    "size_category": "medium"
  },
  {
    "issue_number": 107,
    "repo_name": "LiveCodeBench/LiveCodeBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This version doesn't seem to be compatible\",\n    \"consider locking the version temporarily\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"doesn't seem to be compatible\",\n    \"consider locking the version temporarily\"\n  ]\n}\n```",
    "issue_url": "https://github.com/LiveCodeBench/LiveCodeBench/issues/107",
    "repo_size": 86,
    "size_category": "medium"
  },
  {
    "issue_number": 178,
    "repo_name": "father-bot/chatgpt_telegram_bot",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It primarily describes a problem encountered during the build process without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/father-bot/chatgpt_telegram_bot/issues/178",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 461,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is a straightforward request for functionality without any indication of known problems or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/461",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 388,
    "repo_name": "weaviate/Verba",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the hostname is hardcoded\",\n    \"the port information is not passed on to method connect_to_docker\",\n    \"fixes the issue\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"not possible to change\",\n    \"hardcoded\",\n    \"not passed on\",\n    \"fixes the issue\"\n  ]\n}\n```",
    "issue_url": "https://github.com/weaviate/Verba/issues/388",
    "repo_size": 243,
    "size_category": "large"
  },
  {
    "issue_number": 305,
    "repo_name": "llm-workflow-engine/llm-workflow-engine",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Let's add a little quick command, maybe `/c` so I don't have to type 'continue' over and over.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Let's add\",\n    \"so I don't have to type 'continue' over and over\"\n  ]\n}\n```",
    "issue_url": "https://github.com/llm-workflow-engine/llm-workflow-engine/issues/305",
    "repo_size": 188,
    "size_category": "medium"
  },
  {
    "issue_number": 2479,
    "repo_name": "pytorch/torchtune",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"These changes need to be made to Mistral.\",\n    \"Update tokenize_message to use add_start_tokens and add_end_tokens like in https://github.com/pytorch/torchtune/pull/1494\",\n    \"Replace add_eos with add_end_tokens and update tokenize_messages as in https://github.com/pytorch/torchtune/pull/1494\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"need to be made\",\n    \"update\",\n    \"replace\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pytorch/torchtune/issues/2479",
    "repo_size": 237,
    "size_category": "large"
  },
  {
    "issue_number": 17194,
    "repo_name": "PrefectHQ/prefect",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This can lead to a sprawl of deployments that may hold little business meaning\",\n    \"This code is hard to grok and easy to mess up.\",\n    \"the parent flow\u2019s relationship to the child infra-dependent flows is very decoupled making execution of the parent flow brittle to changes in server-side configuration\",\n    \"it\u2019s highly likely that `my_vertex_flow` and `my_high_cpu_k8s_flow` will fail if called directly because they rely on specialized infrastructure, but the flow author cannot enforce that dependency in Prefect today.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation, design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"can lead to a sprawl of deployments\",\n    \"hard to grok and easy to mess up\",\n    \"relationship to the child infra-dependent flows is very decoupled\",\n    \"execution of the parent flow brittle to changes\",\n    \"highly likely that ... will fail if called directly\",\n    \"cannot enforce that dependency\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/prefect/issues/17194",
    "repo_size": 289,
    "size_category": "large"
  },
  {
    "issue_number": 617,
    "repo_name": "browser-use/web-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply states a problem without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/browser-use/web-ui/issues/617",
    "repo_size": 353,
    "size_category": "large"
  },
  {
    "issue_number": 38,
    "repo_name": "datastax/astra-assistants-api",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Why do you need any validations here that breaks API?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"validation errors\",\n    \"breaks API\"\n  ]\n}\n```",
    "issue_url": "https://github.com/datastax/astra-assistants-api/issues/38",
    "repo_size": 58,
    "size_category": "medium"
  },
  {
    "issue_number": 1053,
    "repo_name": "bentoml/OpenLLM",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I'm not sure what to look at next to debug this.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I'm not sure what to look at next to debug this.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/bentoml/OpenLLM/issues/1053",
    "repo_size": 97,
    "size_category": "medium"
  },
  {
    "issue_number": 679,
    "repo_name": "robusta-dev/holmesgpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Need to make sure we don't break evals\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Need to make sure\",\n    \"don't break\"\n  ]\n}\n```",
    "issue_url": "https://github.com/robusta-dev/holmesgpt/issues/679",
    "repo_size": 88,
    "size_category": "medium"
  },
  {
    "issue_number": 278,
    "repo_name": "evalplus/evalplus",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"throws a `ValueError` when the input string contains only spaces\",\n    \"contradicts the expected behavior\",\n    \"Ideally, the function should return an empty dictionary `{}` for strings containing only spaces\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"throws a `ValueError`\",\n    \"contradicts the expected behavior\",\n    \"should return an empty dictionary\"\n  ]\n}\n```",
    "issue_url": "https://github.com/evalplus/evalplus/issues/278",
    "repo_size": 206,
    "size_category": "large"
  },
  {
    "issue_number": 2251,
    "repo_name": "SeldonIO/MLServer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Model has neither pad_token or eos_token, setting batch size to 1\",\n    \"should change to if hf_pipeline.tokenizer.pad_token_id is None\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"setting batch size to 1\",\n    \"should change to\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SeldonIO/MLServer/issues/2251",
    "repo_size": 145,
    "size_category": "medium"
  },
  {
    "issue_number": 1329,
    "repo_name": "FlagOpen/FlagEmbedding",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u5728\u63a8\u7406\u65f6\u9884\u52a0\u8f7d\u539f\u59cb\u6a21\u578b\u6743\u91cd\u65f6\u51fa\u73b0huggingface\u8fde\u63a5\u4e0d\u4e0a\u7684\u95ee\u9898\",\n    \"\u662f\u5426\u6709\u529e\u6cd5\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u6539\u4e3a\u672c\u5730\u8def\u5f84\u53c2\u6570\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u51fa\u73b0...\u95ee\u9898\",\n    \"\u662f\u5426\u6709\u529e\u6cd5...\",\n    \"\u9884\u52a0\u8f7d\u539f\u59cb\u6a21\u578b\u6743\u91cd\u65f6\u51fa\u73b0\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FlagOpen/FlagEmbedding/issues/1329",
    "repo_size": 371,
    "size_category": "large"
  },
  {
    "issue_number": 759,
    "repo_name": "GaiZhenbiao/ChuanhuChatGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is a feature request without indications of existing problems or debts.\"\n}\n```",
    "issue_url": "https://github.com/GaiZhenbiao/ChuanhuChatGPT/issues/759",
    "repo_size": 305,
    "size_category": "large"
  },
  {
    "issue_number": 249,
    "repo_name": "evalplus/evalplus",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I have checked that the number of results and the task_id is exactly matched to the MBPPPlus v0.3.0.\",\n    \"When I run without docker: evalplus.evaluate --dataset mbpp --samples my_data.jsonl I got the correct answer.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I manually generate the code solution\",\n    \"It shows: AssertionError: Missing problems in samples\",\n    \"When I run without docker: ... I got the correct answer.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/evalplus/evalplus/issues/249",
    "repo_size": 206,
    "size_category": "large"
  },
  {
    "issue_number": 148,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"MMCV==2.2.0 is used but incompatible.\",\n    \"Please install mmcv>=2.0.0rc4 < 2.1.0\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"is used but incompatible\",\n    \"please install\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/148",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 183,
    "repo_name": "jekalmin/extended_openai_conversation",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. The author is simply asking for guidance on how to implement a feature (multiple timers) without indicating any known issues or temporary fixes in the current implementation.\"\n}\n```",
    "issue_url": "https://github.com/jekalmin/extended_openai_conversation/issues/183",
    "repo_size": 226,
    "size_category": "large"
  },
  {
    "issue_number": 351,
    "repo_name": "potpie-ai/potpie",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"only uses bearer token authentication\",\n    \"need to add API key authentication support to make it consistent with other API endpoints\",\n    \"reuse the get_api_key_user dependency\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"need to add\",\n    \"only uses\",\n    \"should\",\n    \"reuse\"\n  ]\n}\n```",
    "issue_url": "https://github.com/potpie-ai/potpie/issues/351",
    "repo_size": 64,
    "size_category": "medium"
  },
  {
    "issue_number": 2148,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"-DLLAMA_CUBLAS is deprecated\",\n    \"dependency versions for compatibility\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"is deprecated\",\n    \"for compatibility\"\n  ]\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/2148",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 39,
    "repo_name": "AmenRa/ranx",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"You should make `check_keys` optional in evaluate because sometimes queries do not return any results for lexical-based systems.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"should make ... optional\",\n    \"sometimes queries do not return any results\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AmenRa/ranx/issues/39",
    "repo_size": 62,
    "size_category": "medium"
  },
  {
    "issue_number": 655,
    "repo_name": "InternLM/xtuner",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"trained multimodal model can only input **one image** at one time\",\n    \"is there any method to support multi image & queries at one time?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"can only input **one image** at one time\",\n    \"is there any method to support multi image & queries at one time?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/InternLM/xtuner/issues/655",
    "repo_size": 344,
    "size_category": "large"
  },
  {
    "issue_number": 2970,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Could this be a bug in the compiled Gemma3ForConditionalGeneration_forward logic?\",\n    \"What is the correct way to fine-tune unsloth/gemma-3-12b-it with LoRA and gradient checkpointing without hitting this error?\",\n    \"Any fix or workaround is appreciated \ud83d\ude4f\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Could this be a bug\",\n    \"What is the correct way\",\n    \"Any fix or workaround is appreciated\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/2970",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 114,
    "repo_name": "OSU-NLP-Group/HippoRAG",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"anyone konws why? pls help\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"anyone konws why? pls help\"\n  ]\n}\n```",
    "issue_url": "https://github.com/OSU-NLP-Group/HippoRAG/issues/114",
    "repo_size": 120,
    "size_category": "medium"
  },
  {
    "issue_number": 1282,
    "repo_name": "Josh-XT/AGiXT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"there may be a chance of false positives depending on the log level\",\n    \"this would be disabled by default but can be enabled within the GitHub extension\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"there may be a chance of\",\n    \"this would be disabled by default\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Josh-XT/AGiXT/issues/1282",
    "repo_size": 76,
    "size_category": "medium"
  },
  {
    "issue_number": 184,
    "repo_name": "PrefectHQ/ControlFlow",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Automatically generated by Colab.\",\n    \"Commented out IPython magic to ensure Python compatibility.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Automatically generated\",\n    \"Commented out\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/ControlFlow/issues/184",
    "repo_size": 61,
    "size_category": "medium"
  },
  {
    "issue_number": 861,
    "repo_name": "robusta-dev/holmesgpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"nested params are lost\",\n    \"known limitations or problems they plan to address\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"lost when going from\",\n    \"known limitations or problems\"\n  ]\n}\n```",
    "issue_url": "https://github.com/robusta-dev/holmesgpt/issues/861",
    "repo_size": 88,
    "size_category": "medium"
  },
  {
    "issue_number": 3429,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is a straightforward feature request without indications of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/3429",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 2706,
    "repo_name": "pytorch/torchtune",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"in order to enable these models in general, we need an interface allowing us to build a torchtune tokenizer from an arbitrary Hugging Face hub upload\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"we need an interface\",\n    \"allowing us to build\",\n    \"in order to enable\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pytorch/torchtune/issues/2706",
    "repo_size": 237,
    "size_category": "large"
  },
  {
    "issue_number": 2257,
    "repo_name": "embeddings-benchmark/mteb",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply references a model without indicating any known problems or areas needing future improvement.\"\n}\n```",
    "issue_url": "https://github.com/embeddings-benchmark/mteb/issues/2257",
    "repo_size": 301,
    "size_category": "large"
  },
  {
    "issue_number": 99,
    "repo_name": "LiveCodeBench/LiveCodeBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not express any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is primarily a request for clarification regarding the discrepancy between the number of samples in the release and the leaderboard, without indicating any known problems or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/LiveCodeBench/LiveCodeBench/issues/99",
    "repo_size": 86,
    "size_category": "medium"
  },
  {
    "issue_number": 1166,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Azure OpenAI can only be setup in system default LLM Preference.\",\n    \"But I want to specify it for a single workspace and realize that it is not available in the drop down list.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"can only be setup\",\n    \"want to specify\",\n    \"realize that it is not available\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/1166",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 100,
    "repo_name": "beir-cellar/beir",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It is primarily a request for clarification regarding the model and its checkpoint release, without any indication of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/beir-cellar/beir/issues/100",
    "repo_size": 149,
    "size_category": "medium"
  },
  {
    "issue_number": 1080,
    "repo_name": "OpenRLHF/OpenRLHF",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u4f46qwen3\u7684think\u5185\u5bb9\u53ea\u9488\u5bf9 **\u6700\u540e\u4e00\u4e2auser-message\u4e4b\u540e\u7684\u90a3\u4e9bai-message** \u624d\u62fc\u4e0a\",\n    \"\u56e0\u6b64\uff0c`process_data`\u4e2d\u83b7\u5f97\u7684`response_ranges`\u5728\u8fd9\u6837\u573a\u666f\u4e0b\u53ef\u80fd\u4e0d\u6b63\u786e\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u5904\u7406\u662f\u6839\u636e...\u8ba1\u7b97\u51fa\u8d77\u59cbidx\",\n    \"\u53ef\u80fd\u4e0d\u6b63\u786e\"\n  ]\n}\n```",
    "issue_url": "https://github.com/OpenRLHF/OpenRLHF/issues/1080",
    "repo_size": 361,
    "size_category": "large"
  },
  {
    "issue_number": 16948,
    "repo_name": "open-webui/open-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"If Image Generation Engine is set to OpenAI or Gemini, that parameter is not included in the request\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"not included in the request\",\n    \"should be sent in the request\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-webui/open-webui/issues/16948",
    "repo_size": 332,
    "size_category": "large"
  },
  {
    "issue_number": 698,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Sometimes the LLM gets carried away and writes gibberish for a long time.\",\n    \"Let's stop when we notice.\",\n    \"Accidentally clicking during a generation.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"gets carried away\",\n    \"writes gibberish\",\n    \"let's stop when we notice\",\n    \"accidentally clicking\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/698",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 2919,
    "repo_name": "crewAIInc/crewAI",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"This introduced multiple version conflicts and dependency issues\",\n    \"I had to manually upgrade llama-index just to make things work\",\n    \"I believe that embedchain might be getting pulled in indirectly through one of the upgraded dependencies, possibly without being declared explicitly\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"introduced multiple version conflicts\",\n    \"had to manually upgrade\",\n    \"might be getting pulled in indirectly\",\n    \"without being declared explicitly\"\n  ]\n}\n```",
    "issue_url": "https://github.com/crewAIInc/crewAI/issues/2919",
    "repo_size": 135,
    "size_category": "medium"
  },
  {
    "issue_number": 1671,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report describes a functional problem with the application but does not acknowledge any suboptimal solutions, known limitations, or technical shortcuts. The author does not indicate any awareness of technical debt or future improvements needed.\"\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/1671",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 1676,
    "repo_name": "h2oai/h2ogpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I don\u2019t have it in the application 'Web-Search integration with Chat and Document Q/A'\",\n    \"I don't have a function in my interface.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I don\u2019t have it\",\n    \"I don't have a function\",\n    \"How can I enable these additional features?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/h2oai/h2ogpt/issues/1676",
    "repo_size": 299,
    "size_category": "large"
  },
  {
    "issue_number": 8702,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\\\"[address=0.0.0.0:45015, pid=5038] The decoder prompt (length 134492) is longer than the maximum model length of 50000. Make sure that `max_model_len` is no smaller than the number of text tokens.\\\"\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"The decoder prompt (length 134492) is longer than the maximum model length of 50000.\",\n    \"Make sure that `max_model_len` is no smaller than the number of text tokens.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8702",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 162,
    "repo_name": "PromtEngineer/localGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is simply a question asking for guidance on how to restrict the program to one document.\"\n}\n```",
    "issue_url": "https://github.com/PromtEngineer/localGPT/issues/162",
    "repo_size": 194,
    "size_category": "medium"
  },
  {
    "issue_number": 161,
    "repo_name": "huggingface/optimum-benchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report describes a specific error encountered while running a benchmark with a timm model, but it does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. The author does not indicate any awareness of a temporary fix or future improvements needed, focusing instead on the error itself.\"\n}\n```",
    "issue_url": "https://github.com/huggingface/optimum-benchmark/issues/161",
    "repo_size": 60,
    "size_category": "medium"
  },
  {
    "issue_number": 37,
    "repo_name": "microsoft/sarathi-serve",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the figures in the sarathi-serve are mismatched with the paper\",\n    \"Figure 8 in the paper is about llama2-70b and mistral-7b, while in the osdi-sarathi-serve folder it's about falcon180b\",\n    \"the experiment contents also look mismatched\",\n    \"Other figures and corresponding scripts also mismatch\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"mismatched\",\n    \"look mismatched\",\n    \"also mismatch\"\n  ]\n}\n```",
    "issue_url": "https://github.com/microsoft/sarathi-serve/issues/37",
    "repo_size": 26,
    "size_category": "small"
  },
  {
    "issue_number": 2315,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"all options are grayed out\",\n    \"The options are operable.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"not closed\",\n    \"all options are grayed out\",\n    \"expected to happen\"\n  ]\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/2315",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 135,
    "repo_name": "qdrant/vector-db-benchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Some engines like ElasticSearch and OpenSearch take relatively longer to boot.\",\n    \"It would be nice to have the wait feature in-built in the benchmarking script.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"take relatively longer to boot\",\n    \"would be nice to have\"\n  ]\n}\n```",
    "issue_url": "https://github.com/qdrant/vector-db-benchmark/issues/135",
    "repo_size": 66,
    "size_category": "medium"
  },
  {
    "issue_number": 1221,
    "repo_name": "pydantic/logfire",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Extra boilerplate \u2013 no one-liner equivalent to `instrument_fastapi()`.\",\n    \"Shallower context \u2013 fewer automatic fields (request/response metadata, status codes, deadlines, latencies, exceptions).\",\n    \"Dependency friction \u2013 Logfire currently requires `5 <= protobuf < 6`, but my gRPC stack is built on protobuf \u2265 6. Downgrading protobuf just to use Logfire is painful\u2014any workaround or plan to address this?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I have to hand-roll interceptors and sprinkle `logfire.info` / `logfire.error` calls\",\n    \"no one-liner equivalent\",\n    \"fewer automatic fields\",\n    \"Downgrading protobuf just to use Logfire is painful\",\n    \"any workaround or plan to address this?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pydantic/logfire/issues/1221",
    "repo_size": 202,
    "size_category": "large"
  },
  {
    "issue_number": 1033,
    "repo_name": "GaiZhenbiao/ChuanhuChatGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily reports a bug related to the functionality of preset prompts without acknowledging any suboptimal solutions, temporary fixes, or areas needing future improvement. There are no indications of known limitations or technical shortcuts mentioned by the author.\"\n}\n```",
    "issue_url": "https://github.com/GaiZhenbiao/ChuanhuChatGPT/issues/1033",
    "repo_size": 305,
    "size_category": "large"
  },
  {
    "issue_number": 90,
    "repo_name": "AnswerDotAI/RAGatouille",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The index is created in './.ragatouille/colbert/indexes/index_name/' - how to choose this path?\",\n    \"It's at least not clear in the doc.\",\n    \"Having a name starting with '.' can be annoying, as you often do not see it\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"not clear in the doc\",\n    \"can be annoying\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AnswerDotAI/RAGatouille/issues/90",
    "repo_size": 196,
    "size_category": "medium"
  },
  {
    "issue_number": 4,
    "repo_name": "microsoft/promptbench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue is a straightforward request for clarification regarding the version of ChatGPT used in a paper. It does not express any acknowledgment of suboptimal solutions, limitations, or technical debt.\"\n}\n```",
    "issue_url": "https://github.com/microsoft/promptbench/issues/4",
    "repo_size": 63,
    "size_category": "medium"
  },
  {
    "issue_number": 650,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It primarily reports a specific bug related to a metaclass conflict without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/650",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 626,
    "repo_name": "adapter-hub/adapters",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. The author is seeking guidance on extending the framework and does not indicate any known issues or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/adapter-hub/adapters/issues/626",
    "repo_size": 161,
    "size_category": "medium"
  },
  {
    "issue_number": 414,
    "repo_name": "neo4j/neo4j-graphrag-python",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Not urgent but worth checking\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Not urgent but worth checking\"\n  ]\n}\n```",
    "issue_url": "https://github.com/neo4j/neo4j-graphrag-python/issues/414",
    "repo_size": 88,
    "size_category": "medium"
  },
  {
    "issue_number": 463,
    "repo_name": "AgentOps-AI/agentops",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"We currently support LlamaIndex integration but are missing docs\",\n    \"Add missing docs to LlamaIndex\",\n    \"Update LlamaIndex docs with AgentOps latest patterns and screenshots\",\n    \"Add LlamaIndex support to our own docs\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"documentation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"missing docs\",\n    \"add missing docs\",\n    \"update docs\",\n    \"add support\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AgentOps-AI/agentops/issues/463",
    "repo_size": 139,
    "size_category": "medium"
  },
  {
    "issue_number": 321,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply requests the addition of a metric without indicating any known problems or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/321",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 853,
    "repo_name": "castorini/pyserini",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"it's not make sense to let user install faiss/torch/onnxruntime etc.\",\n    \"we can utilize transformers utils `is_backend_avaliable` and `requires_backend` to dynamically import dependencies\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"it's not make sense\",\n    \"we can utilize\",\n    \"dynamically import dependencies\"\n  ]\n}\n```",
    "issue_url": "https://github.com/castorini/pyserini/issues/853",
    "repo_size": 104,
    "size_category": "medium"
  },
  {
    "issue_number": 193,
    "repo_name": "NVIDIA/TensorRT-Model-Optimizer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the amax that is set during the calibration step doesnt take into consideration block_sizes\",\n    \"this results into following error\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"doesnt take into consideration\",\n    \"results into following error\"\n  ]\n}\n```",
    "issue_url": "https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/193",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 42,
    "repo_name": "OSU-NLP-Group/HippoRAG",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. The author is seeking help for an error without indicating any known issues or plans for improvement.\"\n}\n```",
    "issue_url": "https://github.com/OSU-NLP-Group/HippoRAG/issues/42",
    "repo_size": 120,
    "size_category": "medium"
  },
  {
    "issue_number": 1264,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"TypeError: SFTTrainer.__init__() got an unexpected keyword argument 'dataset_text_field'\",\n    \"Is there any method of fixing this issue?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"unexpected keyword argument\",\n    \"Is there any method of fixing this issue?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/1264",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 1455,
    "repo_name": "ModelCloud/GPTQModel",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Key Mismatch:\",\n    \"The original key in self.named_parameters() is 'model.layers.21.mlp.experts.w2_qweight'.\",\n    \"The processed key in the quantized weight file is 'model.layers.21.mlp.experts.w2_weight'.\",\n    \"Error Cause:\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Key Mismatch:\",\n    \"Error Cause:\",\n    \"the code attempts to access param = params_dict[name], but the name from the weight file does not exist in params_dict\"\n  ]\n}\n```",
    "issue_url": "https://github.com/ModelCloud/GPTQModel/issues/1455",
    "repo_size": 123,
    "size_category": "medium"
  },
  {
    "issue_number": 112,
    "repo_name": "danny-avila/rag_api",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply requests the addition of a feature (cohere embers) without indicating any existing problems or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/danny-avila/rag_api/issues/112",
    "repo_size": 88,
    "size_category": "medium"
  },
  {
    "issue_number": 10234,
    "repo_name": "Significant-Gravitas/AutoGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Manual-setup triggers require special treatment because the user has to get the webhook ingress URL and use it to manually set up the webhook in the platform of their choice.\",\n    \"Most of the mechanism is there (as implemented in #10167), but there is no UI to display the URL yet.\",\n    \"Also, we have some warnings that manual-setup webhooks are not supported that we need to remove.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"require special treatment\",\n    \"there is no UI to display\",\n    \"warnings that manual-setup webhooks are not supported\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Significant-Gravitas/AutoGPT/issues/10234",
    "repo_size": 215,
    "size_category": "large"
  },
  {
    "issue_number": 629,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"ValueError(\\\"No results found\\\") breaks Ui\",\n    \"known limitations or problems they plan to address\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"breaks\",\n    \"No results found\",\n    \"known limitations\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/629",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 815,
    "repo_name": "h2oai/h2ogpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"make clickable vs. info buttons different color or otherwise styled differently\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"make ... different color\",\n    \"styled differently\"\n  ]\n}\n```",
    "issue_url": "https://github.com/h2oai/h2ogpt/issues/815",
    "repo_size": 299,
    "size_category": "large"
  },
  {
    "issue_number": 121,
    "repo_name": "qdrant/vector-db-benchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I saw relative code in github but no pgvector data in the https://qdrant.tech/benchmarks/\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I saw relative code\",\n    \"but no pgvector data\"\n  ]\n}\n```",
    "issue_url": "https://github.com/qdrant/vector-db-benchmark/issues/121",
    "repo_size": 66,
    "size_category": "medium"
  },
  {
    "issue_number": 28,
    "repo_name": "RUC-NLPIR/FlashRAG",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u589e\u5927\u8fd9\u4e9b\u53c2\u6570,\u5e76\u4e0d\u4f1a\u51cf\u5c11 `Retrieval process` \u6240\u6d88\u8017\u7684\u65f6\u95f4\",\n    \"\u867d\u7136\u6bcf\u4e00\u6b21`Retrieval process` \u7684\u6570\u91cf\u4ece14\u51cf\u5c0f\u52304\uff0c\u4f46\u603b\u4f53\u65f6\u95f4\u5e76\u4e0d\u4f1a\u7f29\u77ed\uff0c\u4ecd\u4e3a1\u5c0f\u65f6\u5de6\u53f3\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u6211\u6ce8\u610f\u5230\",\n    \"\u4f3c\u4e4e\",\n    \"\u5e76\u4e0d\u4f1a\",\n    \"\u867d\u7136\",\n    \"\u4ecd\u4e3a\"\n  ]\n}\n```",
    "issue_url": "https://github.com/RUC-NLPIR/FlashRAG/issues/28",
    "repo_size": 164,
    "size_category": "medium"
  },
  {
    "issue_number": 211,
    "repo_name": "ServiceNow/AgentLab",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"because in my organization we are using Python 3.13.\",\n    \"as per our internal policy we cannot downgrade or use another version of python.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"cannot downgrade\",\n    \"internal policy\"\n  ]\n}\n```",
    "issue_url": "https://github.com/ServiceNow/AgentLab/issues/211",
    "repo_size": 67,
    "size_category": "medium"
  },
  {
    "issue_number": 1907,
    "repo_name": "h2oai/h2ogpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"sed -i 's/with HiddenPrints():/if True:/g'\",\n    \"sed -i 's/client='ANDROID_MUSIC'/client='ANDROID'/g'\",\n    \"sed -i s/17.31.35/19.08.35/g\",\n    \"sed -i s/17.33.2/19.08.35/g\",\n    \"sed -i s/5.16.51/6.40.52/g\",\n    \"sed -i s/5.21/6.41/g\",\n    \"sed -i s/pytubefixfix/pytubefix/g\",\n    \"sed -i s/Pytube/PytubeFix/g\",\n    \"sed -i s/PytubeFixFix/PytubeFix/g\",\n    \"sed -i s/Pytube/Pytubefix/g\",\n    \"sed -i 's/pytube>=15/pytube>=6/g'\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"sed -i\",\n    \"s/old_value/new_value/g\",\n    \"temporary fixes\",\n    \"workarounds\"\n  ]\n}\n```",
    "issue_url": "https://github.com/h2oai/h2ogpt/issues/1907",
    "repo_size": 299,
    "size_category": "large"
  },
  {
    "issue_number": 1061,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u6bcf\u6b21cv\u8868\u73b0\u6700\u597d\u7684\u5c31\u662f\u7b2c2\u8f6e\",\n    \"\u4ece\u7b2c3\u8f6e\u5f00\u59cb\uff0c\u8bad\u7ec3loss \u6301\u7eed\u4e0b\u964d\uff0c\u800c\u9a8c\u8bc1loss\u6301\u7eed\u4e0a\u5347\",\n    \"change to 1e-5 during sft\",\n    \"change to constantlr during sft\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": [\n    \"performance\",\n    \"configuration\"\n  ],\n  \"LANGUAGE_PATTERNS\": [\n    \"\u603b\u662f\u5931\u8d25\",\n    \"\u6bcf\u6b21cv\u8868\u73b0\u6700\u597d\u7684\u5c31\u662f\",\n    \"\u6301\u7eed\u4e0b\u964d\uff0c\u800c\u9a8c\u8bc1loss\u6301\u7eed\u4e0a\u5347\",\n    \"change to\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/1061",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 195,
    "repo_name": "weaviate/Verba",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Query failed: 'NoneType' object is not iterable\",\n    \"Something went wrong: 'NoneType' object is not iterable\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Query failed\",\n    \"Something went wrong\"\n  ]\n}\n```",
    "issue_url": "https://github.com/weaviate/Verba/issues/195",
    "repo_size": 243,
    "size_category": "large"
  },
  {
    "issue_number": 287,
    "repo_name": "qwersyk/Newelle",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The behavior has also been observed on another machine using the official Flatpak.\",\n    \"The issue seems to be related to critical GTK errors, but no definitive confirmation has been established.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"seems to be related to\",\n    \"no definitive confirmation has been established\"\n  ]\n}\n```",
    "issue_url": "https://github.com/qwersyk/Newelle/issues/287",
    "repo_size": 133,
    "size_category": "medium"
  },
  {
    "issue_number": 893,
    "repo_name": "neuml/txtai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I am not sure whether this isn't user error\",\n    \"to reduce the probability of user error\",\n    \"despite me explicitly setting 'context=10' when creating the RAG pipeline\",\n    \"Did I make an error in setting up or applying the pipeline?\",\n    \"Is this a bug in the pipeline?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I am not sure\",\n    \"to reduce the probability of user error\",\n    \"explicitly setting\",\n    \"Did I make an error\",\n    \"Is this a bug\"\n  ]\n}\n```",
    "issue_url": "https://github.com/neuml/txtai/issues/893",
    "repo_size": 252,
    "size_category": "large"
  },
  {
    "issue_number": 91,
    "repo_name": "bigcode-project/bigcode-evaluation-harness",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently, the harness raises an exception when used with 8-bit models\",\n    \"seems like a check is needed for every .to call\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"raises an exception\",\n    \"seems like a check is needed\",\n    \"suggestions\"\n  ]\n}\n```",
    "issue_url": "https://github.com/bigcode-project/bigcode-evaluation-harness/issues/91",
    "repo_size": 159,
    "size_category": "medium"
  },
  {
    "issue_number": 388,
    "repo_name": "PrefectHQ/ControlFlow",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Seems to be deprecated and unused\",\n    \"brings a bit of confusion for starters\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"deprecated\",\n    \"unused\",\n    \"brings a bit of confusion\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/ControlFlow/issues/388",
    "repo_size": 61,
    "size_category": "medium"
  },
  {
    "issue_number": 208,
    "repo_name": "evalplus/evalplus",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It primarily provides information about the model and its usage without indicating any known issues or areas needing future improvement.\"\n}\n```",
    "issue_url": "https://github.com/evalplus/evalplus/issues/208",
    "repo_size": 206,
    "size_category": "large"
  },
  {
    "issue_number": 558,
    "repo_name": "assafelovic/gpt-researcher",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It would be good if we can add/modify this field as per default its not enabled.\",\n    \"Is there any way to do it on this current version manually?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"It would be good if\",\n    \"Is there any way to do it\",\n    \"as per default its not enabled\"\n  ]\n}\n```",
    "issue_url": "https://github.com/assafelovic/gpt-researcher/issues/558",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 52,
    "repo_name": "PKU-Alignment/safe-rlhf",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is a straightforward request for assistance in plotting a graph from a JSON file without any indication of known issues or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/PKU-Alignment/safe-rlhf/issues/52",
    "repo_size": 90,
    "size_category": "medium"
  },
  {
    "issue_number": 280,
    "repo_name": "ServiceNow/AgentLab",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Transformers and torch should be made optional to make the package lighter.\",\n    \"These can installed by user if needed.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"should be made optional\",\n    \"to make the package lighter\",\n    \"can installed by user if needed\"\n  ]\n}\n```",
    "issue_url": "https://github.com/ServiceNow/AgentLab/issues/280",
    "repo_size": 67,
    "size_category": "medium"
  },
  {
    "issue_number": 3369,
    "repo_name": "huggingface/trl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the completions are often empty or contain very unreasonable results\",\n    \"I don't know which parameter might be incorrectly set\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"often empty or contain very unreasonable results\",\n    \"I don't know which parameter might be incorrectly set\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/trl/issues/3369",
    "repo_size": 239,
    "size_category": "large"
  },
  {
    "issue_number": 27,
    "repo_name": "LiveCodeBench/LiveCodeBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily seeks clarification on how to use a function and does not acknowledge any suboptimal solutions, limitations, or technical shortcuts. There are no admissions of technical debt present in the content.\"\n}\n```",
    "issue_url": "https://github.com/LiveCodeBench/LiveCodeBench/issues/27",
    "repo_size": 86,
    "size_category": "medium"
  },
  {
    "issue_number": 69,
    "repo_name": "seratch/ChatGPT-in-Slack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"my following messages in the resulting thread are ignored by the bot.\",\n    \"sending messages in a thread does not even log anything.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"ignored by the bot\",\n    \"does not even log anything\"\n  ]\n}\n```",
    "issue_url": "https://github.com/seratch/ChatGPT-in-Slack/issues/69",
    "repo_size": 53,
    "size_category": "medium"
  },
  {
    "issue_number": 298,
    "repo_name": "father-bot/chatgpt_telegram_bot",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply states that the bot is not working without detailing any known issues or plans for improvement.\"\n}\n```",
    "issue_url": "https://github.com/father-bot/chatgpt_telegram_bot/issues/298",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 213,
    "repo_name": "bigcode-project/bigcode-evaluation-harness",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the process is hung and not moving forward\",\n    \"Rerun this multiple times, still the same\",\n    \"Could someone please check or let me know if I'm missing somethin?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"the process is hung\",\n    \"not moving forward\",\n    \"Rerun this multiple times\",\n    \"Could someone please check or let me know if I'm missing somethin?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/bigcode-project/bigcode-evaluation-harness/issues/213",
    "repo_size": 159,
    "size_category": "medium"
  },
  {
    "issue_number": 1637,
    "repo_name": "ModelCloud/GPTQModel",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not express any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is a straightforward question about how to achieve a specific functionality without indicating any known problems or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/ModelCloud/GPTQModel/issues/1637",
    "repo_size": 123,
    "size_category": "medium"
  },
  {
    "issue_number": 228,
    "repo_name": "AnswerDotAI/RAGatouille",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"For some reason, it says that RAGatouille is not installed, when in reality I have installed it.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"For some reason\",\n    \"when in reality I have installed it\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AnswerDotAI/RAGatouille/issues/228",
    "repo_size": 196,
    "size_category": "medium"
  },
  {
    "issue_number": 59,
    "repo_name": "LiveCodeBench/LiveCodeBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not express any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is a straightforward request for information regarding the completion of data collection for a release.\"\n}\n```",
    "issue_url": "https://github.com/LiveCodeBench/LiveCodeBench/issues/59",
    "repo_size": 86,
    "size_category": "medium"
  },
  {
    "issue_number": 451,
    "repo_name": "browser-use/web-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is a straightforward request for guidance on submitting a vulnerability report without any indication of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/browser-use/web-ui/issues/451",
    "repo_size": 353,
    "size_category": "large"
  },
  {
    "issue_number": 8325,
    "repo_name": "Significant-Gravitas/AutoGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue description is straightforward and does not indicate any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply outlines the desired functionality without mentioning any known issues or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/Significant-Gravitas/AutoGPT/issues/8325",
    "repo_size": 215,
    "size_category": "large"
  },
  {
    "issue_number": 99,
    "repo_name": "danny-avila/rag_api",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"it tries to run the `CREATE EXTENSION IF NOT EXISTS vector`, which fails because it isn't the database superuser\",\n    \"I cannot do that in production\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"fails because it isn't the database superuser\",\n    \"I cannot do that in production\"\n  ]\n}\n```",
    "issue_url": "https://github.com/danny-avila/rag_api/issues/99",
    "repo_size": 88,
    "size_category": "medium"
  },
  {
    "issue_number": 335,
    "repo_name": "browser-use/web-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I want to avoid login problems.\",\n    \"I tried this but it is not working, how to debug it?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I want to avoid login problems.\",\n    \"I tried this but it is not working\"\n  ]\n}\n```",
    "issue_url": "https://github.com/browser-use/web-ui/issues/335",
    "repo_size": 353,
    "size_category": "large"
  },
  {
    "issue_number": 714,
    "repo_name": "PromtEngineer/localGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the app crashes\",\n    \"I thought it was an issue with flask and tried waitress\",\n    \"the problem persisted\",\n    \"the langchain usage in this localgpt api app can't handle async requests\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"crashes the app\",\n    \"thought it was an issue\",\n    \"problem persisted\",\n    \"can't handle async requests\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PromtEngineer/localGPT/issues/714",
    "repo_size": 194,
    "size_category": "medium"
  },
  {
    "issue_number": 2664,
    "repo_name": "letta-ai/letta",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, or known limitations. The user is reporting a bug without indicating any awareness of technical debt or future improvements needed.\"\n}\n```",
    "issue_url": "https://github.com/letta-ai/letta/issues/2664",
    "repo_size": 134,
    "size_category": "medium"
  },
  {
    "issue_number": 2532,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"it could possibly that the GPU is being ignored as `gpustack/detectors/nvidia_smi/nvidia_smi.py` is reporting 0MB for total memory due to `nvidia-smi` in the container only reporting memory details at the MIG device level and not for the top level of the GPU / physical level (it reports N/A or Insufficient Permissions)\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"it could possibly\",\n    \"reporting 0MB for total memory\",\n    \"not for the top level of the GPU / physical level\",\n    \"Insufficient Permissions\"\n  ]\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/2532",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 620,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"uses deprecated `datasets.DownloadConfig.use_auth_token`\",\n    \"will break with datasets 3.0 release\",\n    \"the root cause is that `evaluate` uses `datasets.DownloadConfig.use_auth_token`, which was deprecated since datasets-2.14.0\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"uses deprecated\",\n    \"will break\",\n    \"deprecated since\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/620",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 346,
    "repo_name": "weaviate/Verba",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Import Socket is timing out after 1 minute\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"timing out\",\n    \"after 1 minute\"\n  ]\n}\n```",
    "issue_url": "https://github.com/weaviate/Verba/issues/346",
    "repo_size": 243,
    "size_category": "large"
  },
  {
    "issue_number": 1355,
    "repo_name": "Josh-XT/AGiXT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Add session to all endpoints\",\n    \"accept session on all classes that use the database\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Add\",\n    \"accept\",\n    \"all endpoints\",\n    \"all classes\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Josh-XT/AGiXT/issues/1355",
    "repo_size": 76,
    "size_category": "medium"
  },
  {
    "issue_number": 13,
    "repo_name": "kaarthik108/snowChat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Is there a possibility that this could use open source LLM?\",\n    \"OpenAi costs money and there are open source LLM's out there\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Is there a possibility\",\n    \"could use\",\n    \"costs money\",\n    \"there are open source LLM's out there\"\n  ]\n}\n```",
    "issue_url": "https://github.com/kaarthik108/snowChat/issues/13",
    "repo_size": 15,
    "size_category": "small"
  },
  {
    "issue_number": 457,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Seems like it is correct in main branch docs.\",\n    \"Maybe there are the bugs for docs publishing?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"documentation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Seems like\",\n    \"Maybe there are\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/457",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 261,
    "repo_name": "browser-use/web-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. The author is reporting an error without indicating any known debt or plans for improvement.\"\n}\n```",
    "issue_url": "https://github.com/browser-use/web-ui/issues/261",
    "repo_size": 353,
    "size_category": "large"
  },
  {
    "issue_number": 1849,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"can i by pass it plz?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"bypass\",\n    \"the issue is the connexion to HF\"\n  ]\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/1849",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 290,
    "repo_name": "PromtEngineer/localGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply poses a question about the usability of a specific hardware component for AI, without indicating any known problems or plans for improvement.\"\n}\n```",
    "issue_url": "https://github.com/PromtEngineer/localGPT/issues/290",
    "repo_size": 194,
    "size_category": "medium"
  },
  {
    "issue_number": 265,
    "repo_name": "father-bot/chatgpt_telegram_bot",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"this response is given by the bot to any request to the artist\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"something went wrong\",\n    \"this response is given\",\n    \"any request\"\n  ]\n}\n```",
    "issue_url": "https://github.com/father-bot/chatgpt_telegram_bot/issues/265",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 32,
    "repo_name": "entropy-research/Devon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It attempted to open a directory as a file and got stuck\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"attempted to open a directory as a file\",\n    \"got stuck\"\n  ]\n}\n```",
    "issue_url": "https://github.com/entropy-research/Devon/issues/32",
    "repo_size": 71,
    "size_category": "medium"
  },
  {
    "issue_number": 605,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"But in the code (`libs/ktem/ktem/index/file/graph/pipelines.py`), I just found the `LocalSearchMixedContext`\",\n    \"It means that global or local options in kotaemon UI are useless at this moment right?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I just found\",\n    \"It means that\",\n    \"are useless at this moment\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/605",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 2566,
    "repo_name": "camel-ai/camel",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily presents a feature request without acknowledging any suboptimal solutions, limitations, or technical shortcuts. There is no indication of existing technical debt or areas needing future improvement.\"\n}\n```",
    "issue_url": "https://github.com/camel-ai/camel/issues/2566",
    "repo_size": 200,
    "size_category": "large"
  },
  {
    "issue_number": 49,
    "repo_name": "OSU-NLP-Group/HippoRAG",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is primarily a request for clarification regarding missing files and their purpose.\"\n}\n```",
    "issue_url": "https://github.com/OSU-NLP-Group/HippoRAG/issues/49",
    "repo_size": 120,
    "size_category": "medium"
  },
  {
    "issue_number": 1513,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily seeks clarification on the training requirements for a multi-task scoring model and does not explicitly acknowledge any suboptimal solutions, limitations, or technical shortcuts. It poses questions about the necessity of certain tasks without indicating any known debt or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/1513",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 10,
    "repo_name": "evilpan/gptcli",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the model: `gpt-4` and `gpt-4-32k` does not exist\",\n    \"I made absolutely sure my local directory was updated to the latest version\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"does not exist\",\n    \"made absolutely sure\",\n    \"latest version\"\n  ]\n}\n```",
    "issue_url": "https://github.com/evilpan/gptcli/issues/10",
    "repo_size": 20,
    "size_category": "small"
  },
  {
    "issue_number": 3113,
    "repo_name": "mem0ai/mem0",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"local variable 'new_memories_with_actions' referenced before assignment\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"referenced before assignment\",\n    \"encountered an issue\",\n    \"error message states\"\n  ]\n}\n```",
    "issue_url": "https://github.com/mem0ai/mem0/issues/3113",
    "repo_size": 283,
    "size_category": "large"
  },
  {
    "issue_number": 4146,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"restrict access like the default role but still allow them to upload files\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"want to be able to\",\n    \"still allow\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/4146",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 226,
    "repo_name": "topoteretes/cognee",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"suboptimal solutions\",\n    \"temporary fixes\",\n    \"known limitations\",\n    \"technical shortcuts\",\n    \"areas needing future improvement\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"acknowledge\",\n    \"plan to address\",\n    \"workarounds\",\n    \"needing future improvement\"\n  ]\n}\n```",
    "issue_url": "https://github.com/topoteretes/cognee/issues/226",
    "repo_size": 74,
    "size_category": "medium"
  },
  {
    "issue_number": 2980,
    "repo_name": "PaddlePaddle/FastDeploy",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"UserWarning\",\n    \"deprecated\",\n    \"Support for replacing an already imported distutils is deprecated.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PaddlePaddle/FastDeploy/issues/2980",
    "repo_size": 137,
    "size_category": "medium"
  },
  {
    "issue_number": 58,
    "repo_name": "bigcode-project/bigcode-evaluation-harness",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"this would be a bigger refactoring\",\n    \"it'd be better to save generations after each generation is done\",\n    \"offer restarting from previously unfinished generations\",\n    \"just leaving this here if someone is interested\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"would be better\",\n    \"bigger refactoring\",\n    \"if it's interrupted or sth\"\n  ]\n}\n```",
    "issue_url": "https://github.com/bigcode-project/bigcode-evaluation-harness/issues/58",
    "repo_size": 159,
    "size_category": "medium"
  },
  {
    "issue_number": 18656,
    "repo_name": "PrefectHQ/prefect",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Integrations SDK docs are generated via `mkdocs` and hosted via Netlify.\",\n    \"Use `mdxify` to generate API reference documentation for integration libraries and host them in Mintlify.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"current behavior\",\n    \"proposed behavior\",\n    \"use ... to\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/prefect/issues/18656",
    "repo_size": 289,
    "size_category": "large"
  },
  {
    "issue_number": 101,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not express any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is a straightforward request for clarification on how to upload results, without any indication of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/101",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 794,
    "repo_name": "neuml/txtai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"There are a couple places that use `hf_hub_download` instead of `cached_file`.\",\n    \"This should be switched to ensure models stored in local directories are supported.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"should be switched\",\n    \"instead of\"\n  ]\n}\n```",
    "issue_url": "https://github.com/neuml/txtai/issues/794",
    "repo_size": 252,
    "size_category": "large"
  },
  {
    "issue_number": 398,
    "repo_name": "openml/automlbenchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"My team had a very confusing time when `-m aws -s force` caused the IAM role of AutomlBenchmarkRole to be deleted and recreated\",\n    \"Could this be better documented?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"documentation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"confusing time\",\n    \"could this be better documented\"\n  ]\n}\n```",
    "issue_url": "https://github.com/openml/automlbenchmark/issues/398",
    "repo_size": 165,
    "size_category": "medium"
  },
  {
    "issue_number": 14632,
    "repo_name": "open-webui/open-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"All tools are disabled and need to be manually toggled on.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"need to be manually toggled on\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-webui/open-webui/issues/14632",
    "repo_size": 332,
    "size_category": "large"
  },
  {
    "issue_number": 8749,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u5e0c\u671b\u80fd\u591f\u652f\u6301\uff0c\u8c22\u8c22\uff01\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u5e0c\u671b\u80fd\u591f\u652f\u6301\",\n    \"\u65e0\u6cd5\u4f7f\u7528\"\n  ]\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8749",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 1155,
    "repo_name": "livekit/agents",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Interestingly, the same functionality works correctly with OpenAI's function calling.\",\n    \"When an exception is raised in Azure OpenAI function calling, no response is emitted, causing the application to remain silent.\",\n    \"To address this issue, I implemented a solution in which any exception raised is explicitly emitted.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"fails during function calling\",\n    \"no response is emitted\",\n    \"I implemented a solution\",\n    \"allows my code to\"\n  ]\n}\n```",
    "issue_url": "https://github.com/livekit/agents/issues/1155",
    "repo_size": 297,
    "size_category": "large"
  },
  {
    "issue_number": 3709,
    "repo_name": "stanford-crfm/helm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"unexpected behavior in how HELM handles the prod_env directory\",\n    \"which seems to be auto-created and then overrides otherwise correct configurations\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"unexpected behavior\",\n    \"overrides otherwise correct configurations\"\n  ]\n}\n```",
    "issue_url": "https://github.com/stanford-crfm/helm/issues/3709",
    "repo_size": 157,
    "size_category": "medium"
  },
  {
    "issue_number": 17,
    "repo_name": "AmenRa/ranx",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"you only keep one `metric` while iterating over `metrics` (overwriting the previous `metric` in each loop)\",\n    \"replace the line above with:\",\n    \"init `d[m1][\\\"win_tie_loss\\\"][m2] = {}` at the same place as\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"you only keep one `metric`\",\n    \"overwriting the previous `metric`\",\n    \"replace the line above with\",\n    \"init ... at the same place as\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AmenRa/ranx/issues/17",
    "repo_size": 62,
    "size_category": "medium"
  },
  {
    "issue_number": 3326,
    "repo_name": "crewAIInc/crewAI",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I believe the same is required within crew base.\",\n    \"Failed to initialize MCP Adapter: Couldn't connect to the MCP server after 30 seconds\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I believe the same is required\",\n    \"default timeout of 30 seconds\",\n    \"Failed to initialize MCP Adapter\"\n  ]\n}\n```",
    "issue_url": "https://github.com/crewAIInc/crewAI/issues/3326",
    "repo_size": 135,
    "size_category": "medium"
  },
  {
    "issue_number": 412,
    "repo_name": "Lightning-AI/LitServe",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently, enabling batching in LitServe (by setting `max_batch_size` and `batch_timeout`) changes the expected implementation of the `predict` method in `LitAPI` subclasses.\",\n    \"This creates several issues:\",\n    \"The same API implementation behaves differently based on server configuration parameters.\",\n    \"Developers need to maintain different implementations or add conditional logic based on whether batching is enabled.\",\n    \"It violates the principle of separation of concerns - server configuration parameters should not affect the API contract.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation, design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Currently, enabling batching... changes the expected implementation\",\n    \"This creates several issues\",\n    \"Developers need to maintain different implementations\",\n    \"It violates the principle of separation of concerns\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Lightning-AI/LitServe/issues/412",
    "repo_size": 69,
    "size_category": "medium"
  },
  {
    "issue_number": 676,
    "repo_name": "InternLM/xtuner",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. The user is inquiring about a warning they encountered, but they do not indicate any awareness of underlying technical debt or plans to address it.\"\n}\n```",
    "issue_url": "https://github.com/InternLM/xtuner/issues/676",
    "repo_size": 344,
    "size_category": "large"
  },
  {
    "issue_number": 86,
    "repo_name": "NVIDIA/TensorRT-Model-Optimizer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Any chance you will provide a Docker container for ARM64 compatibility?\",\n    \"The main issue here is that TensorRT-LLM is not compatible with my ARM64 (aarch64) architecture.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Any chance you will provide\",\n    \"not compatible with\"\n  ]\n}\n```",
    "issue_url": "https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/86",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 4249,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"we need to expose the `tenant` and `databaseName` fields to be configurable by the user\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"we need to\",\n    \"to be configurable\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/4249",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 264,
    "repo_name": "bigcode-project/bigcode-evaluation-harness",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The following values were not passed to `accelerate launch` and had defaults used instead:\",\n    \"`--num_processes` was set to a value of `1`\",\n    \"`--num_machines` was set to a value of `1`\",\n    \"`--mixed_precision` was set to a value of `'no'`\",\n    \"`--dynamo_backend` was set to a value of `'no'`\",\n    \"To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"The following values were not passed\",\n    \"had defaults used instead\",\n    \"To avoid this warning pass in values for each of the problematic parameters\"\n  ]\n}\n```",
    "issue_url": "https://github.com/bigcode-project/bigcode-evaluation-harness/issues/264",
    "repo_size": 159,
    "size_category": "medium"
  },
  {
    "issue_number": 347,
    "repo_name": "potpie-ai/potpie",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Consider potential edge cases in email formats.\",\n    \"Ensure that validation does not significantly impact performance during high-concurrency situations.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation, performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Consider potential edge cases\",\n    \"Ensure that validation does not significantly impact performance\"\n  ]\n}\n```",
    "issue_url": "https://github.com/potpie-ai/potpie/issues/347",
    "repo_size": 64,
    "size_category": "medium"
  },
  {
    "issue_number": 617,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It is a request for clarification regarding the dataset mentioned in the paper, rather than an admission of technical debt.\"\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/617",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 2608,
    "repo_name": "embeddings-benchmark/mteb",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Might be able to wrangle this into [a workshop paper at ICML]\",\n    \"we will probably have to check\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Might be able to\",\n    \"we will probably have to check\"\n  ]\n}\n```",
    "issue_url": "https://github.com/embeddings-benchmark/mteb/issues/2608",
    "repo_size": 301,
    "size_category": "large"
  },
  {
    "issue_number": 9063,
    "repo_name": "Significant-Gravitas/AutoGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I disabled it for now as it was not properly implemented.\",\n    \"The toggle should be moved to the users profile page/settings page and it should save the state to the users account.\",\n    \"we need to make sure every single page and UI element is updated correctly.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"disabled it for now\",\n    \"not properly implemented\",\n    \"should be moved\",\n    \"should save the state\",\n    \"need to make sure\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Significant-Gravitas/AutoGPT/issues/9063",
    "repo_size": 215,
    "size_category": "large"
  },
  {
    "issue_number": 8959,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u6211\u628atemplate\u4ecellava\u6362\u6210qwen2-vl\uff0c\u5e76\u66f4\u6362qwen model\u540e\u53ef\u4ee5\u6b63\u5e38\u5fae\u8c03\uff0c\u4f46\u662f\u4f7f\u7528llava\u5fae\u8c03\u9047\u5230\u5982\u4e0b\u62a5\u9519\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u6211\u628atemplate\u4ecellava\u6362\u6210qwen2-vl\",\n    \"\u53ef\u4ee5\u6b63\u5e38\u5fae\u8c03\uff0c\u4f46\u662f\u4f7f\u7528llava\u5fae\u8c03\u9047\u5230\u5982\u4e0b\u62a5\u9519\"\n  ]\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/8959",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 1882,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report describes a bug without acknowledging any suboptimal solutions, temporary fixes, or known limitations. There are no indications of technical shortcuts or areas needing future improvement.\"\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/1882",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 736,
    "repo_name": "OpenRLHF/OpenRLHF",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"RuntimeError: The size of tensor a (128) must match the size of tensor b (1698) at non-singleton dimension 4\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"RuntimeError\",\n    \"must match the size of tensor\",\n    \"known limitations or problems\"\n  ]\n}\n```",
    "issue_url": "https://github.com/OpenRLHF/OpenRLHF/issues/736",
    "repo_size": 361,
    "size_category": "large"
  },
  {
    "issue_number": 7403,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily describes a discrepancy in scoring between two methods of model evaluation without explicitly acknowledging any suboptimal solutions, limitations, or technical shortcuts. The author is seeking clarification on the observed behavior rather than admitting to any technical debt.\"\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/7403",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 4066,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It primarily requests features related to the Gemini models without indicating any known debt or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/4066",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 1123,
    "repo_name": "open-compass/VLMEvalKit",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. The author is reporting an error without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/open-compass/VLMEvalKit/issues/1123",
    "repo_size": 212,
    "size_category": "large"
  },
  {
    "issue_number": 240,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"Workaround would appear to be to separately download and install ollama complete setup.\",\n    \"I was hoping to continue to work 'within kotaemon' instead of laying external pieces.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Workaround would appear to be\",\n    \"I was hoping to continue to work\",\n    \"instead of laying external pieces\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/240",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 9010,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u5176\u6838\u5fc3\u903b\u8f91\u4e3a\u5747\u5300\u5206\u5e03\u9009\u62e9\u5c42\",\n    \"\u5219\u5e94\u4e3a\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u5e94\u4e3a\",\n    \"\u5176\u6838\u5fc3\u903b\u8f91\u4e3a\"\n  ]\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/9010",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 277,
    "repo_name": "InternLM/HuixiangDou",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u5728\u4e0a\u9762\u7b2c2\u6b65\u52a0\u4e86`--standalone` \u4e5f\u65e0\u6d4e\u4e8e\u4e8b\",\n    \"Hybrid-LLM\u73af\u5883\u4e0b\u53ef\u4ee5\u6b63\u5e38\u8fd0\u884c\uff0c\u4e0d\u8fc7\u4f3c\u4e4e\u6ca1\u6709\u8c03\u7528deepseek API\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u4e5f\u65e0\u6d4e\u4e8e\u4e8b\",\n    \"\u4e0d\u8fc7\u4f3c\u4e4e\u6ca1\u6709\"\n  ]\n}\n```",
    "issue_url": "https://github.com/InternLM/HuixiangDou/issues/277",
    "repo_size": 44,
    "size_category": "small"
  },
  {
    "issue_number": 2344,
    "repo_name": "camel-ai/camel",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is primarily a feature request without indications of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/camel-ai/camel/issues/2344",
    "repo_size": 200,
    "size_category": "large"
  },
  {
    "issue_number": 8834,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u5728\u6a21\u578b\u670d\u52a1\u5546azure openai\u4e2d\u66f4\u65b0\u6a21\u578b\u5217\u8868\u4e5f\u6ca1\u6709\u6700\u65b0\u7684gpt-5\",\n    \"\u624b\u52a8\u6dfb\u52a0\u65f6\u6ca1\u6709\u6a21\u578b\u662f\u5426\u6709\u5185\u7f6e\u641c\u7d22\u5f15\u64ce\u7684\u9009\u9879\",\n    \"\u53ea\u80fd\u4f7f\u7528\u667a\u80fd\u8054\u7f51 \u5173\u95ed\u53ea\u80fd\u8054\u7f51\u540e\u4f1a\u8fd4\u56de504\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u6ca1\u6709\u6700\u65b0\u7684gpt-5\",\n    \"\u6ca1\u6709\u6a21\u578b\u662f\u5426\u6709\u5185\u7f6e\u641c\u7d22\u5f15\u64ce\u7684\u9009\u9879\",\n    \"\u8fd4\u56de504\"\n  ]\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8834",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 1225,
    "repo_name": "openaccess-ai-collective/axolotl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Seems like when you train with this parameter, there's no evaluation stage after last training step.\",\n    \"Intuitively it should distribute evaluations in a such a way so the latest evaluating happens after last training step.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Seems like\",\n    \"Intuitively it should\"\n  ]\n}\n```",
    "issue_url": "https://github.com/axolotl-ai-cloud/axolotl/issues/1225",
    "repo_size": 193,
    "size_category": "medium"
  },
  {
    "issue_number": 3020,
    "repo_name": "livekit/agents",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"if there are ongoing sip phone calls using LiveKit Cloud WebSockets, those calls may get dropped when the pod handling them is shut down.\",\n    \"Is there a recommended way to handle this scenario gracefully?\",\n    \"Does LiveKit support session persistence mechanisms such as sticky sessions, session resumption, or any other strategy to prevent disruption during pod upgrades?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"may get dropped\",\n    \"recommended way to handle this scenario gracefully\",\n    \"support session persistence mechanisms\"\n  ]\n}\n```",
    "issue_url": "https://github.com/livekit/agents/issues/3020",
    "repo_size": 297,
    "size_category": "large"
  },
  {
    "issue_number": 760,
    "repo_name": "OpenRLHF/OpenRLHF",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I\u2019m having trouble understanding why this constraint is necessary.\",\n    \"It seems counterintuitive for the actor and vllm model to share GPU resources.\"\n  ],\n  \"WHO_ADMITS\": \"Issue author\",\n  \"DEBT_TYPE\": \"design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"having trouble understanding\",\n    \"seems counterintuitive\"\n  ]\n}\n```",
    "issue_url": "https://github.com/OpenRLHF/OpenRLHF/issues/760",
    "repo_size": 361,
    "size_category": "large"
  },
  {
    "issue_number": 116,
    "repo_name": "AnswerDotAI/RAGatouille",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"when trying to prepare training data without mining hard negatives\",\n    \"it tries to set the min_rank for the miner but there is no miner\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"when trying to prepare training data without mining hard negatives\",\n    \"it tries to set the min_rank for the miner but there is no miner\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AnswerDotAI/RAGatouille/issues/116",
    "repo_size": 196,
    "size_category": "medium"
  },
  {
    "issue_number": 353,
    "repo_name": "PrefectHQ/ControlFlow",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I find it muddy figuring out whether controlflow can handle both cases, or if I need prefect for for the former, and controlflow for the later.\",\n    \"I find the difference between the prefect core library flow and task decorators / functions, and the controlflow library flow and task decorators / definitions to be confusing to differentiate in documentation, and to implement when both are needed.\",\n    \"LLM code assistants also get totally confused and conflate both libraries, even when providing the docs as context.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"confusion\",\n    \"muddy figuring out\",\n    \"confusing to differentiate\",\n    \"get totally confused and conflate\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/ControlFlow/issues/353",
    "repo_size": 61,
    "size_category": "medium"
  },
  {
    "issue_number": 221,
    "repo_name": "father-bot/chatgpt_telegram_bot",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is simply a request for information about increasing a message memory limit without indicating any known problems or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/father-bot/chatgpt_telegram_bot/issues/221",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 1314,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the instruct2 call is that it doesn't really capture the characteristics of the prompt speech\",\n    \"the synthesized speech is wildly off the prompt speech characteristics\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"doesn't really capture\",\n    \"wildly off\",\n    \"am I missing something here?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/1314",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 162,
    "repo_name": "jekalmin/extended_openai_conversation",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I can't make the complete switch to assist because I can't find the way to make the result of a script or automation that is not started from a device pronounced.\",\n    \"Do you know a way to achieve this using Assist?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I can't make the complete switch\",\n    \"I can't find the way\",\n    \"Do you know a way to achieve this\"\n  ]\n}\n```",
    "issue_url": "https://github.com/jekalmin/extended_openai_conversation/issues/162",
    "repo_size": 226,
    "size_category": "large"
  },
  {
    "issue_number": 190,
    "repo_name": "NVIDIA/TensorRT-Model-Optimizer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not express any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply asks for clarification on the differences between two configurations without indicating any known problems or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/190",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 1021,
    "repo_name": "pydantic/logfire",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It would be nice to have an ability to generate URLs that display records for a given `trace_id` using the usual UI.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"It would be nice to have\",\n    \"ability to generate\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pydantic/logfire/issues/1021",
    "repo_size": 202,
    "size_category": "large"
  },
  {
    "issue_number": 6308,
    "repo_name": "janhq/jan",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"wipes the conversation instead of handling the missing model gracefully\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"instead of handling\",\n    \"missing model gracefully\"\n  ]\n}\n```",
    "issue_url": "https://github.com/menloresearch/jan/issues/6308",
    "repo_size": 267,
    "size_category": "large"
  },
  {
    "issue_number": 13070,
    "repo_name": "open-webui/open-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the columns allocated to each model's output are quite narrow\",\n    \"This significantly hinders the reading experience\",\n    \"the current layout of the model selection/switching elements at the top of the comparison view occupies considerable vertical screen real estate\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"narrow columns\",\n    \"significantly hinders\",\n    \"occupies considerable vertical screen real estate\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-webui/open-webui/issues/13070",
    "repo_size": 332,
    "size_category": "large"
  },
  {
    "issue_number": 9525,
    "repo_name": "Significant-Gravitas/AutoGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This is NOT GOOD because that means our users cannot see the entire list of agents that are available on our platform.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"This is NOT GOOD\",\n    \"missing\",\n    \"cannot see\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Significant-Gravitas/AutoGPT/issues/9525",
    "repo_size": 215,
    "size_category": "large"
  },
  {
    "issue_number": 3974,
    "repo_name": "huggingface/trl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"invalid configuration error\",\n    \"known limitations or problems they plan to address\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"invalid configuration error\",\n    \"known limitations\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/trl/issues/3974",
    "repo_size": 239,
    "size_category": "large"
  },
  {
    "issue_number": 111,
    "repo_name": "NVIDIA/TensorRT-Model-Optimizer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This version of the ONNX parser only supports TensorRT INetworkDefinitions with an explicit batch dimension.\",\n    \"The implicit batch dimension mode has been deprecated.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"only supports\",\n    \"has been deprecated\",\n    \"doesn't support\",\n    \"ensure the network was created using\"\n  ]\n}\n```",
    "issue_url": "https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/111",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 1216,
    "repo_name": "FoundationAgents/MetaGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"the repair mechanism was not triggered\",\n    \"it didn't work\",\n    \"the model generated incorrect JSON response\",\n    \"the parser did not match the regex\",\n    \"the logger reported an error, then directly returned the incorrectly formatted text\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"not triggered\",\n    \"did not match\",\n    \"reported an error\",\n    \"incorrectly formatted text\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FoundationAgents/MetaGPT/issues/1216",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 7084,
    "repo_name": "oobabooga/text-generation-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It would be helpful when returning to old chats to be able to see which model was used to generate a reply.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"It would be helpful\",\n    \"to be able to see\",\n    \"which model was used\"\n  ]\n}\n```",
    "issue_url": "https://github.com/oobabooga/text-generation-webui/issues/7084",
    "repo_size": 339,
    "size_category": "large"
  },
  {
    "issue_number": 680,
    "repo_name": "neuml/txtai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"'CustomStreamWrapper' object is not subscriptable\",\n    \"this works fine\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Error is thrown\",\n    \"this works fine\"\n  ]\n}\n```",
    "issue_url": "https://github.com/neuml/txtai/issues/680",
    "repo_size": 252,
    "size_category": "large"
  },
  {
    "issue_number": 1373,
    "repo_name": "FlagOpen/FlagEmbedding",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not explicitly acknowledge any suboptimal solutions, limitations, or technical shortcuts. It primarily raises a question about the normalization of output scores without indicating any known problems or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/FlagOpen/FlagEmbedding/issues/1373",
    "repo_size": 371,
    "size_category": "large"
  },
  {
    "issue_number": 3010,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Any known issues or limitations when using Unsloth to fine-tune Med-Gemma 3 with QLoRA or LoRA?\",\n    \"Are there recommended configurations or examples for this use case?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration, implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"known issues or limitations\",\n    \"recommended configurations or examples\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/3010",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 1467,
    "repo_name": "FlagOpen/FlagEmbedding",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I notice that this package publishes only source distributions, so that every user has to build the wheel themselves.\",\n    \"Better for package owners to build and publish wheels once and for all.\",\n    \"I did not find a workflow in this repository for publishing or I would have submitted a pull request.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I notice that\",\n    \"Better for\",\n    \"I did not find a workflow\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FlagOpen/FlagEmbedding/issues/1467",
    "repo_size": 371,
    "size_category": "large"
  },
  {
    "issue_number": 346,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Maybe this is already implemented? In which case the docs just need updating.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"documentation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Maybe this is already implemented?\",\n    \"In which case the docs just need updating.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/346",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 1474,
    "repo_name": "FlagOpen/FlagEmbedding",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply poses a question about future support for a specific feature without indicating any existing problems or debts.\"\n}\n```",
    "issue_url": "https://github.com/FlagOpen/FlagEmbedding/issues/1474",
    "repo_size": 371,
    "size_category": "large"
  },
  {
    "issue_number": 2475,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It primarily describes an error encountered during deployment without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/2475",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 1188,
    "repo_name": "FlagOpen/FlagEmbedding",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, temporary fixes, known limitations, or technical shortcuts. It simply reports an error without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/FlagOpen/FlagEmbedding/issues/1188",
    "repo_size": 371,
    "size_category": "large"
  },
  {
    "issue_number": 397,
    "repo_name": "Lightning-AI/LitServe",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently trying to implement my own spec but the only thing I can do is check if hat been set and raise an exception.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Currently trying to implement my own spec but the only thing I can do is check if hat been set and raise an exception.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Lightning-AI/LitServe/issues/397",
    "repo_size": 69,
    "size_category": "medium"
  },
  {
    "issue_number": 6131,
    "repo_name": "janhq/jan",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It focuses on goals and success criteria without indicating any known problems or areas needing future improvement.\"\n}\n```",
    "issue_url": "https://github.com/menloresearch/jan/issues/6131",
    "repo_size": 267,
    "size_category": "large"
  },
  {
    "issue_number": 7037,
    "repo_name": "oobabooga/text-generation-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Could we have the 'xxx ms per token' and 'xxx tokens per second' stats from the logs\",\n    \"Maybe a new node called 'stats' or so!\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Could we have\",\n    \"Maybe a new node called\"\n  ]\n}\n```",
    "issue_url": "https://github.com/oobabooga/text-generation-webui/issues/7037",
    "repo_size": 339,
    "size_category": "large"
  },
  {
    "issue_number": 20,
    "repo_name": "HKUDS/Auto-Deep-Research",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"comand 'COMPLETION_MODEL=openrouter/deepseek/deepseek-r1 auto deep-research' does not work properly\",\n    \"\u65e0\u6cd5\u5c06\u201cCOMPLETION_MODEL=openrouter/deepseek/deepseek-r1\u201d\u9879\u8bc6\u522b\u4e3a c mdlet\u3001\u51fd\u6570\u3001\u811a\u672c\u6587\u4ef6\u6216\u53ef\u8fd0\u884c\u7a0b\u5e8f\u7684\u540d\u79f0\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"does not work properly\",\n    \"\u65e0\u6cd5\u5c06...\u9879\u8bc6\u522b\u4e3a\"\n  ]\n}\n```",
    "issue_url": "https://github.com/HKUDS/Auto-Deep-Research/issues/20",
    "repo_size": 32,
    "size_category": "small"
  },
  {
    "issue_number": 790,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. The author is seeking help for a specific error without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/790",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 8,
    "repo_name": "ricklamers/shell-ai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"to automatically fix errors or have a kind of chat history\",\n    \"it could be helpful to have the console output visible to the LLM or at least a part of it (1-2k tokens)\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"could be helpful\",\n    \"to automatically fix errors\",\n    \"at least a part of it\"\n  ]\n}\n```",
    "issue_url": "https://github.com/ricklamers/shell-ai/issues/8",
    "repo_size": 24,
    "size_category": "small"
  },
  {
    "issue_number": 1151,
    "repo_name": "open-compass/VLMEvalKit",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model.\",\n    \"This will result in minor differences in outputs.\",\n    \"You'll still be able to use a slow processor with `use_fast=False`.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Using a slow image processor\",\n    \"will result in minor differences in outputs\",\n    \"still be able to use a slow processor\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-compass/VLMEvalKit/issues/1151",
    "repo_size": 212,
    "size_category": "large"
  },
  {
    "issue_number": 14,
    "repo_name": "beir-cellar/beir",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. The author is simply asking for clarification about the dataset, without indicating any awareness of issues that need to be addressed.\"\n}\n```",
    "issue_url": "https://github.com/beir-cellar/beir/issues/14",
    "repo_size": 149,
    "size_category": "medium"
  },
  {
    "issue_number": 365,
    "repo_name": "SWE-bench/SWE-bench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"But what about alternatives to `GitHub`?\",\n    \"Would it be feasible to abstract the Repository/Tracker source, and use `Gitea` or `GitLab` instead?\",\n    \"Or is the entire design concept for `SWE-Agent` pinned to `GitHub` in some immutable way?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"what about alternatives\",\n    \"feasible to abstract\",\n    \"pinned to `GitHub` in some immutable way\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SWE-bench/SWE-bench/issues/365",
    "repo_size": 199,
    "size_category": "medium"
  },
  {
    "issue_number": 668,
    "repo_name": "mlcommons/algorithmic-efficiency",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This trivial error should be easy to fix for the author of this python-file.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"obvious number of arguments mismatch\",\n    \"trivial error should be easy to fix\"\n  ]\n}\n```",
    "issue_url": "https://github.com/mlcommons/algorithmic-efficiency/issues/668",
    "repo_size": 78,
    "size_category": "medium"
  },
  {
    "issue_number": 2252,
    "repo_name": "livekit/agents",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It is a straightforward request for configuration guidance without any indication of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/livekit/agents/issues/2252",
    "repo_size": 297,
    "size_category": "large"
  },
  {
    "issue_number": 1687,
    "repo_name": "griptape-ai/griptape",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I was confused by the example.\",\n    \"If this confused me, it will likely confuse others, and may lead to more/duplicated github issues.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"confused by the example\",\n    \"may lead to more/duplicated github issues\"\n  ]\n}\n```",
    "issue_url": "https://github.com/griptape-ai/griptape/issues/1687",
    "repo_size": 90,
    "size_category": "medium"
  },
  {
    "issue_number": 134,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It seems that currently only CPU is used for interference on Mac.\",\n    \"It would be nice to support GPU accelerated inference for MacOS apple silicon chip.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"It seems that\",\n    \"would be nice to support\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/134",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 830,
    "repo_name": "neuml/txtai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results.\",\n    \"I'm unsure what is causing the issue.\",\n    \"It may be related to the fact that txtai is installing torch-cpu and faiss-cpu despite my system having a GPU.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": [\n    \"configuration\",\n    \"performance\",\n    \"implementation\"\n  ],\n  \"LANGUAGE_PATTERNS\": [\n    \"unsafe, unsupported, undocumented workaround\",\n    \"unsure what is causing the issue\",\n    \"may be related to the fact\"\n  ]\n}\n```",
    "issue_url": "https://github.com/neuml/txtai/issues/830",
    "repo_size": 252,
    "size_category": "large"
  },
  {
    "issue_number": 1255,
    "repo_name": "assafelovic/gpt-researcher",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"During the final step of handleChat execution, a WebSocket error will occur\",\n    \"who knows what the problem is\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"will occur\",\n    \"who knows what the problem is\"\n  ]\n}\n```",
    "issue_url": "https://github.com/assafelovic/gpt-researcher/issues/1255",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 191,
    "repo_name": "NVIDIA/TensorRT-Model-Optimizer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"mapping.py since ... has been deprecated\",\n    \"Although ONNX has not released this change yet, I faced this trouble while quantizing a LLM to NVFP4 precision\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"has been deprecated\",\n    \"faced this trouble\",\n    \"requires me to yet-to-be-released version\"\n  ]\n}\n```",
    "issue_url": "https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/191",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 389,
    "repo_name": "SWE-bench/SWE-bench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"the jsonl loading is wrong and results in a json decoding error\",\n    \"This should be replaced with something like this:\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"json loading is wrong\",\n    \"results in a json decoding error\",\n    \"should be replaced with something like this\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SWE-bench/SWE-bench/issues/389",
    "repo_size": 199,
    "size_category": "medium"
  },
  {
    "issue_number": 157,
    "repo_name": "intel/auto-round",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"AutoRound currently does not support numpy2x.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"currently does not support\",\n    \"not support\"\n  ]\n}\n```",
    "issue_url": "https://github.com/intel/auto-round/issues/157",
    "repo_size": 94,
    "size_category": "medium"
  },
  {
    "issue_number": 1358,
    "repo_name": "assafelovic/gpt-researcher",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report only states a specific error message without any acknowledgment of suboptimal solutions, limitations, or plans for future improvements. It does not indicate any awareness of technical debt.\"\n}\n```",
    "issue_url": "https://github.com/assafelovic/gpt-researcher/issues/1358",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 16999,
    "repo_name": "open-webui/open-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Option 1: Only one endpoint\",\n    \"Option 2: If both endpoints are used the values of the models should match\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"should match\",\n    \"different outputs\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-webui/open-webui/issues/16999",
    "repo_size": 332,
    "size_category": "large"
  },
  {
    "issue_number": 1402,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u8fd9\u4e2a4090\u57283\u79d2\u5185\u751f\u6210\u7ed3\u675f\uff08\u5360\u7528\u738799%\uff09\uff0c5080\u898110\u79d2\uff08\u5360\u7528\u738724%\uff09\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u63a8\u7406\u6bd44090\u61623-4\u500d\",\n    \"\u5360\u7528\u7387\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/1402",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 2105,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"there are many inherent features in Open-WebUI that don't need to be reinvented in PrivateGPT\",\n    \"could be added as an extra parameter in the poetry install\",\n    \"with relatively low effort\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"don't need to be reinvented\",\n    \"could be added\",\n    \"relatively low effort\"\n  ]\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/2105",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 332,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"However, in many models, there is no specified max_length, so max_length here is actually the default value as 20.\",\n    \"Therefore, when computing the ppl, the input text will be cut as long as the length exceeds 20, while 20 is too small for most cases.\",\n    \"I believe developers should fix this bug because perplexity is commonly used in text generation tasks.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"However, in many models, there is no specified max_length\",\n    \"20 is too small for most cases\",\n    \"I believe developers should fix this bug\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/332",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 426,
    "repo_name": "Lightning-AI/LitServe",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Right now the health check endpoint returns 'ok' when all the processes has started.\",\n    \"There could be scenario when the LitAPI depends on another API/service (such as check if Ollama has pulled the model in background) and health-check need to account for the liveliness of that service too.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Right now the health check endpoint returns\",\n    \"There could be scenario when\",\n    \"health-check need to account for\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Lightning-AI/LitServe/issues/426",
    "repo_size": 69,
    "size_category": "medium"
  },
  {
    "issue_number": 48,
    "repo_name": "OSU-NLP-Group/HippoRAG",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. The author is asking a question for clarification rather than admitting to any technical debt.\"\n}\n```",
    "issue_url": "https://github.com/OSU-NLP-Group/HippoRAG/issues/48",
    "repo_size": 120,
    "size_category": "medium"
  },
  {
    "issue_number": 311,
    "repo_name": "browser-use/web-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"struggles to work (locate, click or perform any other actions) on dynamically loaded content\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"struggles to work\",\n    \"any other actions\",\n    \"dynamically loaded content\"\n  ]\n}\n```",
    "issue_url": "https://github.com/browser-use/web-ui/issues/311",
    "repo_size": 353,
    "size_category": "large"
  },
  {
    "issue_number": 36,
    "repo_name": "Emerging-AI/ENOVA",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"might not work\",\n    \"if you encounter any issues\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Emerging-AI/ENOVA/issues/36",
    "repo_size": 4,
    "size_category": "small"
  },
  {
    "issue_number": 71,
    "repo_name": "datastax/astra-assistants-api",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"its unable to make more than 1 tool call\",\n    \"the run status is completed and it returns the answer\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"unable to make more than 1 tool call\",\n    \"run status is completed\"\n  ]\n}\n```",
    "issue_url": "https://github.com/datastax/astra-assistants-api/issues/71",
    "repo_size": 58,
    "size_category": "medium"
  },
  {
    "issue_number": 2764,
    "repo_name": "mem0ai/mem0",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"returns a list instead of a tuple\",\n    \"But in the current project\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"returns a list instead of a tuple\",\n    \"But in the current project\"\n  ]\n}\n```",
    "issue_url": "https://github.com/mem0ai/mem0/issues/2764",
    "repo_size": 283,
    "size_category": "large"
  },
  {
    "issue_number": 4200,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"not able to pass image to Agentflow\",\n    \"which i am not able to do current agentflow version\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"not able to\",\n    \"which i am not able to do\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/4200",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 77,
    "repo_name": "rusiaaman/wcgw",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"'file_paths' is a required property\",\n    \"'action_json' is a required property\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Input validation error\",\n    \"is a required property\"\n  ]\n}\n```",
    "issue_url": "https://github.com/rusiaaman/wcgw/issues/77",
    "repo_size": 28,
    "size_category": "small"
  },
  {
    "issue_number": 499,
    "repo_name": "openml/automlbenchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It primarily describes a failure in running tests without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/openml/automlbenchmark/issues/499",
    "repo_size": 165,
    "size_category": "medium"
  },
  {
    "issue_number": 48,
    "repo_name": "AnswerDotAI/RAGatouille",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Testing is currently very sparse.\",\n    \"It's essentially just ensuring model loading works properly (not tested in all cases yet)\",\n    \"This is an ongoing issue\",\n    \"Improve unit test coverage\",\n    \"Test every component of the data processing pipeline to ensure the training pipeline can be grown without breaking anything\",\n    \"Test model loading in a variety of circumstances\",\n    \"Just about anything else you can think of: it should be tested\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"currently very sparse\",\n    \"not tested in all cases yet\",\n    \"ongoing issue\",\n    \"should be tested\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AnswerDotAI/RAGatouille/issues/48",
    "repo_size": 196,
    "size_category": "medium"
  },
  {
    "issue_number": 278,
    "repo_name": "pytorch/benchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"most models raise NotImplemented\",\n    \"it is strictly opt-in to add quantization for particular models\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"raise NotImplemented\",\n    \"opt-in to add\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pytorch/benchmark/issues/278",
    "repo_size": 123,
    "size_category": "medium"
  },
  {
    "issue_number": 132,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Cuda out of memory issue when set dimension like dynamic degree, motion_smoothness, and subject consistency\",\n    \"ram allocation always reach 64 GB\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"face Cuda out of memory issue\",\n    \"ram allocation always reach\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/132",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 97,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The server socket has failed to listen on any local network address.\",\n    \"The server socket has failed to bind to [::]:50001 (errno: 98 - Address already in use).\",\n    \"The server socket has failed to bind to 0.0.0.0:50001 (errno: 98 - Address already in use).\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"failed to listen\",\n    \"failed to bind\",\n    \"errno: 98 - Address already in use\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/97",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 114,
    "repo_name": "huggingface/evaluate",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is simply a request for the addition of a metric without any indication of existing problems or temporary fixes.\"\n}\n```",
    "issue_url": "https://github.com/huggingface/evaluate/issues/114",
    "repo_size": 264,
    "size_category": "large"
  },
  {
    "issue_number": 136,
    "repo_name": "NVIDIA/TensorRT-Model-Optimizer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"AssertionError\",\n    \"assert not np_y_scale.shape or w32.shape[-1] == np_y_scale.shape[0]\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"AssertionError\",\n    \"assert not\"\n  ]\n}\n```",
    "issue_url": "https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/136",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 1045,
    "repo_name": "OpenRLHF/OpenRLHF",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The current loop for prompt, _, _ in prompts_dataset: expects 3 returned values, but the dataset's return signature was modified in recent commits, and the calling logic hasn't been updated to match the new return count.\",\n    \"This mismatch causes a runtime error.\",\n    \"an error occurs indicating that the generate method is missing in the actor class. This is likely due to a recent commit where the original generate method was removed, but the call in interactive_chat.py was not updated accordingly.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"expects 3 returned values\",\n    \"hasn't been updated to match\",\n    \"causes a runtime error\",\n    \"is likely due to a recent commit\",\n    \"was not updated accordingly\"\n  ]\n}\n```",
    "issue_url": "https://github.com/OpenRLHF/OpenRLHF/issues/1045",
    "repo_size": 361,
    "size_category": "large"
  },
  {
    "issue_number": 3787,
    "repo_name": "huggingface/trl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"IndexError: string index out of range\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"IndexError\",\n    \"out of range\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/trl/issues/3787",
    "repo_size": 239,
    "size_category": "large"
  },
  {
    "issue_number": 922,
    "repo_name": "neuml/txtai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I am getting dimensions mismatch when I use txtai 8.6.0 to index data with models having 2_Dense layer that has different in_features and out_features.\",\n    \"By default, index was created with the dimension of in_feature but the encoded vector is of dimension out_feature.\",\n    \"Does that mean models with 2_Dense layer is not yet supported?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I am getting dimensions mismatch\",\n    \"I am getting similar dimension mismatch errors\",\n    \"Does that mean models with 2_Dense layer is not yet supported?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/neuml/txtai/issues/922",
    "repo_size": 252,
    "size_category": "large"
  },
  {
    "issue_number": 3083,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n    \"SATD_FOUND\": \"Yes\",\n    \"EXACT_QUOTES\": [\n        \"the `rope_scaling` parameter is not being passed to vLLM when `fast_inference=True` is enabled\",\n        \"The `rope_scaling` parameter is not included in the `allowed_args` or `load_vllm_kwargs` parameters\",\n        \"This prevents the rope scaling configuration from being passed to the underlying vLLM engine\"\n    ],\n    \"WHO_ADMITS\": \"issue author\",\n    \"DEBT_TYPE\": \"implementation\",\n    \"LANGUAGE_PATTERNS\": [\n        \"not being passed\",\n        \"not included\",\n        \"prevents the rope scaling configuration from being passed\"\n    ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/3083",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 2291,
    "repo_name": "stanford-crfm/helm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"should show more information about the model, either as a tooltip (preferred) or via a link to the models page (need a href anchor)\",\n    \"should just be \u2018Model\u2019 for simplicity\",\n    \"should tooltip show the description based on the schema\",\n    \"would just drop all the train-test contamination stuff from the frontend since we\u2019re not consistently updating this\",\n    \"Right after the adapter specification, we should have a panel to display the key metrics (the same ones that are displayed on a results table - need to pull that out of the schema). This is the most important.\",\n    \"strong dislike for scrollbars, and I think the input box should be a lot bigger (scroll when we hit nearly a screen full of content)\",\n    \"could show all the information in a popup to save a click because right now you need to click expand to actually see the prompts\",\n    \"\u2018Details\u2019 doesn\u2019t show anything, so can just get rid of it.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"should show\",\n    \"should just be\",\n    \"should tooltip show\",\n    \"would just drop\",\n    \"we should have\",\n    \"strong dislike for\",\n    \"could show\",\n    \"can just get rid of\"\n  ]\n}\n```",
    "issue_url": "https://github.com/stanford-crfm/helm/issues/2291",
    "repo_size": 157,
    "size_category": "medium"
  },
  {
    "issue_number": 131,
    "repo_name": "beir-cellar/beir",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"it is the second time I encounter low results for specific models.\",\n    \"Are some models not technically feasible?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"low results\",\n    \"worked like a charm\",\n    \"bad results again\",\n    \"what do I miss here?\",\n    \"not technically feasible\"\n  ]\n}\n```",
    "issue_url": "https://github.com/beir-cellar/beir/issues/131",
    "repo_size": 149,
    "size_category": "medium"
  },
  {
    "issue_number": 8894,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"\u4e2a\u4eba\u8ba4\u4e3a\u53ef\u80fd\u7684\u539f\u56e0\uff1a\u5f00\u542f\u5b50\u8bdd\u9898\u65f6\u4f1a\u81ea\u52a8\u751f\u6210\u5b50\u8bdd\u9898\u6807\u9898\u3002\u5728\u4e34\u65f6\u8bdd\u9898\u4e2d\uff0c\u5b50\u8bdd\u9898\u6807\u9898\u3010\u65e0\u5904\u53ef\u653e\u3011\u53ef\u80fd\u662f\u5bfc\u81f4\u9875\u9762\u6301\u7eed\u52a0\u8f7d\u7684\u539f\u56e0\u3002\",\n    \"\u5982\u679c\u786e\u5b9e\u662f\u8fd9\u4e2a\u539f\u56e0\u5bfc\u81f4\u7684\uff0c\u4e2a\u4eba\u8ba4\u4e3a\u6709\u4ee5\u4e0b\u4e24\u4e2a\u89e3\u51b3\u65b9\u6848\uff1a\",\n    \"\u9650\u5236\u5728\u4e34\u65f6\u8bdd\u9898\u4e2d\u5efa\u7acb\u5b50\u8bdd\u9898\",\n    \"\u5728\u5efa\u7acb\u5b50\u8bdd\u9898\u65f6\uff0c\u5982\u679c\u5f53\u524d session \u6ca1\u6709\u4fdd\u5b58\u4e3a\u8bdd\u9898\uff0c\u5219\u81ea\u52a8\u4fdd\u5b58\u3002\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u4e2a\u4eba\u8ba4\u4e3a\u53ef\u80fd\u7684\u539f\u56e0\",\n    \"\u5982\u679c\u786e\u5b9e\u662f\u8fd9\u4e2a\u539f\u56e0\u5bfc\u81f4\u7684\",\n    \"\u6211\u8ba4\u4e3a\u6709\u4ee5\u4e0b\u4e24\u4e2a\u89e3\u51b3\u65b9\u6848\"\n  ]\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8894",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 1413,
    "repo_name": "FlagOpen/FlagEmbedding",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily consists of questions regarding the origin of training queries and does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. The author is seeking clarification rather than admitting to any technical debt.\"\n}\n```",
    "issue_url": "https://github.com/FlagOpen/FlagEmbedding/issues/1413",
    "repo_size": 371,
    "size_category": "large"
  },
  {
    "issue_number": 8999,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It primarily focuses on a specific error encountered during the execution of a command without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/8999",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 27,
    "repo_name": "ryo-ma/gpt-assistants-api-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, or known limitations. It primarily describes a problem encountered during image upload without indicating any awareness of technical debt or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/ryo-ma/gpt-assistants-api-ui/issues/27",
    "repo_size": 19,
    "size_category": "small"
  },
  {
    "issue_number": 436,
    "repo_name": "SWE-bench/SWE-bench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not express any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply requests an update to a repository link and asks a question about another project, without indicating any known issues or areas for improvement.\"\n}\n```",
    "issue_url": "https://github.com/SWE-bench/SWE-bench/issues/436",
    "repo_size": 199,
    "size_category": "medium"
  },
  {
    "issue_number": 60,
    "repo_name": "seratch/ChatGPT-in-Slack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It appears this repo may only support ChatGPT via OpenAI tokens\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"It appears\",\n    \"may only support\"\n  ]\n}\n```",
    "issue_url": "https://github.com/seratch/ChatGPT-in-Slack/issues/60",
    "repo_size": 53,
    "size_category": "medium"
  },
  {
    "issue_number": 1074,
    "repo_name": "OpenRLHF/OpenRLHF",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"I feel like some recommendation of hardware related setup (minimal supported GPU and driver versions) and some reproducible steps could be helpful\",\n    \"It shows torch.distributed.DistBackendError: NCCL error ....... ncclUnhandledCudaError: CAll to CUDA function failed. CUDA failure 304 'OS call failed or operation not supported on this OS'\",\n    \"The job was terminated without much useful debug messages\",\n    \"There are some potential root causes, e.g., (1) SIGKILL by OOM killer due to high memory usage, (2) ray stop --force. (3) SIGSEGV or other errors\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I feel like\",\n    \"could be helpful\",\n    \"shows ... error\",\n    \"terminated without much useful debug messages\",\n    \"potential root causes\"\n  ]\n}\n```",
    "issue_url": "https://github.com/OpenRLHF/OpenRLHF/issues/1074",
    "repo_size": 361,
    "size_category": "large"
  },
  {
    "issue_number": 510,
    "repo_name": "GaiZhenbiao/ChuanhuChatGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u521b\u5efa\u4e00\u4e2acsv\u6587\u4ef6\u628a\u7528\u6237\u540d\u548c\u5bf9\u5e94\u4f7f\u7528\u7684token\u50a8\u5b58\u5728\u672c\u5730\uff0c\u6bcf\u6b21response\u7684\u65f6\u5019\u66f4\u65b0\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u53ef\u80fd\u7684\u89e3\u51b3\u529e\u6cd5\",\n    \"\u6bcf\u6b21response\u7684\u65f6\u5019\u66f4\u65b0\"\n  ]\n}\n```",
    "issue_url": "https://github.com/GaiZhenbiao/ChuanhuChatGPT/issues/510",
    "repo_size": 305,
    "size_category": "large"
  },
  {
    "issue_number": 44,
    "repo_name": "microsoft/sarathi-serve",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily reports a missing file error without any acknowledgment of suboptimal solutions, limitations, or plans for future improvements. It simply asks if the file is available, which does not indicate any recognition of technical debt.\"\n}\n```",
    "issue_url": "https://github.com/microsoft/sarathi-serve/issues/44",
    "repo_size": 26,
    "size_category": "small"
  },
  {
    "issue_number": 8263,
    "repo_name": "lobehub/lobe-chat",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Provider 'authentik' is missing both `issuer` and `authorization` endpoint config. At least one of them is required.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"missing both `issuer` and `authorization` endpoint config\",\n    \"At least one of them is required\"\n  ]\n}\n```",
    "issue_url": "https://github.com/lobehub/lobe-chat/issues/8263",
    "repo_size": 248,
    "size_category": "large"
  },
  {
    "issue_number": 8295,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"it seems like the model parameters are not correctly loaded since the loss is as high as training from the beginning.\",\n    \"If I directly use `--resume_from_checkpoint XXX`, several errors may occur.\",\n    \"I tried to fix those errors by copying the model weights `mp_rank_00_model_states.pt` and the scheduler `scheduler.pt` from the input folder (LlamaFactory ckpt folder) to the output folder (deepspeed universal ckpt folder).\",\n    \"I found the loss is as high as training from scratch.\",\n    \"I further find that the loaded (universal checkpoint) model's weights are not the same as the Llamafactory's saved weights, even though I copied the `mp_rank_00_model_states.pt`.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"it seems like\",\n    \"I notice that\",\n    \"I found\",\n    \"I further find\",\n    \"I tried to fix those errors\"\n  ]\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/8295",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 52,
    "repo_name": "ServiceNow/AgentLab",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"dask seemed to still have issues, investigate and make sure we can run in parallel on the different benchmarks\",\n    \"the field depends_on is likely to pollute the experiment results as it's loading all dataclass fields into it. Let's investigate if we can store it as an attribute (i.e. not a dataclass field) this would be stored in the pickle but not be loaded in the pandas dataframe.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": [\n    \"performance\",\n    \"implementation\"\n  ],\n  \"LANGUAGE_PATTERNS\": [\n    \"seemed to still have issues\",\n    \"Let's investigate if we can\",\n    \"likely to pollute the experiment results\"\n  ]\n}\n```",
    "issue_url": "https://github.com/ServiceNow/AgentLab/issues/52",
    "repo_size": 67,
    "size_category": "medium"
  },
  {
    "issue_number": 2006,
    "repo_name": "castorini/pyserini",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"installing these dependencies can be quite trick\",\n    \"untangling `faiss` has been quite tricky\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"can be quite tricky\",\n    \"has been quite tricky\"\n  ]\n}\n```",
    "issue_url": "https://github.com/castorini/pyserini/issues/2006",
    "repo_size": 104,
    "size_category": "medium"
  },
  {
    "issue_number": 2814,
    "repo_name": "embeddings-benchmark/mteb",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I will leave it for future\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I will leave it for future\"\n  ]\n}\n```",
    "issue_url": "https://github.com/embeddings-benchmark/mteb/issues/2814",
    "repo_size": 301,
    "size_category": "large"
  },
  {
    "issue_number": 4172,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"404 This is not a chat model and thus not supported in the v1/chat/completions endpoint.\",\n    \"Did you mean to use v1/completions?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Getting erros like:\",\n    \"This is not a chat model and thus not supported\",\n    \"Did you mean to use\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/4172",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 241,
    "repo_name": "AnswerDotAI/RAGatouille",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"How to turn off return of -- the verbose unstructured text\",\n    \"just Return the dict -> [{\\\"content\\\": ...\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"How to turn off return of\",\n    \"just Return the dict\"\n  ]\n}\n```",
    "issue_url": "https://github.com/AnswerDotAI/RAGatouille/issues/241",
    "repo_size": 196,
    "size_category": "medium"
  },
  {
    "issue_number": 1262,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The inferrence speed is too slow\",\n    \"the GPU utilization is below 50%\",\n    \"the power usage is only 100+W, which is too low\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"too slow\",\n    \"below 50%\",\n    \"too low\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/1262",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 1031,
    "repo_name": "open-compass/VLMEvalKit",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u597d\u50cf\u662fmax-token\u7684\u95ee\u9898\uff0c\u8fd9\u4e2a\u5728\u54ea\u8bbe\u7f6e\uff1f\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u597d\u50cf\u662f\",\n    \"\u8fd9\u4e2a\u5728\u54ea\u8bbe\u7f6e\uff1f\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-compass/VLMEvalKit/issues/1031",
    "repo_size": 212,
    "size_category": "large"
  },
  {
    "issue_number": 1371,
    "repo_name": "Josh-XT/AGiXT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, or known limitations. It primarily describes a bug encountered during API querying without indicating any awareness of technical debt or future improvements needed.\"\n}\n```",
    "issue_url": "https://github.com/Josh-XT/AGiXT/issues/1371",
    "repo_size": 76,
    "size_category": "medium"
  },
  {
    "issue_number": 8371,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not express any acknowledgment of suboptimal solutions, limitations, or technical debt. It is a request for documentation regarding the API parameters without indicating any known issues or temporary fixes.\"\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/8371",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 263,
    "repo_name": "browser-use/web-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"tasks get queued and will run after the first task is completed\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"cannot run tasks simultaneously\",\n    \"tasks get queued\",\n    \"will run after the first task is completed\"\n  ]\n}\n```",
    "issue_url": "https://github.com/browser-use/web-ui/issues/263",
    "repo_size": 353,
    "size_category": "large"
  },
  {
    "issue_number": 48,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"need to update requirenment.txt\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"need to update\",\n    \"requirement\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/48",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 54,
    "repo_name": "ServiceNow/AgentLab",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The assert in get_std_err (inspect_result.py) is causing problems when reward are not integers\",\n    \"We might want to go for empirical std instead\",\n    \"or add an exception to switch to empirical std\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"causing problems\",\n    \"might want to\",\n    \"add an exception\"\n  ]\n}\n```",
    "issue_url": "https://github.com/ServiceNow/AgentLab/issues/54",
    "repo_size": 67,
    "size_category": "medium"
  },
  {
    "issue_number": 184,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply requests the addition of a feature (SQLDocstore for Postgres) without mentioning any known issues or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/184",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 905,
    "repo_name": "open-compass/VLMEvalKit",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It primarily describes a problem encountered during evaluation without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/open-compass/VLMEvalKit/issues/905",
    "repo_size": 212,
    "size_category": "large"
  },
  {
    "issue_number": 436,
    "repo_name": "browser-use/web-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"it will switch from Tab0 to Tab1, and then a second later switch back to Tab0\",\n    \"It keeps switching back to the tab that was first active when the agent was started\",\n    \"Previous versions work just fine\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"notice when I give a task\",\n    \"it will switch\",\n    \"keeps switching back\",\n    \"previous versions work just fine\"\n  ]\n}\n```",
    "issue_url": "https://github.com/browser-use/web-ui/issues/436",
    "repo_size": 353,
    "size_category": "large"
  },
  {
    "issue_number": 9860,
    "repo_name": "Significant-Gravitas/AutoGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently the Agents list in the Library is ordered based on time of last edit to an agent in the builder, instead this should be ordered by the time of last execution.\",\n    \"all executions should be counted, not just those manually triggered through the GUI.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Currently the Agents list in the Library is ordered based on time of last edit\",\n    \"this should be ordered by the time of last execution\",\n    \"not just those manually triggered through the GUI\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Significant-Gravitas/AutoGPT/issues/9860",
    "repo_size": 215,
    "size_category": "large"
  },
  {
    "issue_number": 12,
    "repo_name": "Vchitect/VBench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not explicitly acknowledge any suboptimal solutions, limitations, or technical shortcuts. It primarily seeks clarification on the configuration and influence of evaluation data settings without indicating any known problems or areas needing improvement.\"\n}\n```",
    "issue_url": "https://github.com/Vchitect/VBench/issues/12",
    "repo_size": 155,
    "size_category": "medium"
  },
  {
    "issue_number": 356,
    "repo_name": "open-compass/VLMEvalKit",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"max new token is different\",\n    \"I believe we should have a consistent MAX_NEW_TOKENS across the project\",\n    \"If it makes sense, I can create a PR to modify all of them\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I believe we should have\",\n    \"If it makes sense, I can create a PR\"\n  ]\n}\n```",
    "issue_url": "https://github.com/open-compass/VLMEvalKit/issues/356",
    "repo_size": 212,
    "size_category": "large"
  },
  {
    "issue_number": 23681,
    "repo_name": "vllm-project/vllm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"it's unclear if users and other projects ought to pull directly from 'q9t5s3a7' or if that is something that users should trust.\",\n    \"please at least update the docs to explain why users should trust this ECR location.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"documentation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"it's unclear\",\n    \"please at least update the docs to explain\"\n  ]\n}\n```",
    "issue_url": "https://github.com/vllm-project/vllm/issues/23681",
    "repo_size": 165,
    "size_category": "medium"
  },
  {
    "issue_number": 72,
    "repo_name": "SWE-bench/SWE-bench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"many were basically impossible for a skilled human to 'solve'\",\n    \"Mainly because the tasks were under specified wrt to the hidden test cases that determine passing.\",\n    \"The tests were checking implementation specific details from the repo\u2019s PR that weren't actually stated requirements of the task.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"basically impossible\",\n    \"under specified\",\n    \"checking implementation specific details\",\n    \"weren't actually stated requirements\"\n  ]\n}\n```",
    "issue_url": "https://github.com/SWE-bench/SWE-bench/issues/72",
    "repo_size": 199,
    "size_category": "medium"
  },
  {
    "issue_number": 7105,
    "repo_name": "oobabooga/text-generation-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I'm unsure of what my last version was\",\n    \"Model STILL runs in my old text-generation-webui, just not the new one.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I'm unsure of what my last version was\",\n    \"refuses to run with the same model and same settings\"\n  ]\n}\n```",
    "issue_url": "https://github.com/oobabooga/text-generation-webui/issues/7105",
    "repo_size": 339,
    "size_category": "large"
  },
  {
    "issue_number": 1082,
    "repo_name": "pydantic/logfire",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"From time to time, but almost on every container run, there are at least a few Connection Errors\",\n    \"Some runs show the connection reset error once and than manage to revive the connection and send the logs to logfire and sometimes I'll see that error repeating throughout the container's life span.\",\n    \"I recently added a call to `shutdown` to see if this helps but it didn't change much\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"From time to time\",\n    \"there are at least a few Connection Errors\",\n    \"manage to revive the connection\",\n    \"error repeating throughout the container's life span\",\n    \"I recently added a call to `shutdown` to see if this helps but it didn't change much\"\n  ]\n}\n```",
    "issue_url": "https://github.com/pydantic/logfire/issues/1082",
    "repo_size": 202,
    "size_category": "large"
  },
  {
    "issue_number": 90,
    "repo_name": "aj47/100x-orchestrator",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"sometimes llm gives invalid pr format\",\n    \"Invalid PR info JSON\",\n    \"Future Improvements\",\n    \"Provide more detailed progress metrics.\",\n    \"Enhance error handling mechanisms for the cloning process.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"sometimes ... gives invalid\",\n    \"Invalid ... JSON\",\n    \"Future Improvements\",\n    \"Provide more detailed ...\",\n    \"Enhance ... mechanisms\"\n  ]\n}\n```",
    "issue_url": "https://github.com/aj47/100x-orchestrator/issues/90",
    "repo_size": 41,
    "size_category": "small"
  },
  {
    "issue_number": 52,
    "repo_name": "bhaskatripathi/pdfGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue report does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It simply describes a problem encountered without indicating any awareness of underlying technical debt.\"\n}\n```",
    "issue_url": "https://github.com/bhaskatripathi/pdfGPT/issues/52",
    "repo_size": 98,
    "size_category": "medium"
  },
  {
    "issue_number": 748,
    "repo_name": "InternLM/xtuner",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the checkpoint you are trying to load has model type `llava_llama` but Transformers does not recognize this architecture.\",\n    \"This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"the checkpoint you are trying to load has model type ... but ... does not recognize this architecture.\",\n    \"This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/InternLM/xtuner/issues/748",
    "repo_size": 344,
    "size_category": "large"
  },
  {
    "issue_number": 7938,
    "repo_name": "hiyouga/LLaMA-Factory",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u8fd8\u662f\u4f1aOOM\uff0c\u9700\u8981\u6d88\u8017\u8fd9\u4e48\u591a\u8d44\u6e90\u5417\uff0c\u54ea\u91cc\u53ef\u4ee5\u4f18\u5316\u5462\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u9700\u8981\u6d88\u8017\u8fd9\u4e48\u591a\u8d44\u6e90\u5417\",\n    \"\u54ea\u91cc\u53ef\u4ee5\u4f18\u5316\u5462\"\n  ]\n}\n```",
    "issue_url": "https://github.com/hiyouga/LLaMA-Factory/issues/7938",
    "repo_size": 435,
    "size_category": "large"
  },
  {
    "issue_number": 22,
    "repo_name": "evilpan/gptcli",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It primarily provides information and code examples related to using the Azure OpenAI service without indicating any areas needing future improvement or addressing existing problems.\"\n}\n```",
    "issue_url": "https://github.com/evilpan/gptcli/issues/22",
    "repo_size": 20,
    "size_category": "small"
  },
  {
    "issue_number": 45,
    "repo_name": "ricklamers/shell-ai",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue describes a specific code error without acknowledging any suboptimal solutions, limitations, or technical shortcuts. It simply points out a syntax mistake without indicating any future improvements or known problems.\"\n}\n```",
    "issue_url": "https://github.com/ricklamers/shell-ai/issues/45",
    "repo_size": 24,
    "size_category": "small"
  },
  {
    "issue_number": 237,
    "repo_name": "NVIDIA/TensorRT-Model-Optimizer",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I don\u2019t have enough GPU memory to keep the full model resident in fp16/bf16/fp8 during calibration.\",\n    \"Can I quantize Kimi\u2011K2\u20111T when VRAM is not enough?\",\n    \"Is layer/block\u2011wise calibration supported?\",\n    \"Any out\u2011of\u2011core/offload option to use CPU RAM/NVMe for weights/activations during calibration?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I don\u2019t have enough GPU memory\",\n    \"Can I quantize... when VRAM is not enough?\",\n    \"Is layer/block\u2011wise calibration supported?\",\n    \"Any out\u2011of\u2011core/offload option...\"\n  ]\n}\n```",
    "issue_url": "https://github.com/NVIDIA/TensorRT-Model-Optimizer/issues/237",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 317,
    "repo_name": "PrefectHQ/ControlFlow",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It simply states that one version of the software does not run a specific flow correctly compared to another version, without detailing any underlying issues or plans for resolution.\"\n}\n```",
    "issue_url": "https://github.com/PrefectHQ/ControlFlow/issues/317",
    "repo_size": 61,
    "size_category": "medium"
  },
  {
    "issue_number": 85,
    "repo_name": "OSU-NLP-Group/HippoRAG",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"ZeroDivisionError: division by zero\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"this error occurs\",\n    \"How can I fix it?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/OSU-NLP-Group/HippoRAG/issues/85",
    "repo_size": 120,
    "size_category": "medium"
  },
  {
    "issue_number": 1057,
    "repo_name": "pydantic/logfire",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue is a question about future plans for a performance visualization dashboard and does not contain any acknowledgment of suboptimal solutions, limitations, or technical debt.\"\n}\n```",
    "issue_url": "https://github.com/pydantic/logfire/issues/1057",
    "repo_size": 202,
    "size_category": "large"
  },
  {
    "issue_number": 687,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"any way to get support for XLM-RoBERTA, DeBERTA et similia models?\",\n    \"i see that there was another issue asking the same things, there were any progress since then?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"any way to get support for\",\n    \"there were any progress since then?\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/687",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 67,
    "repo_name": "danny-avila/rag_api",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply requests a feature enhancement to allow specifying a dimensions parameter as an environment variable.\"\n}\n```",
    "issue_url": "https://github.com/danny-avila/rag_api/issues/67",
    "repo_size": 88,
    "size_category": "medium"
  },
  {
    "issue_number": 7208,
    "repo_name": "oobabooga/text-generation-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"it uses as much VRAM as the model's size.\",\n    \"So, all experts are loaded always.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"as much VRAM as the model's size\",\n    \"all experts are loaded always\"\n  ]\n}\n```",
    "issue_url": "https://github.com/oobabooga/text-generation-webui/issues/7208",
    "repo_size": 339,
    "size_category": "large"
  },
  {
    "issue_number": 15,
    "repo_name": "RUC-NLPIR/FlashRAG",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue is a request for clarification regarding the meaning of specific metrics and does not acknowledge any suboptimal solutions, limitations, or technical debt.\"\n}\n```",
    "issue_url": "https://github.com/RUC-NLPIR/FlashRAG/issues/15",
    "repo_size": 164,
    "size_category": "medium"
  },
  {
    "issue_number": 64,
    "repo_name": "microsoft/promptbench",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, known limitations, or technical shortcuts. It is a request for additional data rather than an admission of existing technical debt.\"\n}\n```",
    "issue_url": "https://github.com/microsoft/promptbench/issues/64",
    "repo_size": 63,
    "size_category": "medium"
  },
  {
    "issue_number": 2711,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It is understandable that citations are not included, at least for being compatible with OpenAI's spec.\",\n    \"Is it possible to enhance the API or provide another API for receiving the citation data, say based the returned id in the above API?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"It is understandable that citations are not included\",\n    \"Is it possible to enhance the API\",\n    \"provide another API for receiving the citation data\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/2711",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 1009,
    "repo_name": "bentoml/OpenLLM",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0.\",\n    \"Serialisation format is not specified. Defaulting to 'safetensors'. Your model might not work with this format.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": [\n    \"configuration\",\n    \"implementation\"\n  ],\n  \"LANGUAGE_PATTERNS\": [\n    \"FutureWarning\",\n    \"deprecated\",\n    \"not specified\",\n    \"defaulting to\"\n  ]\n}\n```",
    "issue_url": "https://github.com/bentoml/OpenLLM/issues/1009",
    "repo_size": 97,
    "size_category": "medium"
  },
  {
    "issue_number": 1798,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Warning: No remote 'origin' in /opt/homebrew/Library/Taps/seal/homebrew-local-openfst-1.8.3, skipping update!\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Warning:\",\n    \"skipping update!\"\n  ]\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/1798",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 804,
    "repo_name": "GaiZhenbiao/ChuanhuChatGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I wish we could support txt2img functions\",\n    \"I'm planning to support in following steps\",\n    \"\u53ef\u80fd\u518d\u4eff\u7167xmchat\uff0c\u63d0\u4f9bimg2img\uff08\u57ab\u56fe/\u91cd\u7ed8/\u8865\u753b\uff09\u529f\u80fd\",\n    \"\u672a\u6765\u9664\u4e86midjourney\u518d\u63a5\u5165\u5f00\u6e90stable-diffusion\u7684sdapi\uff08\u53ef\u8fdc\u7a0b\u4e5f\u53ef\u672c\u5730\u90e8\u7f72\uff09\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I wish we could support\",\n    \"I'm planning to support\",\n    \"\u53ef\u80fd\u518d\u4eff\u7167\",\n    \"\u672a\u6765\u9664\u4e86midjourney\u518d\u63a5\u5165\"\n  ]\n}\n```",
    "issue_url": "https://github.com/GaiZhenbiao/ChuanhuChatGPT/issues/804",
    "repo_size": 305,
    "size_category": "large"
  },
  {
    "issue_number": 1276,
    "repo_name": "Josh-XT/AGiXT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, or known limitations. It primarily describes a bug without indicating any technical debt or areas needing future improvement.\"\n}\n```",
    "issue_url": "https://github.com/Josh-XT/AGiXT/issues/1276",
    "repo_size": 76,
    "size_category": "medium"
  },
  {
    "issue_number": 148,
    "repo_name": "huggingface/optimum-benchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Some of the models failed during benchmarking\",\n    \"Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0!\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"failed during benchmarking\",\n    \"Expected all tensors to be on the same device\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/optimum-benchmark/issues/148",
    "repo_size": 60,
    "size_category": "medium"
  },
  {
    "issue_number": 656,
    "repo_name": "OpenRLHF/OpenRLHF",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily consists of questions regarding memory requirements and support for pipeline parallelism. There are no explicit acknowledgments of suboptimal solutions, limitations, or technical shortcuts. The content does not indicate any known issues or areas needing future improvement.\"\n}\n```",
    "issue_url": "https://github.com/OpenRLHF/OpenRLHF/issues/656",
    "repo_size": 361,
    "size_category": "large"
  },
  {
    "issue_number": 3503,
    "repo_name": "oobabooga/text-generation-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I would like to have a place for more serious modes and prompting/instruction concepts to be rated and grow.\",\n    \"Or at least a central repository for everyone's work that cares to share with a link from the Characters dropdown.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"design\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I would like to have\",\n    \"Or at least\",\n    \"hard time finding\"\n  ]\n}\n```",
    "issue_url": "https://github.com/oobabooga/text-generation-webui/issues/3503",
    "repo_size": 339,
    "size_category": "large"
  },
  {
    "issue_number": 204,
    "repo_name": "father-bot/chatgpt_telegram_bot",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It's really add 2 parse external link content?\",\n    \"Get short description of www.blabla.ru/article.html\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"It's really\",\n    \"add 2 parse\",\n    \"short description\"\n  ]\n}\n```",
    "issue_url": "https://github.com/father-bot/chatgpt_telegram_bot/issues/204",
    "repo_size": 222,
    "size_category": "large"
  },
  {
    "issue_number": 15,
    "repo_name": "existence-master/Sentient",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It primarily outlines a goal for migration without indicating any known problems or temporary fixes.\"\n}\n```",
    "issue_url": "https://github.com/existence-master/Sentient/issues/15",
    "repo_size": 37,
    "size_category": "small"
  },
  {
    "issue_number": 930,
    "repo_name": "OpenRLHF/OpenRLHF",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Does the number of GPU cards I have necessarily need to be no less than 40=18+18+18+18+4*2?\",\n    \"Does this configuration require a total of 5 nodes (each with 8 GPUs), summing up to at least 40 GPUs?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Does the number of GPU cards I have necessarily need to be\",\n    \"Does this configuration require\"\n  ]\n}\n```",
    "issue_url": "https://github.com/OpenRLHF/OpenRLHF/issues/930",
    "repo_size": 361,
    "size_category": "large"
  },
  {
    "issue_number": 2652,
    "repo_name": "gpustack/gpustack",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"a proposal to improve the api of users\",\n    \"you can add the issuance of api key not only by the validity period by days, but add the use of the number of tokens??\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"proposal to improve\",\n    \"add the issuance of api key\",\n    \"not only by the validity period\",\n    \"but add the use of the number of tokens\"\n  ]\n}\n```",
    "issue_url": "https://github.com/gpustack/gpustack/issues/2652",
    "repo_size": 397,
    "size_category": "large"
  },
  {
    "issue_number": 1476,
    "repo_name": "FunAudioLLM/CosyVoice",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"\u8fd9\u4e2aserver.py\u751f\u6210\u7684\u97f3\u9891\u6709\u95ee\u9898\",\n    \"\u97f3\u9891\u4f4e\u6c89\u3002\u800c\u7528web.py\u7f51\u9875\u751f\u6210\u7684\u97f3\u9891\u5c31\u6b63\u5e38\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"\u6709\u95ee\u9898\",\n    \"\u4f4e\u6c89\",\n    \"\u6b63\u5e38\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FunAudioLLM/CosyVoice/issues/1476",
    "repo_size": 440,
    "size_category": "large"
  },
  {
    "issue_number": 349,
    "repo_name": "potpie-ai/potpie",
    "analysis": "```json\n{\n  \"SATD_FOUND\": true,\n  \"EXACT_QUOTES\": [\n    \"the current implementation of the ShareChat feature is experiencing performance issues\",\n    \"identify queries that are slow or executed multiple times unnecessarily\",\n    \"consider implementing indexing on the relevant tables to speed up read operations\",\n    \"refactor complex queries to simplify them or break them down into smaller, more manageable parts\",\n    \"explore options for caching frequently accessed data to reduce database load\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"experiencing performance issues\",\n    \"identify queries that are slow\",\n    \"executed multiple times unnecessarily\",\n    \"consider implementing\",\n    \"refactor complex queries\",\n    \"explore options for caching\"\n  ]\n}\n```",
    "issue_url": "https://github.com/potpie-ai/potpie/issues/349",
    "repo_size": 64,
    "size_category": "medium"
  },
  {
    "issue_number": 1094,
    "repo_name": "NVIDIA/NeMo-Guardrails",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"It currently depends on the OpenTelemetry SDK causing problems if used in an already instrumented application.\",\n    \"The current implementation requires a lot of additional configuration that makes it harder to have tracing visibility.\",\n    \"This makes it troublesome to rotate the secrets quickly or keep the resource attribute consistent across NeMo guardrails and my application.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"requires a lot of additional configuration\",\n    \"causing problems if used in an already instrumented application\",\n    \"makes it troublesome to rotate the secrets quickly\"\n  ]\n}\n```",
    "issue_url": "https://github.com/NVIDIA/NeMo-Guardrails/issues/1094",
    "repo_size": 148,
    "size_category": "medium"
  },
  {
    "issue_number": 1342,
    "repo_name": "Josh-XT/AGiXT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"This suggests there might be an issue with how the command is handling the input or processing data internally. I need to investigate this further to understand the root cause of the error.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"This suggests there might be an issue\",\n    \"I need to investigate this further to understand the root cause\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Josh-XT/AGiXT/issues/1342",
    "repo_size": 76,
    "size_category": "medium"
  },
  {
    "issue_number": 1409,
    "repo_name": "Mintplex-Labs/anything-llm",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I need to change the Ollama URL for each workspace so that they can use independent Systems which have dedicated GPUs.\",\n    \"I am unable to do that now\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I need to change\",\n    \"I am unable to do that now\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Mintplex-Labs/anything-llm/issues/1409",
    "repo_size": 389,
    "size_category": "large"
  },
  {
    "issue_number": 108,
    "repo_name": "beir-cellar/beir",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, temporary fixes, known limitations, technical shortcuts, or areas needing future improvement. It is simply a request for assistance regarding a missing training set.\"\n}\n```",
    "issue_url": "https://github.com/beir-cellar/beir/issues/108",
    "repo_size": 149,
    "size_category": "medium"
  },
  {
    "issue_number": 3344,
    "repo_name": "huggingface/trl",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"If I set `per_device_train_batch_size `and `gradient_accumulation_steps `to 1, I can run normally.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"If I set ... I can run normally.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/huggingface/trl/issues/3344",
    "repo_size": 239,
    "size_category": "large"
  },
  {
    "issue_number": 3057,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"The breaking change is introduced with trl==0.20.0\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"breaking change\",\n    \"cannot import name\"\n  ]\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/3057",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 673,
    "repo_name": "openml/automlbenchmark",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"that's just a lot of extra unnecessary work\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I think it's a typo\",\n    \"Currently, in case the data is re-ordered and `save=True`, it is written to file and the file path is returned.\",\n    \"the caller likely then would call the function again\",\n    \"that's just a lot of extra unnecessary work\"\n  ]\n}\n```",
    "issue_url": "https://github.com/openml/automlbenchmark/issues/673",
    "repo_size": 165,
    "size_category": "medium"
  },
  {
    "issue_number": 1106,
    "repo_name": "FoundationAgents/MetaGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"the process of identifying which methods or functions need refactoring\",\n    \"understanding their dependencies and potential impact on the overall software\",\n    \"enhance code generation agent's ability to perform advanced code refactoring\",\n    \"improving its capability to analyze code, identify refactor opportunities, and understand the implications of those changes\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"need refactoring\",\n    \"understanding their dependencies\",\n    \"enhance code generation agent's ability\",\n    \"improving its capability\",\n    \"identify refactor opportunities\",\n    \"understand the implications of those changes\"\n  ]\n}\n```",
    "issue_url": "https://github.com/FoundationAgents/MetaGPT/issues/1106",
    "repo_size": 203,
    "size_category": "large"
  },
  {
    "issue_number": 641,
    "repo_name": "mlcommons/algorithmic-efficiency",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Criteo1tb OOMs during eval for some third party training algorithms in PyTorch.\",\n    \"We're exploring reducing the criteo1tb eval bsz on both JAX and PyTorch.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"OOMs during eval\",\n    \"exploring reducing\",\n    \"significantly impacts the run time\"\n  ]\n}\n```",
    "issue_url": "https://github.com/mlcommons/algorithmic-efficiency/issues/641",
    "repo_size": 78,
    "size_category": "medium"
  },
  {
    "issue_number": 2749,
    "repo_name": "letta-ai/letta",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I was on an old version of Letta when all this started to happen\",\n    \"could not get model list, only the model that I had loaded in the system was working\",\n    \"the only slight change I made was when Ollama updated to allow storing models on a different drive\",\n    \"it would be nice to have simple way of updating to newer versions of Letta\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"used to work perfectly fine\",\n    \"could not get model list\",\n    \"only the model that I had loaded in the system was working\",\n    \"it would be nice to have\"\n  ]\n}\n```",
    "issue_url": "https://github.com/letta-ai/letta/issues/2749",
    "repo_size": 134,
    "size_category": "medium"
  },
  {
    "issue_number": 2851,
    "repo_name": "livekit/agents",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"We\u2019re stuck on how to feed that final DTMF string (123456) into the system so it behaves exactly like a user\u2019s speech transcription result.\",\n    \"Let us know if there\u2019s a recommended approach or workaround in the meantime.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"We\u2019re stuck on\",\n    \"Let us know if there\u2019s a recommended approach or workaround\"\n  ]\n}\n```",
    "issue_url": "https://github.com/livekit/agents/issues/2851",
    "repo_size": 297,
    "size_category": "large"
  },
  {
    "issue_number": 369,
    "repo_name": "h2oai/h2ogpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not express any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is primarily a user inquiry seeking clarification about the functionality and privacy of the databases, rather than an admission of technical debt.\"\n}\n```",
    "issue_url": "https://github.com/h2oai/h2ogpt/issues/369",
    "repo_size": 299,
    "size_category": "large"
  },
  {
    "issue_number": 323,
    "repo_name": "Cinnamon/kotaemon",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"When I deploy on Render, there is only one way to input pdf data.\",\n    \"When I have so many pdf files, there is only one way to input individual files.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"only one way to input\",\n    \"so many pdf files\"\n  ]\n}\n```",
    "issue_url": "https://github.com/Cinnamon/kotaemon/issues/323",
    "repo_size": 338,
    "size_category": "large"
  },
  {
    "issue_number": 341,
    "repo_name": "llm-workflow-engine/llm-workflow-engine",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Currently at my system it takes about 5s to start.\",\n    \"I am sure that only small subset of all features are used for simple cases.\",\n    \"May be it's possible not to load all that huge megabytes at once, but only when really needed.\",\n    \"I just want you to know that for some use cases startup time may be critical.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"takes about 5s to start\",\n    \"only small subset of all features are used\",\n    \"not to load all that huge megabytes at once\",\n    \"startup time may be critical\"\n  ]\n}\n```",
    "issue_url": "https://github.com/llm-workflow-engine/llm-workflow-engine/issues/341",
    "repo_size": 188,
    "size_category": "medium"
  },
  {
    "issue_number": 899,
    "repo_name": "NVIDIA/NeMo-Guardrails",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"NeMo guardrails don't work as they should with the most vanilla case for fact checking.\",\n    \"Does anyone else has those problems and when it the gpt-4o model predicted to be working for fact checking?\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"don't work as they should\",\n    \"doesn't answer when using gpt-4o model\",\n    \"when it the gpt-4o model predicted to be working\"\n  ]\n}\n```",
    "issue_url": "https://github.com/NVIDIA/NeMo-Guardrails/issues/899",
    "repo_size": 148,
    "size_category": "medium"
  },
  {
    "issue_number": 1513,
    "repo_name": "imartinez/privateGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue primarily reports a JSONDecodeError during startup without any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. There are no indications from the issue content that the author is aware of any technical debt or plans to address it.\"\n}\n```",
    "issue_url": "https://github.com/zylon-ai/private-gpt/issues/1513",
    "repo_size": 379,
    "size_category": "large"
  },
  {
    "issue_number": 2098,
    "repo_name": "castorini/pyserini",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It simply asks a question about the functionality of the FaissSearcher regarding GPU usage without indicating any known issues or plans for improvement.\"\n}\n```",
    "issue_url": "https://github.com/castorini/pyserini/issues/2098",
    "repo_size": 104,
    "size_category": "medium"
  },
  {
    "issue_number": 7006,
    "repo_name": "oobabooga/text-generation-webui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"something in the requirements is wrong\",\n    \"I renamed the config-user.yaml file, but it didn't help\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"something in the requirements is wrong\",\n    \"didn't help\"\n  ]\n}\n```",
    "issue_url": "https://github.com/oobabooga/text-generation-webui/issues/7006",
    "repo_size": 339,
    "size_category": "large"
  },
  {
    "issue_number": 631,
    "repo_name": "robusta-dev/holmesgpt",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"A way to make sure the current master branch can be deployed without any errors on the most common architecture/OS\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"can be deployed without any errors\",\n    \"most common architecture/OS\"\n  ]\n}\n```",
    "issue_url": "https://github.com/robusta-dev/holmesgpt/issues/631",
    "repo_size": 88,
    "size_category": "medium"
  },
  {
    "issue_number": 912,
    "repo_name": "InternLM/xtuner",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"Setting ds_accelerator to cuda (auto detect)\",\n    \"df: \\\"/home/guochenchen/.triton/autotune\\\": \u6ca1\u6709\u90a3\u4e2a\u6587\u4ef6\u6216\u76ee\u5f55\",\n    \"WARNING: command error: '[Errno 13] Permission denied: '/home/guochenchen''!\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"Setting ... to ... (auto detect)\",\n    \"\u6ca1\u6709\u90a3\u4e2a\u6587\u4ef6\u6216\u76ee\u5f55\",\n    \"Permission denied\"\n  ]\n}\n```",
    "issue_url": "https://github.com/InternLM/xtuner/issues/912",
    "repo_size": 344,
    "size_category": "large"
  },
  {
    "issue_number": 197,
    "repo_name": "browser-use/web-ui",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any explicit acknowledgment of suboptimal solutions, temporary fixes, or known limitations. The author simply describes a problem they are experiencing without indicating any awareness of technical debt or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/browser-use/web-ui/issues/197",
    "repo_size": 353,
    "size_category": "large"
  },
  {
    "issue_number": 122,
    "repo_name": "weaviate/Verba",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"implementation\",\n  \"LANGUAGE_PATTERNS\": [\n    \"DeprecationWarning\",\n    \"Please move to\"\n  ]\n}\n```",
    "issue_url": "https://github.com/weaviate/Verba/issues/122",
    "repo_size": 243,
    "size_category": "large"
  },
  {
    "issue_number": 1252,
    "repo_name": "ModelCloud/GPTQModel",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"I think to build a docker image would not be hard.\",\n    \"this image builf from huggingface is giving me the following log:\",\n    \"THIS IMAGE IS DEPRECATED and is scheduled for DELETION.\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"configuration\",\n  \"LANGUAGE_PATTERNS\": [\n    \"I think to build a docker image would not be hard.\",\n    \"this image builf from huggingface is giving me the following log:\",\n    \"THIS IMAGE IS DEPRECATED and is scheduled for DELETION.\"\n  ]\n}\n```",
    "issue_url": "https://github.com/ModelCloud/GPTQModel/issues/1252",
    "repo_size": 123,
    "size_category": "medium"
  },
  {
    "issue_number": 322,
    "repo_name": "unslothai/unsloth",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"No\",\n  \"REASON\": \"The issue does not contain any acknowledgment of suboptimal solutions, limitations, or technical shortcuts. It is simply a request for AMD support without any indication of existing problems or future improvements.\"\n}\n```",
    "issue_url": "https://github.com/unslothai/unsloth/issues/322",
    "repo_size": 398,
    "size_category": "large"
  },
  {
    "issue_number": 394,
    "repo_name": "PromtEngineer/localGPT",
    "analysis": "```json\n{\n  \"SATD_FOUND\": \"Yes\",\n  \"EXACT_QUOTES\": [\n    \"model inference is pretty slow\",\n    \"This action can take a few minutes!\"\n  ],\n  \"WHO_ADMITS\": \"issue author\",\n  \"DEBT_TYPE\": \"performance\",\n  \"LANGUAGE_PATTERNS\": [\n    \"pretty slow\",\n    \"can take a few minutes\"\n  ]\n}\n```",
    "issue_url": "https://github.com/PromtEngineer/localGPT/issues/394",
    "repo_size": 194,
    "size_category": "medium"
  }
]